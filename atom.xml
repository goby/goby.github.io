<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>gobyoung</title>
  
  <subtitle>Walk deep in the sea</subtitle>
  <link href="/atom.xml" rel="self"/>
  
  <link href="https://blog.gobyoung.com/"/>
  <updated>2018-03-18T07:49:33.203Z</updated>
  <id>https://blog.gobyoung.com/</id>
  
  <author>
    <name>Tanglim LUA</name>
    
  </author>
  
  <generator uri="http://hexo.io/">Hexo</generator>
  
  <entry>
    <title>Hello World</title>
    <link href="https://blog.gobyoung.com/2018/hello-world/"/>
    <id>https://blog.gobyoung.com/2018/hello-world/</id>
    <published>2018-03-18T07:49:33.203Z</published>
    <updated>2018-03-18T07:49:33.203Z</updated>
    
    <content type="html"><![CDATA[<p>Welcome to <a href="https://hexo.io/" target="_blank" rel="noopener">Hexo</a>! This is your very first post. Check <a href="https://hexo.io/docs/" target="_blank" rel="noopener">documentation</a> for more info. If you get any problems when using Hexo, you can find the answer in <a href="https://hexo.io/docs/troubleshooting.html" target="_blank" rel="noopener">troubleshooting</a> or you can ask me on <a href="https://github.com/hexojs/hexo/issues" target="_blank" rel="noopener">GitHub</a>.</p><h2 id="Quick-Start"><a href="#Quick-Start" class="headerlink" title="Quick Start"></a>Quick Start</h2><h3 id="Create-a-new-post"><a href="#Create-a-new-post" class="headerlink" title="Create a new post"></a>Create a new post</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo new <span class="string">"My New Post"</span></span><br></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/writing.html" target="_blank" rel="noopener">Writing</a></p><h3 id="Run-server"><a href="#Run-server" class="headerlink" title="Run server"></a>Run server</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo server</span><br></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/server.html" target="_blank" rel="noopener">Server</a></p><h3 id="Generate-static-files"><a href="#Generate-static-files" class="headerlink" title="Generate static files"></a>Generate static files</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo generate</span><br></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/generating.html" target="_blank" rel="noopener">Generating</a></p><h3 id="Deploy-to-remote-sites"><a href="#Deploy-to-remote-sites" class="headerlink" title="Deploy to remote sites"></a>Deploy to remote sites</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo deploy</span><br></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/deployment.html" target="_blank" rel="noopener">Deployment</a></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;Welcome to &lt;a href=&quot;https://hexo.io/&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;Hexo&lt;/a&gt;! This is your very first post. Check &lt;a href=&quot;https://hexo.
      
    
    </summary>
    
      <category term="for" scheme="https://blog.gobyoung.com/categories/for/"/>
    
    
  </entry>
  
  <entry>
    <title>Test image upload</title>
    <link href="https://blog.gobyoung.com/2017/Test%20image%20upload/"/>
    <id>https://blog.gobyoung.com/2017/Test image upload/</id>
    <published>2017-11-19T16:30:22.000Z</published>
    <updated>2018-03-18T07:49:33.203Z</updated>
    
    <content type="html"><![CDATA[<figure class="image-bubble">                <div class="img-lightbox">                    <div class="overlay"></div>                    <img src="/images/image-20171119-163047.png" alt="" title="">                </div>                <div class="image-caption"></div>            </figure>]]></content>
    
    <summary type="html">
    
      
      
        &lt;figure class=&quot;image-bubble&quot;&gt;
                &lt;div class=&quot;img-lightbox&quot;&gt;
                    &lt;div class=&quot;overlay&quot;&gt;&lt;/div&gt;
                   
      
    
    </summary>
    
    
  </entry>
  
  <entry>
    <title>Setup Virtual hexo With SaaS stack</title>
    <link href="https://blog.gobyoung.com/2017/setup-virtual-hexo-with-saas-stack/"/>
    <id>https://blog.gobyoung.com/2017/setup-virtual-hexo-with-saas-stack/</id>
    <published>2017-09-24T05:50:25.000Z</published>
    <updated>2018-03-18T07:49:33.203Z</updated>
    
    <content type="html"><![CDATA[<p>使用开源软件服务栈搭建可视化博客，换言之，就是尽量用免费的 SaaS 服务，搭建可视化的完全掌控的博客站点。 这个想法有点奇怪对不对？ 如果想要用， WordPress 不就可以吗？</p><p>好了，我的想法就是，用 GitHub Page 托管网站。其次，就是能够支持在线编辑。前者很早就实现了，后者是我最近这段时间两台笔记本都坏了无法修复的情况下，用蓝牙键盘 ＋ 锤子手机蛋疼想出来的。</p><p>因为蓝牙键盘没有 Esc 键，以及自己手机里搞一套 nodejs 会不会太蛋疼了。所以就有了这个想法。</p><p>基本的博客框架，就是 <a href="https://hexo.io" target="_blank" rel="noopener">hexo</a>。我最早用的是 <a href="https://hyde.github.io" target="_blank" rel="noopener">hyde</a>，但 hyde 的更新很慢，而且文档缺失，自己写插件实在蛋疼。后来发现 hexo 最近很流行，重点是，插件很多，想要随时拿，所以就转到 hexo 来了。转得很顺利，因为刚开始不懂，刚转为 hexo 想自己写主题，看了半天的 API 文档，不知所以然，毕竟对前端不熟。然后网上一搜，就找很到很多资料了。</p><p>OK，另外一个呢，是编辑器的支持。还好找到 <a href="https://github.com/tajpure/hexo-editor" target="_blank" rel="noopener">hexo-editor</a> 这款开源软件。那思路就很简单了。刚开始我只是想给它加一个 Image Paste and Upload 的功能，这样就可以随时截图随时贴了。写完，突然想起，我又不想在自己的开发机上做这些和私人的东西，于是就想用随便一个 App Engine 来搭建这个 editor 了。然后脑子里第一个想到就是 heroku!!!</p><p>所以，大体的思路如下：</p><ul><li>在 heroku 上创建 nodejs 的 App，并部署 hexo-editor 的代码</li><li>给 hexo-editor 添加 git 的功能，部署时，自动拉取博客的 hexo 源码</li><li>在主界面，添加 Push &amp; Pull 的功能，能够将我们创建的 md 文件<br>push 到 github</li><li>利用和 travis 相同的想法，用 aes 加密 deployment key，在应用启动的时候加入 ssh-agent，后续拉取和部署代码用这个 key</li><li>部署到 github 之后，由 travis 拉去更新，进行编译和生成静态代码，再部署到 github 上的 page repo</li><li>这样就完成了整个过程了</li></ul><p>本来写了一大堆的，因为 session 太短了（一个小时，没有保存），过期重新登陆，缓存没了，干。所以索性把 cookie expiration 设置为 几个月。然后页面插一段 js 代码自动 ping 服务器，这样就能安全地写了。</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;使用开源软件服务栈搭建可视化博客，换言之，就是尽量用免费的 SaaS 服务，搭建可视化的完全掌控的博客站点。 这个想法有点奇怪对不对？ 如果想要用， WordPress 不就可以吗？&lt;/p&gt;
&lt;p&gt;好了，我的想法就是，用 GitHub Page 托管网站。其次，就是能够支持
      
    
    </summary>
    
    
  </entry>
  
  <entry>
    <title>ssh 隧道挖掘艺术</title>
    <link href="https://blog.gobyoung.com/2017/dig-ssh-tunnel/"/>
    <id>https://blog.gobyoung.com/2017/dig-ssh-tunnel/</id>
    <published>2017-09-19T10:22:04.000Z</published>
    <updated>2018-03-18T07:49:33.203Z</updated>
    
    <content type="html"><![CDATA[<p>我们有一台公网的跳板机，但是我们的开发机不能有外网网卡(你看看，一刀切的厉害)。<br>所以只好用 ssh 隧道大法。</p><p>基本架构如下：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">                                                       VPC</span><br><span class="line">                              +-------------+          +---------------------------+</span><br><span class="line">+-------------+               |             |          |  +-----+ +-----+ +-----+  |</span><br><span class="line">|             |               | Jump Server |          |  |Host | |Host | |Host |  |</span><br><span class="line">|  Local PC   +-------------&gt; |   (Proxy)   | &lt;--------+  | A   | | B   | | C   |  |</span><br><span class="line">|             |               |             |          |  +-----+ +-----+ +-----+  |</span><br><span class="line">+-------------+               +-------------+          +---------------------------+</span><br></pre></td></tr></table></figure></p><h1 id="Connect-a-host-behinds-the-firewall"><a href="#Connect-a-host-behinds-the-firewall" class="headerlink" title="Connect a host behinds the firewall"></a>Connect a host behinds the firewall</h1><p>首先我的机器是在防火墙后面，没有公网 IP，每次登陆只能使用 VPN。所幸的是防火墙对 Ingress 控制比较严格， egress 比较松。所以我们可以在某次使用 VPN 登陆 Host 之后，通过反向隧道，打开一条隧道，后面我们的通信都通过这个隧道进行。</p><p>在 host-a 中执行：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">goby@host-a $ ssh -p 2048 goby@proxy -fCNR 20480:localhost:2048</span><br></pre></td></tr></table></figure></p><p>意思就是，我们在 host-a 中，将本地的 2048(ssh 端口) 映射到远端 proxy 的 20480 端口。现在 proxy 和 host-a 之间就有了一条隧道：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">                                             VPC</span><br><span class="line">                   +-------------+          +---------------------------+</span><br><span class="line">+-----------+      |             | &lt;--------+  +-----+ +-----+ +-----+  |</span><br><span class="line">|           |      | Jump Server |  Remote  |  |Host | |Host | |Host |  |</span><br><span class="line">|  Local PC +----&gt; |   (Proxy)   |  Forward |  | A   | | B   | | C   |  |</span><br><span class="line">|           |      |             | &lt;--------+  +-----+ +-----+ +-----+  |</span><br><span class="line">+-----------+      +-------------+          +---------------------------+</span><br></pre></td></tr></table></figure></p><p>那么我们在 proxy 上就能通过 20480 访问 host-a。<br>例如：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">goby@goby-thhinkpad $ ssh -p 2048 goby@proxy ssh -p 20480 goby@localhost</span><br></pre></td></tr></table></figure></p><p>如果我们在防火墙后有 N 台机器，都通过这种方式也太恶心了，怎么办？我们只好把 host-a 也当成第二层跳板机，通过前面创建的隧道。</p><p>所以，我可以在本地启动 ssh-agent，通过 Forward Agent 将本地 key 带过去。例如：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">goby@goby-thhinkpad $ ssh -A -p 2048 goby@proxy ssh -A -p 20480 goby@localhost</span><br><span class="line">goby@host-a $ ssh goby@host-k8s</span><br><span class="line">goby@host-k8s $</span><br></pre></td></tr></table></figure></p><p>熟练使用 ssh_config 的，完全可以将上面合并掉，在本地直接访问，例如我的 debian wheezy 上的 ssh_config：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">Host host-a</span><br><span class="line">  Hostname 127.0.0.1</span><br><span class="line">  User goby</span><br><span class="line">  Port 20480</span><br><span class="line">  ForwardAgent yes</span><br><span class="line">  ProxyCommand ssh -q -W %h:%p goby@proxy -p 2048</span><br><span class="line">  # 某些 ssh 版本，例如 mingw64 要用 nc</span><br><span class="line">  # ProxyCommand ssh goby@proxy -p 2048 nc %h %p</span><br></pre></td></tr></table></figure></p><p>本地就能透明访问 host-a 了。</p><h1 id="Create-a-local-proxy-upon-a-tunnel"><a href="#Create-a-local-proxy-upon-a-tunnel" class="headerlink" title="Create a local proxy upon a tunnel"></a>Create a local proxy upon a tunnel</h1><p>如果仅仅是反向代理，好像也没什么。但是如果，我们开发调试时，需要代理，例如 web 页面，从本地直接访问怎么办？我们就需要将 host-a 当成代理了。<br>所以这时候就需要在前面创建的隧道之中，再创建一个动态隧道代理：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">goby@proxy $ ssh -CNfD 17708 goby@localhost -p20480</span><br></pre></td></tr></table></figure><p>那么在跳板机上就会开启 17708 端口，用于动态隧道。最后我们要把跳板机上的 17708 端口映射到我们本地 PC 上，登陆时候使用 L 参数即可：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">goby@goby-thinkpad $ ssh -A -p 2048 goby@proxy -L 7708:localhost:17708</span><br></pre></td></tr></table></figure></p><p>那么我们就可以在本地使用 Chrome， 配置代理 SOCK4: localhost 7708 访问 host-k8s 的 IP。（搭配 Proxy SwitchOmega 使用风味更佳）</p><h1 id="Mapping-local-port-to-remote"><a href="#Mapping-local-port-to-remote" class="headerlink" title="Mapping local port to remote"></a>Mapping local port to remote</h1><p>在这个艰难的环境里，我们还可以做得更多，在这个 Fucking GFW 的局域网，我们开发中经常要用到代理。那么我们的简单想法，就是将本地代理端口映射给开发机。<br>例如本地端口是 8808，想在 host-a 上开一个公共代理12307给其他所有的node用，那么我们个前面的那个ssh_config 添加 RemoteForward 就可以了</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">Host host-a</span><br><span class="line">  Hostname 127.0.0.1</span><br><span class="line">  User goby</span><br><span class="line">  Port 20480</span><br><span class="line">  ForwardAgent yes</span><br><span class="line">  RemoteForward 12307 localhost:8808</span><br><span class="line">  ProxyCommand ssh -q -W %h:%p goby@proxy -p 2048</span><br><span class="line">  # 某些 ssh 版本，例如 mingw64 要用 nc</span><br><span class="line">  # ProxyCommand ssh goby@proxy -p 2048 nc %h %p</span><br></pre></td></tr></table></figure><p>当然，记得给 host-a 上的 sshd 配置 <code>GatewayPorts yes</code>，否则默认 12307 就监听在 loop 上。</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;我们有一台公网的跳板机，但是我们的开发机不能有外网网卡(你看看，一刀切的厉害)。&lt;br&gt;所以只好用 ssh 隧道大法。&lt;/p&gt;
&lt;p&gt;基本架构如下：&lt;br&gt;&lt;figure class=&quot;highlight plain&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutte
      
    
    </summary>
    
    
  </entry>
  
  <entry>
    <title>Dynamic tracing Go program</title>
    <link href="https://blog.gobyoung.com/2017/dynamic-tracing-go-program/"/>
    <id>https://blog.gobyoung.com/2017/dynamic-tracing-go-program/</id>
    <published>2017-08-22T13:22:21.000Z</published>
    <updated>2018-03-18T07:49:33.203Z</updated>
    
    <content type="html"><![CDATA[<h2 id="About-dynamic-tracing"><a href="#About-dynamic-tracing" class="headerlink" title="About dynamic tracing"></a>About dynamic tracing</h2><p>Before do any trace with Linux tracing tools, we should read this paper by Jim Keniston, et:<br><a href="http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.511.7870&amp;rep=rep1&amp;type=pdf" target="_blank" rel="noopener">Ptrace, Utrace, Uprobes: Lightweight, Dynamic Tracing of User Apps</a>.</p><h2 id="What-is-uprobes"><a href="#What-is-uprobes" class="headerlink" title="What is uprobes"></a>What is uprobes</h2><p>uprobes is a user-space dynamic tracing tool provided in <a href="http://kernelnewbies.org/Linux_3.5#head-95fccbb746226f6b9dfa4d1a48801f63e11688de" target="_blank" rel="noopener">Linux 3.5</a> and imporved in <a href="http://kernelnewbies.org/Linux_3.14#head-ca18fd90b3cee1181d74251909e0dda6934b5add" target="_blank" rel="noopener">Linux 3.14</a>.<br><a href="http://www.brendangregg.com/blog/2015-06-28/linux-ftrace-uprobe.html" target="_blank" rel="noopener">Brendan Gregg</a> said it imspired by <a href="https://lwn.net/Articles/370423/" target="_blank" rel="noopener">Ftrace</a>, which can trace any function in kernel.</p><blockquote><p>  There are currently two types of user-space probes: uprobes and<br>uretprobes (also called return probes).  A uprobe can be inserted on<br>any instruction in the application’s virtual address space.  A return<br>probe fires when a specified user function returns.  These two probe<br>types are discussed in more detail later.</p></blockquote><p>By Jim Keniston introduced in <a href="https://gitlab.com/fche/systemtap/blob/master/runtime/linux/uprobes/uprobes.txt" target="_blank" rel="noopener">SystemTap</a>. </p><h3 id="How-does-Uprobes-work"><a href="#How-does-Uprobes-work" class="headerlink" title="How does Uprobes work"></a>How does Uprobes work</h3><p>Here’s Uprobes doing[<a href="https://gitlab.com/fche/systemtap/blob/master/runtime/linux/uprobes/uprobes.txt" target="_blank" rel="noopener">link</a>]:</p><ul><li>user provide a binary/library and a virtual address of target function(typically the offset instead of va)</li><li>Uprobes makes a copy of the probed instruction, pause the probed application, if running</li><li>Replace the first byte(s) of the probed instruction with breakpoint instrument(eg, int3 on x86_64)<ul><li>The same machinism of ptrace, copy-on-write, so only affects on target process</li><li>Even the shared library</li></ul></li><li>Resume the paused application</li><li>When CPU hit breakpoint instrument, a trap occurs, save CPU user-mode register, and generate a SIGTRAP</li><li>Uprobes accepts the SIGTRAP signal and find out associate probe</li><li>Executes the associated handler, if existed, and passes the probe struct and the saved register.</li><li>REMARK: handler may block, and <strong>the probed thread is stopped when handler running</strong></li><li>Next, Uprobes single-steps its copy of the probed instruction and<br>resumes execution of the probed process at the instruction following<br>the probepoint</li></ul><h3 id="How-does-Uretprobes-work"><a href="#How-does-Uretprobes-work" class="headerlink" title="How does Uretprobes work"></a>How does Uretprobes work</h3><ul><li>Same with previous section’s step 1</li><li>Uprobes setup a probe at the entry to the function</li><li>When funtion called, the probe hit, Uprobes save the return address</li><li>Replace the return address with a <code>trampline</code> address – a piece of code that contains a breakpoint instruction</li><li>When the probed function returned, the return instruction is executed, enter the <code>trampline</code> area</li><li>Uprobes calls user-define handler</li><li>Sets the saved instruction pointer to the saved return<br>address, and that’s where execution resumes upon return from the trap.</li></ul><p>Infact, tracing multi-thread application is hard, and in Go environment. The Go scheduler will<br>weave instruction on-the-fly, and change <code>%sp</code> and <code>%pc</code> on demand.</p><h2 id="How-to-use-Uprobes"><a href="#How-to-use-Uprobes" class="headerlink" title="How to use Uprobes"></a>How to use Uprobes</h2><p>The document in kernel doc, <a href="https://www.kernel.org/doc/Documentation/trace/uprobetracer.txt" target="_blank" rel="noopener">Uprobe-tracer: Uprobe-based Event Tracing</a>, introduced the usage of<br>latest uprobes. </p><p>Before start, we must make sure the kernel support Uprobes, please checking:</p><ul><li><code>CONFIG_UPROBE_EVENT=y</code> in <code>/boot/config-$(uname -r)</code><ul><li>deps on kernel version, you can simply grep <code>UPROBE</code> and ensure all config is set to <code>y</code></li></ul></li><li><code>/sys/kernel/debug/</code> directory is existing (maybe <code>mount -s debugfs</code>)</li></ul><p>The probes stored in <code>/sys/kernel/debug/tracing/uprobe_events</code> and<br>the details in <code>/sys/kernel/debug/tracing/events/uprobes/&lt;EVENT&gt;</code>.</p><h3 id="Synopsis"><a href="#Synopsis" class="headerlink" title="Synopsis"></a>Synopsis</h3><p>Create a probe by <code>echo &lt;probe&gt; &gt; /sys/kernel/debug/tracing/uprobe_events</code>. And here’s the<br><code>&lt;probe&gt;</code> synopsis:</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line">==&gt;</span><br><span class="line">  p[:[GRP/]EVENT] PATH:OFFSET [FETCHARGS] : Set a uprobe</span><br><span class="line">  r[:[GRP/]EVENT] PATH:OFFSET [FETCHARGS] : Set a return uprobe (uretprobe)</span><br><span class="line">  -:[GRP/]EVENT                           : Clear uprobe or uretprobe event</span><br><span class="line"></span><br><span class="line">  GRP           : Group name. If omitted, &quot;uprobes&quot; is the default value.</span><br><span class="line">  EVENT         : Event name. If omitted, the event name is generated based</span><br><span class="line">                  on PATH+OFFSET.</span><br><span class="line">  PATH          : Path to an executable or a library.</span><br><span class="line">  OFFSET        : Offset where the probe is inserted.</span><br><span class="line"></span><br><span class="line">  FETCHARGS     : Arguments. Each probe can have up to 128 args.</span><br><span class="line">   %REG         : Fetch register REG</span><br><span class="line">   @ADDR    : Fetch memory at ADDR (ADDR should be in userspace)</span><br><span class="line">   @+OFFSET : Fetch memory at OFFSET (OFFSET from same file as PATH)</span><br><span class="line">   $stackN  : Fetch Nth entry of stack (N &gt;= 0)</span><br><span class="line">   $stack   : Fetch stack address.</span><br><span class="line">   $retval  : Fetch return value.(*)</span><br><span class="line">   $comm    : Fetch current task comm.</span><br><span class="line">   +|-offs(FETCHARG) : Fetch memory at FETCHARG +|- offs address.(**)</span><br><span class="line">   NAME=FETCHARG     : Set NAME as the argument name of FETCHARG.</span><br><span class="line">   FETCHARG:TYPE     : Set TYPE as the type of FETCHARG. Currently, basic types</span><br><span class="line">               (u8/u16/u32/u64/s8/s16/s32/s64), hexadecimal types</span><br><span class="line">               (x8/x16/x32/x64), &quot;string&quot; and bitfield are supported.</span><br><span class="line"></span><br><span class="line">  (*) only for return probe.</span><br><span class="line">  (**) this is useful for fetching a field of data structures.</span><br></pre></td></tr></table></figure><p>As forward description, we can setup a uprobe or a uretprobe by a prefix with <code>p</code> or <code>r</code>.<br>For example, create a probe in offset <code>0x2794c0</code> of application <code>/home/goby/k8s-bin/kube-controller-manager</code><br>with two arguments, <code>%sp</code> for stack pointer and <code>%ax</code>:</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">echo &quot;p:p_syncDeployment /home/goby/k8s-bin/kube-controller-manager:0x2794c0 %sp %ax&quot; &gt;&gt; /sys/kernel/debug/tracing/uprobe_events</span><br></pre></td></tr></table></figure><p>The same to uretprobes.</p><p>All of these are well-understood, but what is offset?</p><h3 id="How-to-get-function-offset"><a href="#How-to-get-function-offset" class="headerlink" title="How to get function offset"></a>How to get function offset</h3><p>Function offset is relative to <code>.text</code> section, we can get it by following formula:</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">offset(fn) = virtual_address(fn) - virtual_address(.text) + offset(.text)</span><br></pre></td></tr></table></figure><p>So we need get virtual address of target function and <code>.text</code> section.<br>We can dump the section headers to get some of them. By <code>readelf</code>:</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">$ readelf -S &lt;binary&gt;</span><br><span class="line"></span><br><span class="line">There are 46 section headers, starting at offset 0x494fc58:</span><br><span class="line"></span><br><span class="line">Section Headers:</span><br><span class="line">  [Nr] Name              Type             Address           Offset</span><br><span class="line">       Size              EntSize          Flags  Link  Info  Align</span><br><span class="line">  [ 0]                   NULL             0000000000000000  00000000</span><br><span class="line">       0000000000000000  0000000000000000           0     0     0</span><br><span class="line">  ...</span><br><span class="line">  [13] .text             PROGBITS         0000000000401a50  00001a50</span><br><span class="line">       0000000001315c54  0000000000000000  AX       0     0     16</span><br></pre></td></tr></table></figure><p>So:</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">virtual_address(.text) = 0x0000000000401a50</span><br><span class="line">offset(.text) = 0x00001a50</span><br></pre></td></tr></table></figure><p>Or we can simply get the start address if target application is running:</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">$ grep kube-controller-manager /proc/`pidof kube-controller-manager`/maps |grep r-xp</span><br><span class="line">00400000-02b21000 r-xp 00000000 fe:20 529115  /home/goby/k8s-bin/kube-controller-manager</span><br><span class="line">   |</span><br><span class="line">   \- this is the start address = virtual_address(.text) - offset(.text)</span><br></pre></td></tr></table></figure><p>Finally, dump symbol table by <code>objdump</code>:</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">$ objdump -t &lt;binary&gt; |grep syncDeployment</span><br><span class="line"></span><br><span class="line">0000000001e92570 l     O .rodata        0000000000000008              k8s.io/kubernetes/pkg/controller/deployment.(*DeploymentController).syncDeployment.func1.f</span><br><span class="line">00000000006794c0 l     F .text  0000000000000a7f              k8s.io/kubernetes/pkg/controller/deployment.(*DeploymentController).syncDeployment</span><br><span class="line">000000000067b5b0 l     F .text  000000000000016c              k8s.io/kubernetes/pkg/controller/deployment.(*DeploymentController).syncDeploymentStatus</span><br><span class="line">0000000000682b20 l     F .text  0000000000000063              k8s.io/kubernetes/pkg/controller/deployment.(*DeploymentController).(k8s.io/kubernetes/pkg/controller/deployment.syncDeployment)-fm</span><br><span class="line">0000000000682e00 l     F .text  000000000000018d              k8s.io/kubernetes/pkg/controller/deployment.(*DeploymentController).syncDeployment.func1</span><br></pre></td></tr></table></figure><p>OK, pick what we need, <code>00000000006794c0</code> is the va of function. So the offset of function is <code>0x00000000006794c0 - 0x0000000000401a50 + 00001a50 = 0x2794c0</code>.</p><p>And we can get other functions by these steps.</p><h3 id="Setup-uprobe"><a href="#Setup-uprobe" class="headerlink" title="Setup uprobe"></a>Setup uprobe</h3><p>By following command, we setup a probe to function <code>k8s.io/kubernetes/pkg/controller/deployment.(*DeploymentController).syncDeployment</code>:</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"># echo &quot;p:p_syncDeployment /home/goby/k8s-bin/kube-controller-manager:0x2794c0&quot; &gt;&gt; /sys/kernel/debug/tracing/uprobe_events</span><br></pre></td></tr></table></figure><p>We can check the debugfs, which auto-generated once the probe setupped:</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">root@debian7:/sys/kernel/debug/tracing# tree events/uprobes/</span><br><span class="line">events/uprobes/</span><br><span class="line">├── enable</span><br><span class="line">├── filter</span><br><span class="line">└── p_syncDeployment</span><br><span class="line">    ├── enable</span><br><span class="line">    ├── filter</span><br><span class="line">    ├── format</span><br><span class="line">    ├── id</span><br><span class="line">    └── trigger</span><br></pre></td></tr></table></figure><p>OK, everything is ok, let’s fly:</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">echo 1 &gt; /sys/kernel/debug/tracing/events/uprobes/enable</span><br></pre></td></tr></table></figure><h3 id="Trace-Result"><a href="#Trace-Result" class="headerlink" title="Trace Result"></a>Trace Result</h3><p>Once the application call target function. We can get result from <code>/sys/kernel/debug/tracing/trace</code></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">cat /sys/kernel/debug/tracing/trace</span><br><span class="line"></span><br><span class="line"># tracer: nop</span><br><span class="line">#</span><br><span class="line"># entries-in-buffer/entries-written: 398/398   #P:4</span><br><span class="line">#</span><br><span class="line">#                              _-----=&gt; irqs-off</span><br><span class="line">#                             / _----=&gt; need-resched</span><br><span class="line">#                            | / _---=&gt; hardirq/softirq</span><br><span class="line">#                            || / _--=&gt; preempt-depth</span><br><span class="line">#                            ||| /     delay</span><br><span class="line">#           TASK-PID   CPU#  ||||    TIMESTAMP  FUNCTION</span><br><span class="line">#              | |       |   ||||       |         |</span><br><span class="line"> kube-controller-26269 [000] d... 8212014.640986: p_syncDeployment: (0x6794c0) arg1=0xc421101d48 arg2=0xd</span><br><span class="line"> kube-controller-26266 [003] d... 8212014.641009: p_syncDeployment: (0x6794c0) arg1=0xc420cf7d48 arg2=0x11</span><br><span class="line"> kube-controller-26267 [002] d... 8212014.641105: p_syncDeployment: (0x6794c0) arg1=0xc4212a1d48 arg2=0x11</span><br><span class="line"> kube-controller-26268 [001] d... 8212014.641547: p_syncDeployment: (0x6794c0) arg1=0xc421239d48 arg2=0xf</span><br></pre></td></tr></table></figure><p>This result shows who called the function, which cpu run, when called, and the argument we requested.<br>We can parse this file by a script to get function called frequency, get function latency with a return<br>probe.</p><h3 id="Further-doing"><a href="#Further-doing" class="headerlink" title="Further doing"></a>Further doing</h3><p>These procedures are too complicated to do. To trace one function maybe ok, but 10? 100? Yes, we can choose<br>some newer tools if the kernel is newer enough. <a href="https://github.com/iovisor/bcc" target="_blank" rel="noopener">bcc</a> is a nice tool to do<br>such dirty things.</p><p>For example,</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">root@debian7:/usr/share/bcc/tools# ./funccount -p `pidof kube-controller-manager` &quot;/home/goby/k8s-bin/kube-controller-manager:*syncD*&quot;</span><br><span class="line">Tracing 7 functions for &quot;/home/goby/k8s-bin/kube-controller-manager:*syncD*&quot;... Hit Ctrl-C to end.</span><br><span class="line">^C</span><br><span class="line">FUNC                                    COUNT</span><br><span class="line">k8s.io/kubernetes/pkg/controller/deployment.(*DeploymentController).syncDeployment        6</span><br><span class="line">k8s.io/kubernetes/pkg/controller/deployment.(*DeploymentController).syncDeploymentStatus        6</span><br><span class="line">k8s.io/kubernetes/pkg/controller/deployment.(*DeploymentController).(k8s.io/kubernetes/pkg/controller/deployment.syncDeployment)-fm        6</span><br><span class="line">k8s.io/kubernetes/pkg/controller/deployment.(*DeploymentController).syncDeployment.func1        6</span><br><span class="line">Detaching...</span><br></pre></td></tr></table></figure><p>And the bcc created probes for us:<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">root@debian7:/sys/kernel/debug/tracing# cat uprobe_events</span><br><span class="line">p:uprobes/p__home_goby_k8s_bin_kube_controller_manager_0x2729b0_bcc_30466 /home/goby/k8s-bin/kube-controller-manager:0x00000000002729b0</span><br><span class="line">p:uprobes/p__home_goby_k8s_bin_kube_controller_manager_0x2729b0_bcc_30551 /home/goby/k8s-bin/kube-controller-manager:0x00000000002729b0</span><br><span class="line">p:uprobes/p__home_goby_k8s_bin_kube_controller_manager_0x274be0_bcc_30551 /home/goby/k8s-bin/kube-controller-manager:0x0000000000274be0</span><br><span class="line">p:uprobes/p__home_goby_k8s_bin_kube_controller_manager_0x275430_bcc_30551 /home/goby/k8s-bin/kube-controller-manager:0x0000000000275430</span><br><span class="line">p:uprobes/p__home_goby_k8s_bin_kube_controller_manager_0x2794c0_bcc_30551 /home/goby/k8s-bin/kube-controller-manager:0x00000000002794c0</span><br><span class="line">p:uprobes/p__home_goby_k8s_bin_kube_controller_manager_0x27b5b0_bcc_30551 /home/goby/k8s-bin/kube-controller-manager:0x000000000027b5b0</span><br><span class="line">p:uprobes/p__home_goby_k8s_bin_kube_controller_manager_0x282b20_bcc_30551 /home/goby/k8s-bin/kube-controller-manager:0x0000000000282b20</span><br><span class="line">p:uprobes/p__home_goby_k8s_bin_kube_controller_manager_0x282e00_bcc_30551 /home/goby/k8s-bin/kube-controller-manager:0x0000000000282e00</span><br></pre></td></tr></table></figure></p><h2 id="BUG"><a href="#BUG" class="headerlink" title="BUG"></a>BUG</h2><p>Uretprobes is not very stable for golang program, if a return probe enabled and restart the<br>program, it will panic.</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">runtime: unexpected return pc for k8s.io/kubernetes/pkg/controller/deployment.(*DeploymentController).syncDeployment called from 0x7fffffffe000</span><br><span class="line">fatal error: unknown caller pc</span><br></pre></td></tr></table></figure>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h2 id=&quot;About-dynamic-tracing&quot;&gt;&lt;a href=&quot;#About-dynamic-tracing&quot; class=&quot;headerlink&quot; title=&quot;About dynamic tracing&quot;&gt;&lt;/a&gt;About dynamic tracing&lt;/
      
    
    </summary>
    
    
      <category term="go" scheme="https://blog.gobyoung.com/tags/go/"/>
    
      <category term="trace" scheme="https://blog.gobyoung.com/tags/trace/"/>
    
      <category term="uprobe" scheme="https://blog.gobyoung.com/tags/uprobe/"/>
    
      <category term="performance tuning" scheme="https://blog.gobyoung.com/tags/performance-tuning/"/>
    
  </entry>
  
  <entry>
    <title>Hello World</title>
    <link href="https://blog.gobyoung.com/2017/Hello-World/"/>
    <id>https://blog.gobyoung.com/2017/Hello-World/</id>
    <published>2017-08-21T13:27:14.000Z</published>
    <updated>2018-03-18T07:49:33.199Z</updated>
    
    <summary type="html">
    
    </summary>
    
      <category term="bar" scheme="https://blog.gobyoung.com/categories/bar/"/>
    
    
  </entry>
  
  <entry>
    <title>pipe(7) 原理与实现</title>
    <link href="https://blog.gobyoung.com/2017/how-linux-implements-pipe/"/>
    <id>https://blog.gobyoung.com/2017/how-linux-implements-pipe/</id>
    <published>2017-08-09T01:07:41.000Z</published>
    <updated>2018-03-18T07:49:33.203Z</updated>
    
    <content type="html"><![CDATA[<p>title: pipe(7) 原理与实现<br>date: 2017-08-09 09:07:41</p><h2 id="tags"><a href="#tags" class="headerlink" title="tags:"></a>tags:</h2><p>pipe(7) 在我们日常工作中经常碰到，能够串联 Linux &amp; Unix 下各种工具的输入输出，组成一个动态的功能强大的数据处理流，是 Unix 设计哲学的一种体现。最近一次对其进行关注是因为微信群里有人说 pipe 操作会完成 4 次内存拷贝。所以究其原因或者说明对错，就展开一段考究之旅，了解 pipe 发明以前近 50 年的变化（是的，就是这么古老，比 Unix 还古老）和顺便学习 vfs 相应的知识。</p><h2 id="Unix-Pipe-起源"><a href="#Unix-Pipe-起源" class="headerlink" title="Unix Pipe 起源"></a>Unix Pipe 起源</h2><h3 id="pipeline-想法的萌发"><a href="#pipeline-想法的萌发" class="headerlink" title="pipeline 想法的萌发"></a>pipeline 想法的萌发</h3><p>根据<a href="https://en.wikipedia.org/wiki/Pipeline_(Unix)" title="Pipelin Origin of Unix Pipes" target="_blank" rel="noopener">维基百科</a>和 [/sys/doc/][2]的说明，Unix 的 Pipeline 概念最初由 <a href="http://genius.cat-v.org/doug-mcilroy/" target="_blank" rel="noopener">Doug McIlroy</a> 发明。 当时， McIlroy 认为，从一个程序输出到文件，再输入另一个程序非常耗时。互联网总是那么神奇，保存了当时 pipeline 的初衷：</p><blockquote><p>- 10 -</p><p> Summary–what’s most important.</p><p>   To put my strongest concerns into a nutshell:</p><ol><li>We should have some ways of coupling programs like<br>garden hose–screw in another segment when it becomes when<br>it becomes necessary to massage data in another way.<br>This is the way of IO also.</li><li>Our loader should be able to do link-loading and<br>controlled establishment.</li><li>Our library filing scheme should allow for rather<br>general indexing, responsibility, generations, data path<br>switching.</li><li>It should be possible to get private system components<br>(all routines are system components) for buggering around with.</li></ol><p>M. D. McIlroy</p><p>October 11, 1964 </p></blockquote><p><img src="http://doc.cat-v.org/unix/pipes/pipe.png" alt="The Origin of Unix Pipes"></p><p>McIlory 认为当时一个最重要的事就是找到一种类似花园浇水软管的方式，组合不同程序的输入输出，就像一条信息流一样。</p><h3 id="Unix-Pipe-与-标记"><a href="#Unix-Pipe-与-标记" class="headerlink" title="Unix Pipe 与 | 标记"></a>Unix Pipe 与 <code>|</code> 标记</h3><p>在 19 年后的 1973 年，当 <a href="https://en.wikipedia.org/wiki/Ken_Thompson" target="_blank" rel="noopener">Ken Thompson</a> 在 Research Unix 第三版中引入 <code>pipe()</code> 系统调用的时候，MiIlroy 非常兴奋:</p><blockquote><p>“… in one feverish night … The next day, saw an unforgettable orgy of one-liners as everybody joined in the excitement of plumbing”</p></blockquote><p>不过当时 pipeline 并不是 Unix 独有的，在 Dartmouth Time-Sharing System 中也有 “communication files” 的概念。</p><p>在 <a href="https://en.wikipedia.org/wiki/Dennis_Ritchie" target="_blank" rel="noopener">Dennis Ritchie</a> (他老人家也在 2011 年 10 月 12 日去世去世，那一周乔布斯也去世了，世界媒体和人们对两者的关注度天差地别，不过这是另外一个话题了，许多年后的今天有时我们还能看到有人试图去比较批判人们对两个人的态度) 老先生的 <a href="https://www.bell-labs.com/usr/dmr/www/hist.html" target="_blank" rel="noopener">“The Evolution of the Unix Time-sharing System”</a> 论文中的描述，McIlroy 的想法是，在程序的前后，表明输入输出，例如 <code>copy</code> 指令：</p><pre><code>inputfile copy outputfile</code></pre><p>为了更直观表示 pipeline， 不同命令可以组合起来。因此例如 <code>sort</code> 一个 <code>input</code> 文件，然后由 <code>paginate</code> 进行分页，最后用 <code>print</code> 打印结果，可以表示为：</p><pre><code>input sort paginate print</code></pre><p>对应的如今的表示为：</p><pre><code>sort input | pr | opr</code></pre><p>他说，这个想法，在当时某个下午写在黑板上，然而并没有立即行动起来。当时有几个问题亟待解决：</p><ol><li>插入文件的符号太过怪异了，因为我们通常用 <code>cp x y</code>  表示拷贝 <code>x</code> 到 <code>y</code></li><li>同时也没办法区分到时是命令参数还是输入文件还是输出文件; </li><li>这种命令执行的 IO 模型看起来不实用</li></ol><p>最终，在 McIlroy 的坚持下， <code>pipe</code> 最终还是加到系统中，同时用一种新的符号表示， 和 IO 重定向使用同一种符号。例如，上面的那个例子表示为：</p><pre><code>sort input &gt;pr&gt;opr&gt;</code></pre><p>类似重定向文件的思想，把 前一个命令的输出重定向到下一个命令上，当成下一个命令的输入。最后的 <code>&gt;</code> 在上面的例子是必须的因为最后表示输出到 Console，否则会当成重定向 <code>opr</code> 文件中。</p><p>当时 pipeline 很快就让大家接受了，同样迸发出类似 <code>filter</code> 的词。很多命令都积极适配 pipeline。例如，当时没人能够想象有人要 <code>sort</code> <code>pr</code> 在没有参数下排序或者打印标准输入。</p><p>然后，不久之后各种问题接踵而至。大部分都是愚蠢的语法问题，比如 <code>&gt;</code> 命令后的字符串用空格分隔，就像我们给 <code>pr</code> 加了参数，我们就必须加双引号：</p><pre><code>sort input &gt;&quot;pr -2&quot;&gt;opr&gt;</code></pre><p>还有就是，我们尝试让这个标记更佳通用，例如 pipe 接受输入标记 <code>&lt;</code>，这意味着标记并不唯一。例如有人会写成：</p><pre><code>oopr &lt;pr&lt;&quot;sort input&quot;&lt;</code></pre><p>甚至</p><pre><code>pr &lt;&quot;sort input&quot;&lt; &gt;opr&gt;</code></pre><p>就这样，随着第三版的发布，这种表示法持续了几个月，Thompson 提出的<code>|</code> 在第四版横空出世。然而，即使 <code>|</code> 到如今依然延续着，但是它一个非常明显的缺点就是直愣愣地只能线性传递。例如，如何优雅比较两个命令的输出？如何优雅标记一个命令的两个并行输出？</p><p>有意思的是， Ritchie 最后对“unix pipe 是 Multics 文件流拼接的延续” 的看法嗤之以鼻。当然，我并没有对 Multics 文件流拼接进行探讨，那已经是上古时代的东西了。但管道的出现，让命令本身语意用法不变的情况下组合起来形成复杂的程序。</p><blockquote><p>The mental leap needed to see this possibility and to invent the notation is large indeed.</p></blockquote><p><code>|</code> 这个符号表示管道，由于非常形象生动，这个表示延续至今，并移植到非常多的操作系统中，例如 DOS, OS/2, Microsoft Windows, BeOS 等。甚至， Mac OS(X) 中的 Automator 的图标也是向这个发明致敬。</p><figure class="image-bubble">                <div class="img-lightbox">                    <div class="overlay"></div>                    <img src="https://www.blogcdn.com/www.tuaw.com/media/2012/12/automator.png" alt="automator" title="">                </div>                <div class="image-caption">automator</div>            </figure><p>另外在 <a href="https://en.wikipedia.org/wiki/Communicating_sequential_processes" target="_blank" rel="noopener">communicating sequential processes</a> （我想有空，也想谈谈 CSP，特别是最近一年一直都在用 golang ）也受到最初的 McIlroy 的想法的影响。</p><p>当然这个思想也形成软件工程中 <a href="https://en.wikipedia.org/wiki/Pipeline_(software" target="_blank" rel="noopener">“Pipe &amp; Filter Design Pattern”</a>).</p><p>最后，不得不说一句，令人遗憾的是，根据 [Warren Toomey][] 的说法，他在 1999 年 1 月拿到 Dennis Ritchie 关于 Research Unix V3 的拷贝 ，但却没有完整地留存下来，而遗留下来的版本，如今放在<a href="http://www.tuhs.org/Archive/Distributions/Research/Dennis_v3/" target="_blank" rel="noopener">阿尔卡特朗讯</a>的网站上，却刚好遗失了 <code>pipe()</code> 相关的源码，实在令人扼腕（这不得不说起台湾清华大学的开放课程 <a href="http://ocw.nthu.edu.tw/ocw/index.php?page=course&amp;cid=3" target="_blank" rel="noopener">《科幻概论》</a> 的授课老师郑运鸿先生的话，大意是“这个科技时代吊诡的是想要保存的总会丢失，不想要的总是存在世界的某个角落”，这里借用下字面意思）</p><blockquote><p>In partijust got the ‘nsys’ kernel<br>to boot, so I have not had a chance to sit down and work out exactly what<br>functionality is missing.</p><p><a href="http://www.tuhs.org/Archive/Distributions/Research/Dennis_v3/" target="_blank" rel="noopener">http://www.tuhs.org/Archive/Distributions/Research/Dennis_v3/</a></p></blockquote><p>同样， Research Unix V4 在 Dennis Ritchie 贡献出来的非常接近最终 Release Version 的<a href="http://minnie.tuhs.org/cgi-bin/utree.pl?file=V4" target="_blank" rel="noopener">版本</a>(下面的引用也来自这里)也缺少 <code>pipe</code>， 他说：</p><blockquote><p>This is a tar archive derived from a DECtape labelled “nsys”.<br>What is contains is just the kernel source, written in the pre-K&amp;R dialect of C.<br>It is intended only for PDP-11/45, and has setup and memory-handling code that will not work on other models (it’s missing things special to the later, smaller models, and the larger physical address space of the still later 11/70.)<br>It appears that it is intended to be loaded into memory at physical address 0, and transferred to at location 0.</p></blockquote><h2 id="Linux-pipe-的设计实现"><a href="#Linux-pipe-的设计实现" class="headerlink" title="Linux pipe 的设计实现"></a>Linux pipe 的设计实现</h2><p>好，考古之后，我们直接进入 Linux pipe(7) 的最新实现，总的来说，pipe 实现如下：</p><ul><li>在 vfs 中有一个 pipefs 模块，在内核启动的时候挂载进去</li><li>pipefs 与其他文件系统不同，并不是挂载根目录 <code>/</code> 下，而是专门的根 <code>pipe:</code></li><li>pipefs 无法像普通文件系统那样直接访问</li><li>pipefs 的入口在 <code>pipe(2)</code> 系统调用</li><li><code>pipe(2)</code> 在 pipefs 中创建一个文件，然后返回连个 fd，一个用于读一个用于写</li><li>pipefs 是内存文件系统</li></ul><h3 id="Virtual-File-System"><a href="#Virtual-File-System" class="headerlink" title="Virtual File System"></a>Virtual File System</h3><p>// TODO</p><p><a href="https://en.wikipedia.org/wiki/Pipeline_(Unix)" title="Pipelin Origin of Unix Pipes" target="_blank" rel="noopener">1</a>: <a href="https://en.wikipedia.org/wiki/Pipeline_e" target="_blank" rel="noopener">https://en.wikipedia.org/wiki/Pipeline_e</a> System</p><p>首先我们从 VPS 讲起， VFS 即 <a href="https://en.wikipedia.org/wiki/Virtual_file_system" target="_blank" rel="noopener">Virtual File System</a>，简单来说，就是一个文件系统的抽象，<br>定义一定的接口将各种类型的文件系统的接口统一。</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;title: pipe(7) 原理与实现&lt;br&gt;date: 2017-08-09 09:07:41&lt;/p&gt;
&lt;h2 id=&quot;tags&quot;&gt;&lt;a href=&quot;#tags&quot; class=&quot;headerlink&quot; title=&quot;tags:&quot;&gt;&lt;/a&gt;tags:&lt;/h2&gt;&lt;p&gt;pip
      
    
    </summary>
    
    
  </entry>
  
  <entry>
    <title>分布式系统理论基础摘要</title>
    <link href="https://blog.gobyoung.com/2017/distsys-basic/"/>
    <id>https://blog.gobyoung.com/2017/distsys-basic/</id>
    <published>2017-01-07T16:33:07.000Z</published>
    <updated>2018-03-18T07:49:33.203Z</updated>
    
    <content type="html"><![CDATA[<h2 id="网络和节点"><a href="#网络和节点" class="headerlink" title="网络和节点"></a>网络和节点</h2><p>node，或者成为 process, agent, actor, member </p><h3 id="节点"><a href="#节点" class="headerlink" title="节点"></a>节点</h3><ul><li>节点之间很慢，节点内部很快</li><li>所以任务尽可能在一个节点内完成</li><li>节点可靠，1) 挂掉都是作为个体挂，2) 挂掉可感知，3) 状态一致， 4) 状态转换可知</li><li>逻辑上的单节点本身也可以是分布式系统，因为对外提供一致性操作</li><li>进程的形式模型： <a href="https://en.wikipedia.org/wiki/Communicating_sequential_processes" target="_blank" rel="noopener">通信顺序进程</a>， <a href="https://en.wikipedia.org/wiki/Π-calculus" target="_blank" rel="noopener">π演算</a>， <a href="https://en.wikipedia.org/wiki/Ambient_calculus" target="_blank" rel="noopener">Ambient演算</a>， <a href="https://en.wikipedia.org/wiki/Actor_model" target="_blank" rel="noopener">Actor模型</a></li></ul><h4 id="通信顺序进程"><a href="#通信顺序进程" class="headerlink" title="通信顺序进程"></a>通信顺序进程</h4><p>通信顺序进程，就是 Communicating Sequential Processes, 简称 CSP(和 CPS continuation passing-style 好像)<br>。  由于不是科班出身，且对计算机理论并不了解，所以对于这种形式模型不了解。 还好学过数学，好歹能够简单理解下。</p><p>CSP 是描述并发系统中交互模式的形式语言，影响到 occam 以及 golang、crystal 等。 以及例如 <a href="http://www.raftlib.io" target="_blank" rel="noopener">RaftLib</a><br>– 一个目标是在多人协同开发下还能提供极端性能的可移植并行处理系统。</p><p>由于原始的CSP 比较难理解，以下是从wiki上摘抄的非形式化表达。</p><p><strong>定义</strong></p><p>CSP 提供了两种不同类型的元素：</p><ol><li>Events，表示通信或者交互，基本特性是独立且非持久的。<br>可以是原子名(on, off)、组成名(valve.open, valve,close) 或者 输入/输出事件(<code>mouse?xy</code>, <code>screen!bitmap</code>)</li><li>基本进程，表示基本的行为，例如包含 <em>STOP</em>(进程没有交流，或者成为死锁)， <em>SKIP</em>(表示<br>成功结束)</li></ol><p><strong>代数操作符</strong></p><p>//</p><h4 id="π演算"><a href="#π演算" class="headerlink" title="π演算"></a>π演算</h4><p>//</p><h4 id="Ambient演算"><a href="#Ambient演算" class="headerlink" title="Ambient演算"></a>Ambient演算</h4><p>//</p><h4 id="Actor模型"><a href="#Actor模型" class="headerlink" title="Actor模型"></a>Actor模型</h4><p>//</p><h2 id="传输层"><a href="#传输层" class="headerlink" title="传输层"></a>传输层</h2><p>通常我们都是通过 TCP 或者 UDP 来实现的。不过本着</p><blockquote><p>不管如何优化 UDP， 最后都会变成实现一个 TCP</p></blockquote><p>的原则，我们最好使用 TCP，TCP 本身诸多有点能够让我们更专注上层。</p><h3 id="TCP"><a href="#TCP" class="headerlink" title="TCP"></a>TCP</h3><ul><li>Rule 1: 如果能用 TCP ，就用 TCP</li><li>Rule 2: 默认 TCP 也许不快，但是又一堆参数和算法可以优化，常见比如fask/sask/流控/reuse port 等等</li><li>Rule 3: TCP 能够帮我们防止重复发包/丢包/乱序/探活</li><li>Rule 4: 应用层必须处理应用层的问题，比如必须设置超时</li><li>Rule 5: 如果传输最终失败，就必须有相应的措施：要么丢失信息要么重试</li></ul><h3 id="UDP"><a href="#UDP" class="headerlink" title="UDP"></a>UDP</h3><ul><li>Rule 1: UDP 是简单的 IP 复用</li><li>Rule 2: UDP 大部分情况不能满足速度的需求</li><li>Rule 3: UDP 可能被随意丢弃，可能会重复，可能会乱序，这些统统都要自己处理</li><li>Rule 4: 调试 UDP 比 TCP 难(因为你不知道为什么包丢了等等)</li><li>Rule 5: 只有认为 TCP 状态机非常昂贵的情况下，采用 UDP，比如内存因素，比如大量短连接，比如端口复用</li><li>Rule 6: UDP 应该用于 best-effort delivery，比如电话，人能够自己识别和重试，比如游戏，卡顿并且快速恢复，<br>比如其他正确处理下层混乱情况的协议</li></ul><h2 id="时钟"><a href="#时钟" class="headerlink" title="时钟"></a>时钟</h2><p>时钟的作用就是让我们知道事件的先后顺序、状态的变化过程先后。<br>以前不知道为什么 spanner 要弄个 GPS + 原子钟， 后来了解分布式系统<br>中时钟的作用，才能深刻理解。 时钟就是为了给不同数据中心的事务确定先后<br>顺序。</p><p>现在多核时代，不同的CPU之间其实也存在时钟同步问题。接下来就需要安排详读<br><a href="https://www.landley.net/kdocs/ols/2006/ols2006v1-pages-333-346.pdf" target="_blank" rel="noopener">Hrtimers and Beyoung: Transforming the Linux Time Subsystems</a></p><h3 id="什么是-wall-clock"><a href="#什么是-wall-clock" class="headerlink" title="什么是 wall clock?"></a>什么是 wall clock?</h3><p>就是 <code>&lt;sys/time.h&gt;</code> 内的时间，或者说我们常调用的 <code>gettimeofday()</code> 就是。<br>通常它只能让我们得到偏序的结果(即 inner-process events 的顺序)。<br>但这个有什么问题呢？ 为什么大家要研究时钟问题？</p><ul><li>NTP并不是如我们想象的那么美好，</li><li>节点间无法完全同步，节点间的网络传输有时延，处理有耗时，不能确定节点间<br>通信通道的稳定性</li><li>硬件时钟有偏差，时钟会漂移(比如常规晶振的精度，一天延迟个几毫秒也是很常见)</li><li>By Centuries ????</li><li>按照定义， <a href="https://en.wikipedia.org/wiki/Unix_time" target="_blank" rel="noopener">POSIX 时间</a>并非单调，<br>为什么这么说呢？因为 POSIX 时间采用格列高历，有闰秒的考虑(比如今天 2017-1-1 07:59:59 CST)<br>这里就多了1s，导致 POSIX 时间在这里可能会回退 1s。实际上，最好用 TAI，国际原子时，<br>每天严格 86400s ，不会考虑任何闰秒</li><li>想要的时间精度并不一定能够达到</li><li>线程可能会睡眠</li><li>运行时可能睡眠，例如电源管理器为了省电， 给 CPU 降频</li><li><a href="https://events.linuxfoundation.org/slides/2011/linuxcon-japan/lcj2011_wysocki.pdf" target="_blank" rel="noopener">系统/硬件可能休眠</a></li></ul><p>总而言之，最好别用（也可以看看 areiz 与 XXX 关于 Redis Lock 的讨论）。</p><h3 id="什么是-lamport-clock"><a href="#什么是-lamport-clock" class="headerlink" title="什么是 lamport clock?"></a>什么是 lamport clock?</h3><p>来自 Lamport 著名的论文 <a href="http://research.microsoft.com/en-us/um/people/lamport/pubs/time-clocks.pdf" target="_blank" rel="noopener">Times, Clocks and Ordering of Events in Distributed Systems</a></p><p>每个进程单独计时，每次变更时间+1，单调递增，每次信息传递都附上时间。 收到信息， t’ = max(t, t_msg+1)<br>如果我们有一堆全序的进程，那么产生的事件也是全序的，但是可能反直觉(?)</p><h3 id="什么是矢量时钟？"><a href="#什么是矢量时钟？" class="headerlink" title="什么是矢量时钟？"></a>什么是矢量时钟？</h3><p><a href="http://cacm.acm.org/magazines/2016/4/200168-why-logical-clocks-are-easy/abstract" target="_blank" rel="noopener">Why Logical Clocks Are Easy</a></p><ul><li>将 Lamport Clock 变成所有进程的时钟向量， $v = [t_1…t_n]$</li><li>$t_i’ = max(t_i, t_{msg,i})$</li><li>对于进程 $p_i$， 一旦执行操作，则增加向量中 $v’(p_i) = v(p_i) + 1$</li><li>提供偏序因果，即： $A &lt; B$， 当且仅当 $ A_i &lt;= B_i $，且存在 <code>k</code>，使得 $A_k &lt; B_k$</li><li>编程上： 过去共享，但是当前状态独立</li><li>通常只有当前状态才是需要考虑的，过去状态可以丢弃</li><li><code>O(p)</code> 的空间复杂度，其中 p 为进程个数</li><li>有个问题，当进程退出时，需要特殊的方式进行GC，或者不失正确性的情况下直接忽略</li><li>有两种数据结构：Dotted Version Vectors 和 Interval Tree Clocks</li><li><a href="http://gsd.di.uminho.pt/members/cbm/ps/itc2008.pdf" target="_blank" rel="noopener">Interval Tree Clocks</a>: 对于反复<br>创建退出进程比较合适</li><li><a href="http://gsd.di.uminho.pt/members/vff/dotted-version-vectors-2012.pdf" target="_blank" rel="noopener">Dotted Version Vectors</a>:<br>适合于C/S 架构</li></ul><h3 id="GPS-原子时钟"><a href="#GPS-原子时钟" class="headerlink" title="GPS/原子时钟"></a>GPS/原子时钟</h3><p>Spanner 就是 使用这种方案，也是目前知道的唯一使用这种方案的公司。</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h2 id=&quot;网络和节点&quot;&gt;&lt;a href=&quot;#网络和节点&quot; class=&quot;headerlink&quot; title=&quot;网络和节点&quot;&gt;&lt;/a&gt;网络和节点&lt;/h2&gt;&lt;p&gt;node，或者成为 process, agent, actor, member &lt;/p&gt;
&lt;h3 id=&quot;节点&quot;&gt;&lt;
      
    
    </summary>
    
    
      <category term="tech" scheme="https://blog.gobyoung.com/tags/tech/"/>
    
  </entry>
  
  <entry>
    <title>Goodbye, 2016</title>
    <link href="https://blog.gobyoung.com/2017/goodbye-2016/"/>
    <id>https://blog.gobyoung.com/2017/goodbye-2016/</id>
    <published>2017-01-01T15:46:09.000Z</published>
    <updated>2018-03-18T07:49:33.203Z</updated>
    
    <content type="html"><![CDATA[<p>许多年来第一次做年终总结。 略紧张。</p><p>2016 年即将过去了。回首一年，似无大事可叙。 年中老婆怀孕了，似乎是<br>这平平淡淡一年中最值得纪念的日子。</p><p>2015 年最后一天在老婆家办了下婚礼，元旦和她的大学好友在贵阳<br>吃个饭，算给她过了个生日。 年初她和我回家过春节，过完春节<br>回到杭州，她又匆匆飞回贵阳。 接下来相见就是五月初，我们一起随<br>公司组团去台湾玩，在台南骑电动车吹海风，结果老婆腿都被晒伤了。<br>后来我随她坐火车去了趟贵阳，把婚假也休了。 过几个礼拜老婆<br>又飞过来看我。 回去之后她和我说怀孕了。 中秋节我去看她，过一个礼拜<br>她和我又回了趟家，丈母娘也过来了。家中简单地办了场婚礼，<br>闽南那种奢华风承受不起。</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;许多年来第一次做年终总结。 略紧张。&lt;/p&gt;
&lt;p&gt;2016 年即将过去了。回首一年，似无大事可叙。 年中老婆怀孕了，似乎是&lt;br&gt;这平平淡淡一年中最值得纪念的日子。&lt;/p&gt;
&lt;p&gt;2015 年最后一天在老婆家办了下婚礼，元旦和她的大学好友在贵阳&lt;br&gt;吃个饭，算给她过了个
      
    
    </summary>
    
    
      <category term="myself" scheme="https://blog.gobyoung.com/tags/myself/"/>
    
  </entry>
  
  <entry>
    <title>Boost Your Blog with CloudFlare</title>
    <link href="https://blog.gobyoung.com/2016/boost-with-cloudflare/"/>
    <id>https://blog.gobyoung.com/2016/boost-with-cloudflare/</id>
    <published>2016-12-26T10:45:10.000Z</published>
    <updated>2018-03-18T07:49:33.203Z</updated>
    
    <content type="html"><![CDATA[<h1 id="为什么要加速"><a href="#为什么要加速" class="headerlink" title="为什么要加速"></a>为什么要加速</h1><p>因为众所周知的原因， 在大天朝访问 *.github.io 的速度总是不那么理想， 尤其是<br>在庆丰朝的今天。 另外因为 Github 最近的<a href="https://www.bloomberg.com/news/articles/2016-12-15/github-is-building-a-coder-s-paradise-it-s-not-coming-cheap" target="_blank" rel="noopener">财报不太好</a>， 为了开源节流，已经把<br> <a href="https://help.github.com/articles/what-is-github-pages/#usage-limits" target="_blank" rel="noopener">Github Pages 进行限流</a>了。</p><p>我的这个站点很早以前已经经过 CloudFlare 加速了，而且加速效果非常不错。 同时这个站点里头<br>也用到了 google 的一些服务( Google Fonts 以及 Google 自定义搜索等)，通过 CloudFlare<br>也能够实现内容的加速。</p><h1 id="能够加速的地方"><a href="#能够加速的地方" class="headerlink" title="能够加速的地方"></a>能够加速的地方</h1><p>依赖 Cloudflare 的节点, 能够实现 CDN 的加速功能( 但好像看起来我的并不行，<br>总是被调度到他们的总部，不过这样能够防治某墙对 *.github.io 的干扰， 总体效果依然比<br>采用了 Fastly CDN 的 github.io 强)。 </p><h1 id="如何加速"><a href="#如何加速" class="headerlink" title="如何加速"></a>如何加速</h1><p>加速基本模型如下：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">Client &lt;-----&gt; CloudFlare &lt;--&gt; Github Pages Server</span><br></pre></td></tr></table></figure><p>好在 Github Pages 支持域名绑定，我们把域名给 CloudFlare 解析，然后 CNAME 到<br>goby.github.io 即可，记得在配置的时候打开 CDN and HTTPProxy 开关。</p><p>然后在 CloudFlare 配置即可。以下介绍下一些关键点。</p><h2 id="HTTP2"><a href="#HTTP2" class="headerlink" title="HTTP2"></a>HTTP2</h2><p>打开 CloudFlare 的 Cryto/SSL， 调整成 Flexible 即可。</p><p>CloudFlare 如何实现的呢？ 简单地说，就是替我们申请 X.509 证书，帮我们做 SSL 卸载。<br>然后通过 SAN(<a href="https://en.wikipedia.org/wiki/Subject_Alternative_Name" target="_blank" rel="noopener">Subject Alternative Name</a>) 将一张证书给一堆域名用。比如，我<br>的证书的 SAN 字段就是这样的：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">DNS Name=sni152148.cloudflaressl.com</span><br><span class="line">DNS Name=*.atom-design.com.pl</span><br><span class="line">...</span><br><span class="line">DNS Name=*.gobyoung.com</span><br><span class="line">...</span><br></pre></td></tr></table></figure><p>生成一个带有 SAN 的证书可以参见 <a href="https://gist.github.com/Soarez/9688998" target="_blank" rel="noopener">How to setup your own CA with OpenSSL</a>。<br>从返回的头部也初步判断 CloudFlare 用户前端 Server 就是 Nginx( ningx 大牛章亦春之前就在<br>它家)， 而 nginx 干这种事情最得心应手。</p><p>现在用 Nginx + OpenSSL 做 SSL offload 可以借助硬件，比如 Intel 的 <a href="https://software.intel.com/en-us/articles/intel-advanced-encryption-standard-instructions-aes-ni" target="_blank" rel="noopener">AES-NI</a><br>加速。</p><p>猜想它的后台应该是这样实现：</p><ul><li>用户添加一条记录，启用 CDN 以及 SSL</li><li>把用户请求分配到某个证书请求队列中，每个队列有一定的编号，比如 sni152148</li><li>在比较短的时间内，比如可能是一小时或者十分钟，将所有该队列中的域名放入 SAN 并向证书服务商<br>发送证书申请</li><li>完成，并将获得的证书下发到代理服务器上</li><li>在后面某段时间，进行证书之间的 rebalance(即将某个域名转到不同的队列中去, 因为我的网站<br>的证书变过几次)</li></ul><p>因为证书价格不菲，而Let’s Encrypt 之类的需要自己去renew，所以直接交给 CloudFlare 帮我们<br>处理，并且它也支持自动renew。</p><h2 id="代理优化"><a href="#代理优化" class="headerlink" title="代理优化"></a>代理优化</h2><p>另外一个很强大的功能就是代理优化，比如：</p><ul><li>Rocket Loader – 自动优化Javascript，合并 js 文件，并保证第三方的js不会拖慢页面加载速度，<br>我觉得比较强大的一点，它能够让我直接使用 Google Custom Search</li><li>Local Storage Caching – 利用本地缓存(例如 chrome 的 localStorage )，将文件内容写到本地<br>缓存中，防治网络的重复请求(相对于 HTTP 的 Caching 来说，连网络请求都不用了)，也就是说能直接利用<br>本地缓存渲染。</li><li>Cache Header Optimization – 直接优化 HTTP 头的缓存相关(Date/Expire/Last-Modified 之类的)</li><li>HTTP2 – 就如第一节将的，升级成 HTTP2，多路复用、头压缩、请求流优先级等。</li><li>Server Push – 这个也是 HTTP2 的一个优势，解读 HTML 内容，在 Client 获取文件之前，一次性<br>将所需的文件推送给 Client。 常见的比如，当Client 请求 HTML 时，服务端将所需的 CSS、图片等<br>直接推给 Client， 减少多个 RTT。</li><li>AutoMinify – 自动优化 HTML, CSS, Javascript 文件，例如我使用了 bootstrap， <a href="https://blog.gobyoung.com/media/js/bootstrap.js">经过优化</a><br>的文件相较于<a href="https://raw.githubusercontent.com/goby/goby.github.io/master/media/js/bootstrap.js" target="_blank" rel="noopener">原文件</a>，大小降低 32%。</li><li>Automatic Content Caching – CloudFlare 的边缘服务器会自动缓存各种静态资源文件，而且通过<br>TTL 来控制(和 Local Storage Caching 配合)。而且可以配置 TTL，即边缘节点多久回源刷新缓存。</li></ul><p>以下介绍下我对这几个功能的理解，以及让我来做，我改怎么实现。</p><h1 id="如何实现加速-我认为"><a href="#如何实现加速-我认为" class="headerlink" title="如何实现加速(我认为)"></a>如何实现加速(我认为)</h1><p>本章介绍下我认为的该如何实现加速。</p><h2 id="Rocket-Loader"><a href="#Rocket-Loader" class="headerlink" title="Rocket Loader"></a>Rocket Loader</h2><p>官方的介绍 <a href="https://blog.cloudflare.com/56590463/" target="_blank" rel="noopener">How CloudFlare Rocket Loader Redefines the Modern CDN</a> 有点陈旧了，<br>是 2011 年的内容，里头介绍了几点 Rocket Loader 的特点：</p><ul><li>保证所有外部包含的 js 均不会阻碍页面加载</li><li>所有的js，包含第三方的，都是异步加载</li><li>使用单个请求加载所有的 js</li><li>使用 LocalStorage 来缓存 js，除非有必须，否则连请求都不用</li></ul><p>通过我自己的观察，我发现当前(cloudflarejs-rocketloader-0.11.5 Tue Oct 07 2014 03:19:25)，它实现<br>方式如下：</p><ul><li>首先扫描页面，将所有的 scrypt 的 type 改成 <code>text/rocketscript</code>，并将外联的形式的脚本的 <code>src</code><br>属性改成 <code>data-rocketsrc</code></li><li>在页面最开头，注入 <code>CloudFlareJS-0.1.34</code>，实际上就是装着所有 CF 在客户端的加速处理脚本(包含一些特殊的高级<br>功能，比如网站公告等)，由 CloudFlareJS 动态加载 <code>rocket loader</code></li><li>Rocket Loader 处理所有的 <code>text/rocketscript</code> 类型的 <code>script</code>，记录嵌入式脚本和外联脚本的<br>先后顺序，保证原始页面脚本之间的依赖关系</li><li><p>在 Loader 载入完成之后，将所有外联式脚本的地址拼凑起来，发送到 <code>/cdn-cgi/pe/bag2</code> 下，其中结果用 <code>multipart</code> 返回回来，<br>比如当前(2016-12-25)观察到的如下:</p><figure class="highlight"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">GET /cdn-cgi/pe/bag2</span><br><span class="line">QueryString </span><br><span class="line">    <span class="attribute">r[]:https://blog.gobyoung.com/media/js/modernizr.js</span></span><br><span class="line">    r[]:https://blog.gobyoung.com/media/js/jquery.js</span><br><span class="line">    ...</span><br><span class="line"></span><br><span class="line"><span class="attribute">RESP</span></span><br><span class="line">  Content-Type multipart/mixed</span><br><span class="line"></span><br><span class="line">  <span class="attribute">X-Cf-Url</span>: https://blog.gobyoung.com/media/js/modernizr.js</span><br><span class="line">  <span class="attribute">X-Cf-Status</span>: 200</span><br><span class="line">  ...</span><br></pre></td></tr></table></figure></li><li><p>解析响应结果，将脚本，将结果保存在 LocalStorage 中，如果可用的话，这样，下次请求的时候就会先查询一下<br>Local Storage，直接去掉无畏的请求</p></li><li>按照页面的顺序执行 js 文件和 js 脚本</li><li>我发现我用的 jQuery 的 ajax 自己加载 js 脚本，它也能正确地拦截并进行代理，这用的是什么原理？</li></ul><p>有意思的是爆栈上也有类似的<a href="http://webmasters.stackexchange.com/questions/60276/how-does-cloudflares-rocket-loader-actually-work-and-how-can-a-developer-ensur" target="_blank" rel="noopener">讨论</a><br>，和我的看法大同小异。</p><p>这个虽然看起来比较简单，但是实现起来可能有一堆细节要处理（各种浏览器的兼容性、框架兼容性等），<br>比如我使用的是 Google Custom Search，每次搜索都是拼凑 URL， 结果它也都给我缓存起来了，实质上这些<br>请求都是暂时的，这也是它的 bug 之一吧。</p><p>我来实现的话，认为需要实现以下几个部分：</p><p>1). 实现聚合的 Nginx 模块可以利用 subrequest + upstream 简单实现请求的聚合，如下<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">              / subrequest 1.js -- upstream</span><br><span class="line">MainRequest -+- subrequest 2.js -- upstream</span><br><span class="line">              \ subrequest 3.js -- upstream</span><br></pre></td></tr></table></figure></p><p>在实现的时候需要在 main request 把所有的 subrequest 的关键 header 拿到，<br>写入响应 body 中。 在实现中，只需要提取与缓存相关的头即可，第二个是要防止恶意攻击，<br>比如递归请求。第三个本地缓存的重要性。</p><p>2). 实现改写 HTML 的 Nginx 模块，这个直接使用现有的模块 <a href="http://nginx.org/en/docs/http/ngx_http_sub_module.html" target="_blank" rel="noopener">ngx_http_sub_module</a><br>即可。例如：<br><figure class="highlight nginx"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="attribute">location</span> / &#123;</span><br><span class="line">  <span class="attribute">sub_filter</span> <span class="string">'&lt;script&gt;'</span> <span class="string">'&lt;script type="text/rocketscript"&gt;'</span>;</span><br><span class="line">  <span class="attribute">sub_filter</span> <span class="string">'&lt;script src='</span> <span class="string">'&lt;script data-rocketsrc='</span>;</span><br><span class="line">  ...</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p><p>另外一个就需要在 <code>&lt;head&gt;</code> 标签的里头插入 Rocket Loader 的引用，例如：<br><figure class="highlight html"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">script</span>&gt;</span><span class="undefined"></span></span><br><span class="line"><span class="undefined">  try &#123;</span></span><br><span class="line"><span class="xml">    document.write('<span class="tag">&lt;<span class="name">script</span> <span class="attr">type</span>=<span class="string">"text/javascript"</span> <span class="attr">src</span>=<span class="string">//...</span>&gt;</span><span class="undefined"></span></span><span class="tag">&lt;/<span class="name">script</span>&gt;</span>');</span><br><span class="line">  &#125; catch(e) &#123;&#125;</span><br><span class="line"><span class="tag">&lt;/<span class="name">script</span>&gt;</span></span><br></pre></td></tr></table></figure></p><p>用 <a href="https://github.com/yaoweibin/ngx_http_substitutions_filter_module" target="_blank" rel="noopener">nginx_http_substitutions_module</a> 直接用 正则表达式，能实现<br>更加强大的功能， 不过还需要和上面的需求一样，需要一个缓存保障性能。(其实不能简单地进行正则<br>替换，需要对整个 DOM 树进行解析，否则在部分场景下，比如有 <code>&lt;pre&gt;</code> 的时候会出问题)</p><p>3). 客户端 Rocket Loader 的实现，简单的实现如下:<br><figure class="highlight javascript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">var</span> scripts = <span class="built_in">document</span>.getElementsByTagName(<span class="string">'script'</span>);</span><br><span class="line"><span class="keyword">var</span> rockets = [];</span><br><span class="line">scripts.forEach(<span class="function"><span class="keyword">function</span>(<span class="params">i, e</span>)</span>&#123;</span><br><span class="line">  <span class="comment">// 将 rocket 脚本、外联脚本以及不在本地缓存中的脚本加到请求队列中</span></span><br><span class="line">  <span class="keyword">if</span> (isRocketScript(e) &amp;&amp; isExternalScript(e) &amp;&amp; !inLocalStorage(e)) &#123;</span><br><span class="line">    rockets.push(e);</span><br><span class="line">  &#125;</span><br><span class="line">&#125;);</span><br><span class="line"></span><br><span class="line"><span class="comment">// 组建请求，并设置回调</span></span><br><span class="line">getScripts(rockets, <span class="function"><span class="keyword">function</span>(<span class="params">resp</span>) </span>&#123;</span><br><span class="line">  <span class="comment">// 将返回结果放到缓存中</span></span><br><span class="line">  <span class="keyword">for</span> (<span class="keyword">var</span> p : resp.parts) &#123;</span><br><span class="line">    saveLocalStorage(p);</span><br><span class="line">  &#125;</span><br><span class="line">  <span class="comment">// 按顺序执行脚本</span></span><br><span class="line">  runScripts(scripts);</span><br><span class="line">&#125;);</span><br></pre></td></tr></table></figure></p><p>如何解决 rocket loader 的兼容性问题呢？</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;为什么要加速&quot;&gt;&lt;a href=&quot;#为什么要加速&quot; class=&quot;headerlink&quot; title=&quot;为什么要加速&quot;&gt;&lt;/a&gt;为什么要加速&lt;/h1&gt;&lt;p&gt;因为众所周知的原因， 在大天朝访问 *.github.io 的速度总是不那么理想， 尤其是&lt;br&gt;在庆丰朝的
      
    
    </summary>
    
    
      <category term="tech" scheme="https://blog.gobyoung.com/tags/tech/"/>
    
  </entry>
  
  <entry>
    <title>nginx 共享内存分配机制探究</title>
    <link href="https://blog.gobyoung.com/2016/nginx-slab-code-read/"/>
    <id>https://blog.gobyoung.com/2016/nginx-slab-code-read/</id>
    <published>2016-08-08T12:17:33.000Z</published>
    <updated>2018-03-18T07:49:33.203Z</updated>
    
    <content type="html"><![CDATA[<p>在 nginx 模块开发中，充分使用了 nginx 的共享内存， 以下为 nginx 共享内存机制的总结。</p><h1 id="nginx-共享内存结构"><a href="#nginx-共享内存结构" class="headerlink" title="nginx 共享内存结构"></a>nginx 共享内存结构</h1><p>nginx 共享内存采用 slab 形式分配，类似 Jeff Bonwick 的经典论文[1]，由一个 ngx_shm_zone_t 管理。这个结构主要用于 nginx 启动时初始化过程的上下文传递。其中：</p><ul><li>data – 任意指针，创建成功回调方法的上下文</li><li>shm – ngx_shm_t 对象，这个才是真正保存指向共享内存区指针的对象</li><li>init – 初始化回调方法，在 nginx 主循环中创建好共享区之后，会调用这个方法</li><li>tag – 任意指针，一般是指向创建的模块</li><li>noreuse – 在重新载入时（reload，配置重载或者二进制包替换）是否禁止复用，默认是允许复用。在内置tcp/http 的 upstream zone 中为了让配置起效，会设置成禁止复用。</li></ul><p>nginx 这么设计会因为它将配置读取和资源分配相分离，这样也能防止不同配置之间共享区配置冲突。我们重点关注下 ngx_shm_t 类型。</p><ul><li>ngx_shm_t 分成以下几个部分：</li><li>addr – 分配共享区的首地址，也就是 mmap 的返回值</li><li>size – 共享区大小</li><li>name – 共享区名称</li><li>log – 日志对象，用于共享内存的日志，一般就是 cycle 的日志</li></ul><p>ngx_shm_t 的分配非常简单，当前系统是否支持匿名内存(MAP_ANONYMOUS)，如果不支持且有 /dev/zero 设备，就会用 /dev/zero 来创建，否则看看是否支持System V shared memory。匿名内存：</p><pre><code>shm-&gt;addr = (u_char*) mmap(NULL, shm-&gt;size, PROT_READ|PROT_WRITE, MAP_ANON|MAP_SHARED, -1, 0);</code></pre><p>如果是 /dev/zero 方式：</p><pre><code>fd = open(&quot;/dev/zero&quot;)shm-&gt;addr = (u_char*) mmap(NULL, shm-&gt;size, PROT_READ|PROT_WRITE, MAP_SHARED, fd, 0);close(fd);</code></pre><p>如果是 System V shared memory 的方式：</p><pre><code>id = shmget(IPC_PRIVATE, shm-&gt;size, (SHM_R|SHM_W|IPC_CREAT));shm-&gt;addr = shmat(id, NULL, 0);shmctl(id, IPC_RMID, NULL);  /* 所有进程解绑后自动销毁 */</code></pre><p>接下来我们就需要聚焦在 addr 这个上面了。</p><p>为了方便内存管理和提高分配效率， nginx 在向系统申请到指定的内存之后，就在内存最开始的地方划分一块区域作为 meta 数据区，即 ngx_slab_pool_t。以下为 ngx_slab_pool_t 的结构：</p><ul><li>lock – 非指针，保存 mutex 互斥锁的数据</li><li>min_size – 1 &lt;&lt; min_shift，最小的大小</li><li>min_shift – 3，最小大小的偏移</li><li>pages – ngx_slab_page_t*， 指向页结构元数据</li><li>last – 最后一个页</li><li>free – 可用页，下连着可用页的链表</li><li>start – 共享内存数据区开始地址（实际数据分配位置）</li><li>end – 共享内存结束地址 + 1</li><li>mutex – 用来控制内存分配竞态的互斥量，实际上指向的是lock里的数据，或者文件锁实现的话fd保存文件描述符</li><li>log_ctx – 日志上下文，指向 &amp;zero</li><li>zero – 终止符</li><li>log_nomem – flag, 是否打印无法分配内存信息</li><li>data – 用户数据，用来传递与共享内存相关的上下文</li><li>addr – 共享内存开始地址（就是 shm-&gt;addr）</li></ul><h1 id="共享内存初始化"><a href="#共享内存初始化" class="headerlink" title="共享内存初始化"></a>共享内存初始化</h1><p>对共享内存分页主要有以下两个步骤：</p><ol><li>初始化互斥锁</li></ol><p>现在 nginx 对 IP 的互斥锁实现由两种，首先是如果当前编译器/系统/库支持原子操作，那么就使用相应的实现实现位于共享内存里的互斥锁（即对共享区内的数据块执行 cas，并判断是否支持信号量，支持的话就wait，否则自己 cpu_pause 下不行就调度出去，下一次进来重复上述过程）</p><p>否则利用文件锁来实现 IP 互斥锁(用配置文件中的 lock_file + 共享区名称创建所需的文件)（相应的 API 为 ngx_*lock_fd）。</p><ol><li>页表构建</li></ol><p>在初始化好锁之后，就可以创建页表了。 nginx 的页表结构比较简单，是一个简单的链表：</p><ul><li>slab – slab 标记，不同类型页有不同的作用</li><li>next – 下一个页</li><li>prev – 前一个页</li></ul><p>在实际中，页表是按大小进行组织，小需求(&lt; 0.5pagesize)由前若干个 page(又称为 slot ) 管理，大需求都是连续整页地分配，由第二部分的page 分配。基本如下：</p><p> <img src="/assets/img/maglev/b8368623-703d-4515-8e18-90c7a5eac5a6.jpg" alt="Alt pic"> </p><p>在实际内存中，格式化结果如下：<br>1 级是page，大小等于系统的 pagesize：<br>pages = size / (ngx_pagesize + sizeof(ngx_slab_page_t)) </p><p>如果该页由slot 管理，那么 page 中又分成若干个 chunk， chunk 的大小在不同的slot是不一样的，最小的大小为 min_size 为 8，最大的chunk 为 1024。不同chunk大小的bitmap 表示方法不一样：<br>在初始化时，系统预先计算了一个指针长度能表示整个page 时，chunk刚刚好的大小应该是多大（即ngx_slab_exact_size）。比如在 32 位系统为 128字节， 而 64 位为 64 字节。</p><ol><li>当 chunk 小于 ngx_slab_exact_size时，此时一个指针长度的bitmap无法表示所有chunk状态，所以需要 m 个指针，此时，每个page 前 m 个 uintptr_t 大小的区域都是作为 bitmap 使用，剩余的部分才作为可使用的内存区域， 此时用 slab 来表示每个 chunk 的大小（低四位）；</li><li>当 chunk 刚刚好是 ngx_slab_exact_size 时，这个时候就用 页头的 slab 作为 bitmap 使用；</li><li>当 chunk 大于 ngx_slab_exact_size 时，这时候，至多使用半个指针就能表示 bitmap 了， slab 就被分成两部分，高16/32位表示 bitmap， 低4位表示 log(sizeof(chunk)) （也就是说，chunk 大小不能大于 64K，64位系统的页大小不能超过4M）。</li></ol><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/* 获取大小 */</span></span><br><span class="line">n = ngx_pagesize_shift - (page-&gt;slab &amp; NGX_SLAB_SHIFT_MASK);</span><br><span class="line"><span class="comment">/* bitmap 中 后N个1 */</span></span><br><span class="line">n = <span class="number">1</span> &lt;&lt; n;</span><br><span class="line">n = ((<span class="keyword">uintptr_t</span>) <span class="number">1</span> &lt;&lt; n) - <span class="number">1</span>;</span><br><span class="line"><span class="comment">/*移到高位， 此时 mask 就是bitmap中当前选择的位置之前 */</span></span><br><span class="line">mask = n &lt;&lt; NGX_SLAB_MAP_SHIFT;</span><br></pre></td></tr></table></figure><p>如下图：</p><p> <img src="/assets/img/maglev/2367a6a5-cf0c-41cc-a303-0138fa7365c6.jpg" alt="Alt pic"> </p><p>接下来，就利用 mask 查找可用的块，要注意的是，如果当前chunk 分配完了刚好整个页都被用光了，那么需要将这个页从可用页中删除掉（就是从 slot 上解除掉，会不会像个孤页？不会，因为根据被free的地址就能反推得到这个页头，当这个页有chunk被释放时，会被挂回来）。</p><p>当大小需要超过 pagesize/2 的时候， 这时候就跨过 slots， 直接从页头区查找合适的连续空间，以page为单位。这时候大小的信息保存在 slab 中。此时 slab 的最高位表示为连续页的开始，其余部分表示为连续页的个数。如果存在连续页，后续页头的的slab所有位均为1。</p><p>另外又利用prev 指针的低2位来表示该页属于那种类型大小。</p><p>即将可分配内存分成N页，每一页的大小就是系统页大小，然后每一页都有一个ngx_slab_page_t 类型的 meta 数据描述： </p><pre><code>      |&lt;--------------------------------size-----------------------------------&gt;|(end)pool_t| (log(pagesize) - log(min_size)) * page|  pages * page| pages * pagesize |      |&lt;---------------index0----------------&gt;|&lt;-free/pages  |&lt;-start     last-&gt;|.end</code></pre><p>刚开始 free-&gt;next = pages, free-&gt;prev = NULL;   pages-&gt;next = pages-&gt;prev = free;</p><p> <img src="/assets/img/maglev/87184525-3453-4234-83b6-514f4cc2b971.jpg" alt="Alt pic"> </p><h1 id="共享内存分配与回收"><a href="#共享内存分配与回收" class="headerlink" title="共享内存分配与回收"></a>共享内存分配与回收</h1><p>页的分配：</p><p>ngx_slab_alloc_pages 负责分配页表，参数为 pages，即需要多少个页。</p><p>free 的链表保存着可分配的页，每个free 中的 page.slab 表示的是后续连续 page.slab 页都是可用的。这也相当于把链表压缩了下。</p><p>循环查找 free 链表，找到最近可用页，将对应的(连续)页取出，返回给 ngx_slab_alloc。 </p><p>页的回收：</p><p>相应的， ngx_slab_free_pages 负责页的回收，在1.7.2 之前的版本有个问题，就是当程序跑足够久之后，会产生内存碎片，也就是说连续的页会越来越少，直到最后无法再分配大内存。解决办法是直接在回收页的时候合并相邻空闲页就可以了，上代码：</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br></pre></td><td class="code"><pre><span class="line">page-&gt;slab = pages--;</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> (pages) &#123;</span><br><span class="line">    ngx_memzero(&amp;page[<span class="number">1</span>], pages * <span class="keyword">sizeof</span>(<span class="keyword">ngx_slab_page_t</span>));</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">/* 下个节点存在，通常都会存在，将自己解除出来即可 */</span></span><br><span class="line"><span class="keyword">if</span> (page-&gt;next) &#123;</span><br><span class="line">    prev =(<span class="keyword">ngx_slab_page_t</span> *) (page-&gt;prev &amp; ~NGX_SLAB_PAGE_MASK);</span><br><span class="line">    prev-&gt;next = page-&gt;next;</span><br><span class="line">    page-&gt;next-&gt;prev = page-&gt;prev;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">/* 连续页最后一片的下一片 */</span></span><br><span class="line">join = page + page-&gt;slab;</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> (join &lt; pool-&gt;last) &#123;</span><br><span class="line">    type = join-&gt;prev &amp; NGX_SLAB_PAGE_MASK;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> ( type   == NGX_SLAB_PAGE) &#123;</span><br><span class="line">        <span class="comment">/* 如果连续页连着的也是空白页首页，也在free链表中，那么就可以合并起来  */</span></span><br><span class="line">        <span class="keyword">if</span> (join-&gt;next != <span class="literal">NULL</span>) &#123;</span><br><span class="line">            pages += join-&gt;slab;</span><br><span class="line">            page-&gt;slab += join-&gt;slab;</span><br><span class="line"></span><br><span class="line">            prev = (<span class="keyword">ngx_slab_page_t</span> *) (join-&gt;prev &amp; ~NGX_SLAB_PAGE_MASK);</span><br><span class="line">            prev-&gt;next = join-&gt;next;</span><br><span class="line">            join-&gt;next-&gt;prev = join-&gt;prev;</span><br><span class="line"></span><br><span class="line">            join-&gt;slab = NGX_SLAB_PAGE_FREE;</span><br><span class="line">            join-&gt;next = <span class="literal">NULL</span>;</span><br><span class="line">            join-&gt;prev = NGX_SLAB_PAGE;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">/* 接下来是合并前面的页，被释放的非第一个页 */</span></span><br><span class="line"><span class="keyword">if</span> (page &gt; pool-&gt;pages) &#123;</span><br><span class="line">    join = page - <span class="number">1</span>;</span><br><span class="line">    type = join-&gt;prev &amp; NGX_SLAB_PAGE_MASK;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> ( type   == NGX_SLAB_PAGE) &#123;</span><br><span class="line">        <span class="comment">/* 如果前一个页是非首页，那么移到它的首页（就是prev 保存的，见后文） */</span></span><br><span class="line">        <span class="keyword">if</span> (join-&gt;slab == NGX_SLAB_PAGE_FREE) &#123;</span><br><span class="line">            join = (<span class="keyword">ngx_slab_page_t</span> *) (join-&gt;prev &amp; ~NGX_SLAB_PAGE_MASK);</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="comment">/* 同理，将自己合并到前一个空白页的后面 */</span></span><br><span class="line">        <span class="keyword">if</span> (join-&gt;next != <span class="literal">NULL</span>) &#123;</span><br><span class="line">            pages += join-&gt;slab;</span><br><span class="line">            join-&gt;slab += page-&gt;slab;</span><br><span class="line"></span><br><span class="line">            prev = (<span class="keyword">ngx_slab_page_t</span> *) (join-&gt;prev &amp; ~NGX_SLAB_PAGE_MASK);</span><br><span class="line">            prev-&gt;next = join-&gt;next;</span><br><span class="line">            join-&gt;next-&gt;prev = join-&gt;prev;</span><br><span class="line"></span><br><span class="line">            page-&gt;slab = NGX_SLAB_PAGE_FREE;</span><br><span class="line">            page-&gt;next = <span class="literal">NULL</span>;</span><br><span class="line">            page-&gt;prev = NGX_SLAB_PAGE;</span><br><span class="line"></span><br><span class="line">            page = join;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">/* 将页头保存到最后一页的prev中，以合并时快速索引 */</span></span><br><span class="line"><span class="keyword">if</span> (pages) &#123;</span><br><span class="line">    page[pages].prev = (<span class="keyword">uintptr_t</span>) page;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">/* 将空白页插到free 链表最前头 */</span></span><br><span class="line">page-&gt;prev = (<span class="keyword">uintptr_t</span>) &amp;pool-&gt;<span class="built_in">free</span>;</span><br><span class="line">page-&gt;next = pool-&gt;<span class="built_in">free</span>.next;</span><br><span class="line"></span><br><span class="line">page-&gt;next-&gt;prev = (<span class="keyword">uintptr_t</span>) page;</span><br><span class="line"></span><br><span class="line">pool-&gt;<span class="built_in">free</span>.next = page;</span><br></pre></td></tr></table></figure><p>内存分配：</p><p>根据上面的分析，内存分配就比较简单了，首先判断大小，根据大小选择不同的slot or 直接分配：</p><ol><li>大于页的一半，直接进入页的分配，查找满足需求的最大连续页；</li><li>小于页的一半，查找对应的slot，看看slot中有没有可用的页和chunk，没有的话分配一个页，然后查找chunk，并将该页插到slot的链表前头，以方便下一次分配快速查找；当下一次chunk分配不出来了，就把页从slot链表中移除，减少空闲搜索的空间；为了充分利用空间，nginx 恨不得把每个字段掰开来用，所以这种情况又根据bitmap的大小分成三种情况，如上文所述。</li></ol><p>内存回收：</p><p>内存回收同样在两个大同分支中进行，大内存直接把页挂回free 链表中，并且为了减少碎片进行空闲页的合并；小内存则先进性chunk 回收，发现整个页也回收完了就回收页，每回收完就把页挂到 slot 链表中。</p><p>参考文献：</p><ol><li><a href="https://www.usenix.org/legacy/publications/library/proceedings/bos94/full_papers/bonwick.a" target="_blank" rel="noopener">https://www.usenix.org/legacy/publications/library/proceedings/bos94/full_papers/bonwick.a</a></li><li><a href="http://man7.org/training/download/posix_shm_slides.pdf" target="_blank" rel="noopener">http://man7.org/training/download/posix_shm_slides.pdf</a></li><li><a href="https://www.kernel.org/doc/gorman/html/understand/" target="_blank" rel="noopener">https://www.kernel.org/doc/gorman/html/understand/</a></li><li>Memory FAQ <a href="http://landley.net/writing/memory-faq.txt" target="_blank" rel="noopener">http://landley.net/writing/memory-faq.txt</a></li><li>nginx中slab分配器的实现 <a href="http://www.pagefault.info/?p=177" target="_blank" rel="noopener">http://www.pagefault.info/?p=177</a></li></ol>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;在 nginx 模块开发中，充分使用了 nginx 的共享内存， 以下为 nginx 共享内存机制的总结。&lt;/p&gt;
&lt;h1 id=&quot;nginx-共享内存结构&quot;&gt;&lt;a href=&quot;#nginx-共享内存结构&quot; class=&quot;headerlink&quot; title=&quot;nginx 共
      
    
    </summary>
    
    
      <category term="tech" scheme="https://blog.gobyoung.com/tags/tech/"/>
    
  </entry>
  
  <entry>
    <title>Google Maglev 翻译</title>
    <link href="https://blog.gobyoung.com/2016/maglev-load-balancer-translate/"/>
    <id>https://blog.gobyoung.com/2016/maglev-load-balancer-translate/</id>
    <published>2016-03-07T14:13:13.000Z</published>
    <updated>2018-03-18T07:49:33.203Z</updated>
    
    <content type="html"><![CDATA[<p>[缘由]： 本文是 google 在今年NSDI上一篇会议论文，介绍他们运行了8年的负责全球业务的负载均衡服务 Maglev。从文中可以看到 Maglev 中使用的技术，例如 ECMP、BGP、GRE、Kernel Bypass、一致性哈希等都是常见且成熟的技术方案，但他们的组合方案以及后面的监控/调试手段都让我收益良多。因此就在周末的时候翻译了一下，和大家共享。经验较少、水平有限，翻译失当地方欢迎批评指正。原文：[<a href="http://research.google.com/pubs/archive/44824.pdf]" target="_blank" rel="noopener">http://research.google.com/pubs/archive/44824.pdf]</a></p><h1 id="摘要"><a href="#摘要" class="headerlink" title="摘要"></a>摘要</h1><p>Maglev 是 Google 的网络负载均衡器。<br>他是运行在通用 Linux 服务器上的大型分布式软件系统。<br>不像传统的硬件软件负载均衡器，<br>maglev 无需专门的部署物理机架，<br>同时他的能力能够简单地通过增减机器来调节。<br>网络路由器通过等价多路径路由(ECMP) 均等地分发给 maglev 机器；<br>每台 Maglev 机器再匹配数据包与他们对应的服务，<br>然后把包平均分发给每个服务Endpoint。<br>为了适应比较高或者不断增长的流量，Maglev 专门优化包转发性能。<br>单台 Maglev 机器能够满足万兆的小包流量。<br>为了最小化意外错误或者故障给面向连接协议的服务造成影响，<br>Maglev 同时具备一致性哈希和连接追踪功能。<br>Maglev 从 2008 年开始就在Google 内部服务，它支撑全球快速增长的 Google 服务，同时为 Google Cloud Platform 提供网络负载均衡服务。</p><h1 id="1-介绍"><a href="#1-介绍" class="headerlink" title="1. 介绍"></a>1. 介绍</h1><p>Google 是全球互联网流量的主要源头[29, 30]。<br>它提供了数以百计的面向用户的服务，同时还有不断增长的许许多多托管在 Cloud Platform[6] 的服务。<br>著名的 Google 服务，比如 Google 搜索、Gmail 每秒能够收到来自全球各地的百万计的请求， 极大的依赖底层服务基础架构。</p><p>为了满足如此高压力且低延迟，<br>Google 的服务需要在全球范围多个集群部署一堆服务器。<br>每个集群中，为了有效地使用资源和防止个别服务器过载，<br>一个基本的功能就需要均衡所有服务器的流量。<br>从而使网络负载均衡器成为 Google 生产环境的网络基础设施中的重要组成部分。</p><p> <img src="/assets/img/maglev/e30cf8fc-0274-4052-b590-ec8a839789ed.jpg" alt="Alt pic"> </p><p>一个网络负载均衡器通常由多台分布在路由器和服务端(通常是TCP/UDP服务器)之间的设备组成，<br>例如图一所示。<br>它负责每个包的匹配和转发。</p><p>网络负载均衡器传统由硬件设备实现[1,2,3,5,9,12,13]，一般来说有诸多限制。<br>首先，他们的可扩展性通常受限于点单的最大能力，导致无法满足 Google 的增长。<br>其次，他们的高可用不可满足 Google的需求。<br>尽管他们经常成对地部署以避免单点故障，但是只能提供 1 + 1  冗余。<br>第三，他们缺少快速迭代所需要的灵活性和可编程性，修改一台硬件负载均衡设备并非不可能，<br>只是通常比较难。<br>第四，升级代价大。升级一台硬件负载均衡通常包含购买新设备以及物理部署。<br>因为以上种种限制，我们研究和寻求另一种解决方案。</p><p>所有的服务所在集群都是常规服务器，我们可以在这些服务器上<br>以分布式软件的形式构建网络负载均衡器。<br>一个软件负载均衡系统有很多优点。<br>我们可以应用 scale-out 模型来应对可扩展性。<br>LB 的容量可以通过增加系统中机器的数量来改善： 通过ECMP 转发，<br>流量可以均衡地经过所有机器。<br>可用性可可靠性可以通过系统提供 N+1 冗余保证。<br>对系统的整体把控，我们可以快速地添加、测试和部署新特性。<br>同时，也极大的简化 LB 服务的部署： 服务只使用集群中现有的机器。<br>我们也可以将统一集群中服务切分成多个分片(shards) 以达到性能的隔离。</p><p>尽管有如上诸多优点，设计和实现一个软件网络负载均衡器非常复杂和富有挑战性。<br>首先，系统中的每个独立机器必须提供高吞吐量。<br>设 N 为系统中机器的数量， T 为单台机器的最高吞吐量。<br>整个系统的最高容量限制在 N * T。<br>如果 T 不够高，提供满足所有服务的容量并不划算[22]。<br>这个系统作为一个整体必须提供连接持久化(connection persistence)：<br>属于同一连接的数据包必须始终分发到同一个服务上。<br>这个确保了服务质量因为集群经常变化和故障非常常见[23, 40]。</p><p>这篇论文提供了 Maglev，一个快速且可靠的软件负载均衡系统。<br>从 2008 年开始，Maglev 成为 Google 前端服务基础架构中重要组成部分。<br>如今几乎承担 Google 所有来自用户的流量。<br>为了利用当前高速服务器网络技术[18, 41, 35, 31]， 每台 Maglev 机器都能线速地处理每个小包。<br>通过一致性哈希(consistent hashing)和连接追踪(connection tracking)， Maglev 提供了在频繁变更和未知故障下的可靠包分发。<br>尽管本文描述一些技术已经存在许多年，本文展示如果利用这些技术构建一个系统(operational system)。<br>本文的主要贡献?为：<br>1）展现 Maglev 的设计和实现，<br>2）分享全球范围内操作 Maglev 的经验以及<br>3）通过多重评估证明 Maglev 的能力。</p><h1 id="2-系统概况"><a href="#2-系统概况" class="headerlink" title="2. 系统概况"></a>2. 系统概况</h1><p>本节概要地介绍了 Maglev 作为一个网络负载均衡器如何工作。<br>我们先简单地介绍下 Google 的前端服务架构，接下来介绍 Maglev 系统服务配置。</p><h2 id="2-1-前端服务架构"><a href="#2-1-前端服务架构" class="headerlink" title="2.1 前端服务架构"></a>2.1 前端服务架构</h2><p>Maglev 部署在 Google 前端服务位置，包含多种集群规格。<br>为了化繁为简，本文中，我们只关注于构建一个小型的集群，然后简要地描述大型集群的构建。<br>图2 显示一个小型集群的 Google 前端服务架构的概况。</p><p> <img src="/assets/img/maglev/3db49483-ce09-4384-9eec-4963db7c0950.jpg" alt="Alt pic"> </p><p>每个 Google 服务都有一个或者多个 VIP。<br>一个 VIP 和物理 IP 的区别在于 VIP 没有绑给某个特定的网卡，<br>但是为 Maglev 背后多个服务Endpoint提供服务。<br>Maglev 关联每个 VIP 到具体的服务，然后通过 BGP 宣告给上游路由器；<br>然后路由再把 VIP 宣告给 Google 的骨干网。<br>这些 VIP 宣告给互联网使得他们能够在全球内被访问。<br>Maglev 同时处理 IPv4 和 IPv6 流量，以下所有的描述均可用于这两者。</p><p>当用户访问<a href="http://www.google.com" target="_blank" rel="noopener">www.google.com</a> 上的 Google 服务，首先浏览器先发送一个 DNS 请求，<br>然后从某个 Google 的权威DNS服务器上获取 DNS 的响应（可能直接从本地缓存中或者本地DNS的缓存）。<br>DNS 服务考量服务与用户距离以及负载情况，返回服务的 VIP[16]。<br>然后浏览器尝试与该 VIP 建立连接。</p><p>当路由器接收到一个 VIP 数据包，通过 ECMP 将数据包路由到 Maglev 集群中的某台机器上，<br>因为所有 Maglev 集群都用相当的代价宣告同一个 VIP。<br>当 Maglev 的机器接收到数据包， 它从一堆关联到该 VIP 的服务Endpoint中选个一个，<br>然后用 GRE 封包，外层的 IP 即对端的IP。</p><p>当数据包到达所选的服务 endpoint 使进行解包和消费。响应时源地址用VIP 填充，目的地址为用户 IP。<br>我们使用直接服务返回(Direct Server Return， DSR) ，将响应直接发送给路由器，<br>这样 Maglev 无需处理通常是大包的响应包。<br>本文关注来自用户的进向的流量的负载均衡。<br>DSR的实现则在本文的范畴之外。[注： DSR实现需要依赖每个服务上的一个模块，<br>用于GRE拆包和响应包的组装]。</p><h2 id="2-2-Maglev-配置"><a href="#2-2-Maglev-配置" class="headerlink" title="2.2 Maglev 配置"></a>2.2 Maglev 配置</h2><p>如前一节的描述， Maglev 负责像向路由器宣告 VIP 和转发 VIP 流量到服务 endpoint 。<br>每台 Maglev 包含一个控制器和转发器，如图3 所示。<br>控制器和转发器都需要从配置对象中学习 VIP。<br>配置对象则从配置文件中读取或者通过 RPC 接收来自外部系统控制。</p><p> <img src="/assets/img/maglev/987eed70-e65e-4bac-a9e5-81ade6deb8a5.jpg" alt="Alt pic"> </p><p>每台 Maglev 机器，控制器周期性地转发器的健康状态。<br>根据检查结果， 控制器决定通过 BGP 宣告或者撤回 VIP。<br>这个确保路由器只路由包到健康的 Maglev 机器。</p><p>Maglev 接收的所有 VIP 数据包都是由转发器处理。<br>在转发器中， 每个 VIP 配置有 1 个或者多个后端池。<br>除非另外的说明，这些后端就是服务 endpoint 。<br>一个后端池可能包含服务 endpoint 的物理地址，<br>可能包含其他后端池（如此则通用的后端池则无需重复配置）。<br>每个后端池，根据需求关联了一个或者多个对后端服务的健康检查方法。<br>相同服务可能在多个后端池中，健康检查根据 IP 地址去重防止额外的负载。</p><p>转发器的配置管理负责在变更转发规则前解析和校验配置对象。<br>所有的配置更新都是原子性的。同一个集群里 Maglev 机器的配置可能因为<br>网络延迟或者健康检查关系暂时不同步。<br>但是，一致性哈希可以保证在较短时间窗口内，<br>连接在相同后端池的 Maglev 机器之间漂移。</p><p>在同一个集群中可以部署多个 Maglev 分片。<br>不同 Maglev 切片配置不同且为不同的 VIP 服务。<br>分片可以提供性能隔离和保证服务质量。<br>它也能够在不影响常规流量的情况下测试新特性。<br>本文简化问题，我们假定每个集群中只有一个分片。</p><h1 id="3-转发器设计和实现"><a href="#3-转发器设计和实现" class="headerlink" title="3. 转发器设计和实现"></a>3. 转发器设计和实现</h1><p>转发器是 Maglev 的核心组件，他需要快速且可靠地处理大量的数据包。<br>本节解释 Maglev 转发器中关键模块的设计和实现细节，以及设计背后的原理。</p><h2 id="3-1-总体架构"><a href="#3-1-总体架构" class="headerlink" title="3.1 总体架构"></a>3.1 总体架构</h2><p>图4 显示 Maglev 转发器的总体架构。<br>转发器从网卡接收到数据包，通过合理的 GRE/IP 头重写数据包，再将它们发回网卡。<br>Linux 内核不参与这个过程。</p><p> <img src="/assets/img/maglev/68165b8d-e769-499c-8b75-ecca8681600b.jpg" alt="Alt pic"> </p><p>从网卡接收数据包的首先被转发器中的 Steering 模块处理，<br>即通过 5 元组哈希(<code>s_ip</code>, <code>s_port</code>, <code>d_ip</code>, <code>d_port</code>, <code>ip_proto_num</code>)然后交给不同接收队列。<br>每个接受队列附加在一个重写包的线程上。<br>线程首先尝试匹配包到已配置的VIP上，这个步骤过滤了非法的包。<br>然后重新计算 5 元组哈希，然后在连接追踪表(见 3.3 章)上查找对应的哈希值。<br>我们没有重复利用 Streeing 模块中的哈希值，避免跨线程的同步。</p><p>这个连接表存储了最近连接的后端服务的选择结果。<br>如果发现匹配了，并且后端仍然健康，则复用改结果。<br>否则线程查询一致性哈希模块(见 3.4 章节) 同时选择一个新的后端，<br>同时添加一个新的条目到连接表中。<br>如果后端不可用，则丢弃数据包。<br>转发器为每个线程维护一个连接表防止争用。<br>当后端选择后，线程用合适的 GRE/IP 进行封包，然后发送到附加的传输队列。<br>然后 Muxing 模块轮询所有的传输队列，再发送给网卡。</p><p>Steering 模块使用5元组哈希而不是Round Robin 调度有两个原因。<br>首先，它降低同一个连接的数据包重排列的可能性，因为不同线程处理的速度的差异导致数据包乱序。<br>其次，对于连接追踪，转发器只需要为每个连接选择一次后端即可，<br>节省时钟周期，消除因为后端健康检查更新竞争导致的选择不同后端的可能性。<br>极端情况下如果接收队列满了，Steering 模块会退化使用Round-Robin 调度，<br>将数据包发送给其他可用的队列。<br>这个退化机制在处理大量相同5元组数据包中非常有效。</p><h2 id="3-2-快速包处理"><a href="#3-2-快速包处理" class="headerlink" title="3.2 快速包处理"></a>3.2 快速包处理</h2><p>Maglev 转发器需要尽快处理数据包，以在满足 Google 流量需求的情况下节省成本。<br>我们设计它在转发下满足线速 —— 在普遍都是万兆网卡的 Google 集群的今天。<br>换句话说，对于1500字节的IP包来说，相当于813Kpps。<br>然后，我们的需求更加严格：我们需要非常高效地处理小包，因为进来的请求通常是小包。<br>假设IP包的平均大小100字节，转发器必须能够处理 9.06Mpps。<br>本节的描述了我们达到这个包处理速度的关键技术。</p><p>Maglev 是一个运行在通用 Linux 服务器上的用户态程序。<br>因为 Linux 内核协议栈计算开销非常昂贵，<br>并且 Maglev 并不需要协议栈的任何特性，<br>以为这 Maglev 可以在包处理时绕开整个内核。<br>在合适的网卡硬件的支持下，我们在转发器和网卡之间开发了一套绕开内核的机制，<br>如图5.<br>当 Maglev 启动时，预先分配至好网卡和转发器共用的数据包池(Packet pool)。<br>Steering 和 muxing 模块都维护了一个指针的 ring queue ，指向该数据包池。</p><p> <img src="/assets/img/maglev/9688207c-2875-4f4c-81d1-81e8681a1fbb.jpg" alt="Alt pic"> </p><p>Steering 和 Muxing 模块都为了 3 个指向环形队列的指针。<br>对于接收端，网卡将新收到的包放在 <code>received</code> 指针位置，然后向前移动该指针。<br>Steering 模块分发数据包到数据包线程然后向前移动 <code>processed</code> 指针。<br>它同时从池里保留未使用的数据包，然后放在环形队列中，<br>并向前移动 <code>reserved</code> 指针。<br>这三个指针根据箭头一个跟着一个。类似地，在发送端，<br>网卡将指向 <code>send</code> 指针的数据包发送出去并向前移动指针。<br>Muxing 模块将重写的数据包发送队列中的<code>ready</code>位置并向前移动指针。<br>它同时将已被网卡发送的数据包归还给池子并向前移动 <code>recycled</code> 指针。<br>整个过程都没有包拷贝。</p><p>为了减少昂贵跨界操作，我们在可能的时候会批量处理数据包。<br>另外，数据包线程之间不共享任何数据，避免了他们之间的竞争。<br>我们将每个线程绑定在固定的 CPU 核上以保证性能。<br>在所有这些优化措施下， Maglev 能够在处理小包时达到限速，见 5.2 章节。</p><p>进而，Maglev 为整个链路增加的延迟非常小。<br>通常，在我们的标准的机器上， 线程处理的时间为 350ns。<br>有两种特殊情况会延长处理时间。<br>因为转发器是批量处理包的，每个批次需要等到数据包达到一定量或者时钟超时。<br>实现中我们把定时器设为 50 微妙。<br>因此如果 Maglev 显著地空载，在最坏情况下每个数据包都会增加50微妙的延迟。<br>一个可能的优化手段就是动态地调整批量的大小[32]。<br>另一种情况是当 Maglev 过载时，会增加额外的处理时间。<br>Maglev 能够缓存的最多的数据包的数量依赖于包池的大小。<br>超过的数据包会被网卡丢掉。<br>假设包池的大小为3000，转发器能够处理10Mpps，<br>他需要300微妙来处理所有的缓存的数据包。<br>因此 Maglev 过载严重的情况， 每个数据包最多会增加300微妙的延迟。<br>幸运的是，这种情况可以通过合理的容量规划和增加 Maglev 机器解决。</p><h2 id="3-3-后端选择"><a href="#3-3-后端选择" class="headerlink" title="3.3 后端选择"></a>3.3 后端选择</h2><p>一旦数据包目的符合某个 VIP，我们需要从该VIP的后端池中选择一个合适的后端。<br>对于面向连接的协议，比如 TCP，需要严格地将同一连接的所有后端发送给同一个后端。<br>我们通过两部分策略来实现。<br>首先，我们通过一种新型的一致性哈希算法选择出一个后端，<br>然后我们将这个抉择保存在本地的连接表中。</p><p>Maglev 的连接追踪表使用了固定大小的哈希表映射往后端的数据包的 5 元组哈希值。<br>如果哈希值在表中不存在， Maglev 会选择一个后端，并保存在表中。<br>否则 Maglev 简单的复用之前使用的后端。<br>这个保证了属于同一连接的所有数据包都发给同一个后端，只要后端仍然可以处理数据包。<br>连接追踪在后端变更中迟早有用：比如，当后端可用或者宕机，增加或者移除，或者权重变化。</p><p>然后，每个 Maglev 的连接追踪在我们的分布式环境下是独立的。<br>首先，它假设所有的拥有相同五元组的数据包都发往同一台 Maglev 机器。<br>因为上游的路由器通常不提供连接亲缘性，这个假设在一堆 Maglev 机器发生改变时无法保证。<br>不幸的是，这种改变不可避免同时由于种种原因经常发生。<br>比如，当升级集群中的 Maglev 时，我们轮流重启机器，<br>事先将每一台的流量移开一会儿，然后一旦Maglev 启动在恢复。<br>这个过程可能耗时一个小时，这段时间内，Maglev 的数量持续变化。<br>我们有时也添加、移除或者替代 Maglev 机器。<br>所有这些操作会导致标准的 ECMP 实现在很大范围内洗刷流量，导致连接在不同 的Maglev 中切换。<br>新的 Maglev 并没有正确的连接表项，所有如果此时后端也在变更，会导致连接断开。</p><p>第二种理论上的限制是连接追踪表是有限的，<br>在大压力下或者 SYN Flood 攻击下表容易填满。<br>因为 Maglev 只有在超时的情况才会移除表项，移动表满了，<br>我们需要重新为数据包选择后端。<br>虽然实际中现代的计算机通常有大量的内存，<br>但在部署中，Maglev 和其他服务是共享机器的，我们需要限制连接表的大小。</p><p>如果上述任何一种情况发生，我们没办法依赖单一的连接追踪来处理后端的变更。<br>所以 Maglev 同时提供一致性哈希来确保在上述情况下的包的可靠性传输。</p><h2 id="3-4-一致性哈希"><a href="#3-4-一致性哈希" class="headerlink" title="3.4 一致性哈希"></a>3.4 一致性哈希</h2><p>处理连接追踪的限制的一种可行的方法是在所有机器中共享连接状态，<br>例如利用 [34] 中的分布式哈希表。<br>然后，这种方法的负面影响是影响转发性能 ——<br>撤销连接状态甚至在同一台中的 Maglev 机器都会有竞争。</p><p>一种更高性能的方法是使用本地的一致性哈希。<br>一致性哈希的理论[28] 或者 Rendezvous 哈希[38] 在 1990年代被提出来。<br>它通过生成一张带有每个后端的大的查询表来实现。<br>这种方法提供两种符合 Maglev 复原后端选择的特性：</p><ul><li>负载均衡： 每个后端收到几乎相等的链接</li><li>最小破坏： 当一堆后端出现变更，一条连接几乎被发往同一个后端</li></ul><p>[28] 和 [38] 都是通过负载均衡优先最小打断，他们设计目标为小数量服务优化网页缓存。然后， Maglev 有两个原因 take the opposite approach。<br>首先， Maglev 尽可能地均衡负载到后端的服务非常重要。<br>否则，后端服务必须提供额外的冗余服务来承担峰值流量。<br>Maglev 中，对于某些VIP，可能有数以百计的后端服务与之对应，<br>我们的经验发现 [28] 和 [38] 对于每个 VIP 都需要一个过于庞大的查询表，<br>以满足 Maglev 需要的负载均衡能力。<br>其次，尽管最小化查询表disruptions 非常重要，<br>但那时一小数量的 disruption 对于 Maglev 是可以容忍的。<br>稳定的状态，对查询表的更改不会导致连接重置，因为对连接亲缘的 Maglev 不会同时地改变。<br>当连接亲缘的 Maglev 改变时，对于一定量的查询表破坏会有成比例的重置。</p><p>经过上述的考虑，我们设计了一种新型的一致性哈希算法，我们称之为 <em>Maglev 哈希</em>。<br>Maglev 哈希的基本思想就是给每个后端一个<br>所有查询表位置的优先列表。<br>然后所有的后端轮流填充他们最感兴趣的表中的空白位置，直到整张表都完全填满。<br>因此， Maglev 哈希几乎为每个后端共享了一张查询表。<br>通过更改相应的后端次序的频率可以得到相异的后端权重；<br>这个细节本文并未涉及。</p><p>设 <code>M</code> 为查询表的大小。<br>后端 <code>i</code> 感兴趣的列表存储在 <code>permutation[i]</code> 中，<br><code>permutation[i]</code> 是一个数组 <code>(0, M-1)</code> 的随机排列。<br>一个快速生成 <code>permutation[i]</code> 的方法，<br>每个后端都一个唯一的名字。<br>我们首先用两个不同的哈希方法对这个名字进行哈希，<br>产生两个数字 <code>offset</code> 和 <code>skip</code>。<br>然后使用这些数字产生 <code>permutation[i]</code>：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">offset = h1(name[i]) mod M</span><br><span class="line">skip   = h2(name[i]) mod (M-1)  + 1</span><br><span class="line">permutation[i][j] = (offset + j * skip) mod M</span><br></pre></td></tr></table></figure></p><p><code>M</code> 必须是质数，这样所有 <code>skip</code> 都与之互质。<br>设 <code>N</code> 为一个 VIP 后端池的大小。<br>填充它的查询表的算法如<a href="">伪代码1</a>。<br>我们使用<code>next[i]</code> 来追踪后端 <code>i</code> 的 <code>permulation[i]</code> 中下一个位置，最后的查询表存储在 <code>entry</code> 中。<br>算法外层的 while，我们遍历所有的后端。<br>对于每个后端 <code>i</code> 我们从 <code>permutation[i]</code> 中找到一个候选的索引 <code>c</code>，该位置的查询表还是空的，<br>然后把该位置的填充为后端 <code>i</code>。<br>如此循环直到查询表的所有位置均被填充完毕。</p><p><strong>Pseudocode 1</strong> Populate Maglev hashing loockup table.<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line">function Populate</span><br><span class="line">    for each i &lt; N do next[i] = 0 end for</span><br><span class="line">    for each j &lt; M do entry[j] = -1 end for </span><br><span class="line">    n = 0</span><br><span class="line">    while true do</span><br><span class="line">        for each i &lt; N do</span><br><span class="line">            c = permutation[i][next[i]]</span><br><span class="line">            while entry[c] &gt;= 0 do</span><br><span class="line">                next[i] = next[i] + 1</span><br><span class="line">                c = permutation[i][next[i]]</span><br><span class="line">            end while</span><br><span class="line">            entry[c] = i</span><br><span class="line">            next[i] = next[i] + 1</span><br><span class="line">            n = n + 1</span><br><span class="line">            if n == M then return end if</span><br><span class="line">        end for</span><br><span class="line">    end while</span><br><span class="line">end function</span><br></pre></td></tr></table></figure></p><p>这个算法确保可以终止。<br>最坏情况复杂度为 <code>O(M^2)</code>，<br>当后端数量与查询表大小相当且所有的后端被哈希成相同的 <code>permutation</code>。<br>为了避免这种情况，我们总是选择 <code>M</code> 使 <code>M &gt;&gt; N</code>。<br>平均复杂度为 <code>O(MlogM)</code>，<br>因为步骤 <code>n</code> 我们期望算法尝试 <code>M/(M-n)</code> 步去查找一个空白的候选位置，<br>这样总的查找步数就是 <code>sum(M/n, n = 1...M)</code>。<br>每个后端在查询表中拥有 <code>floor(M/N)</code> 或者 <code>ceil(M/N)</code> 个项。<br>因为查询表中不同后端最多的差异项为1。<br>实际中，我们选择 <code>M</code> 大于 <code>100*N</code>，来确保哈希空间内最多有1%的差异。<br>另外产生随机排列的算法，比如 Fisher-Yates Shuffle[20]，<br>用更多的状态产生更好排列，同样也很有效。</p><p><strong>表 1</strong> 一个一致性查询表的示例</p><table><thead><tr><th>编号</th><th>B0</th><th>B1</th><th>B2 </th></tr></thead><tbody><tr><td>0</td><td>3</td><td>0</td><td>3</td></tr><tr><td>1</td><td>0</td><td>2</td><td>4</td></tr><tr><td>2</td><td>4</td><td>4</td><td>5</td></tr><tr><td>3</td><td>1</td><td>6</td><td>6 </td></tr><tr><td>4</td><td>5</td><td>1</td><td>0</td></tr><tr><td>5</td><td>2</td><td>3</td><td>1</td></tr><tr><td>6</td><td>6</td><td>5</td><td>2</td></tr></tbody></table><p>后端的列表</p><table><thead><tr><th>编号</th><th>Before</th><th>Alfter  </th></tr></thead><tbody><tr><td>0</td><td>B1</td><td>B0</td></tr><tr><td>1</td><td>B0</td><td>B0</td></tr><tr><td>2</td><td>B1</td><td>B0</td></tr><tr><td>3</td><td>B0</td><td>B0</td></tr><tr><td>4</td><td>B2</td><td>B2</td></tr><tr><td>5</td><td>B2</td><td>B2</td></tr><tr><td>6</td><td>B0</td><td>B2</td></tr></tbody></table><p>查询表在 B1 移除前后</p><p>我们使用例子如表1，来展示 Maglev 哈希的工作流程。<br>假设有三个后端：  <code>B0</code>, <code>B1</code>,  <code>B2</code>， 查询表的大小为7，<br>同时<code>(offset, skip)</code> 分别为 (3,4), (0,2), (3,1)。<br>生成排列表为表1的上，查询表在 B1 移除前后的变化如表1的下。<br>如例子所示，查询表在包含/不包含B1的情况下都较均衡。<br>在B1移除之后，除了更新所有包含B1的条目，只要再更新条目6即可。<br>实际应用中，在大的查询标下， Maglev 哈希能fairly的应对后端的变更恢复，见 5.3 章节。</p><h1 id="4-操作经验"><a href="#4-操作经验" class="headerlink" title="4. 操作经验"></a>4. 操作经验</h1><p>Maglev 作为一个高度复杂的分布式系统，已经在 Google 服役了6年。<br>在全球范围的运作中，我们学到了很多经验。<br>本章描述了这些年在适应我们需求的变更中 Maglev 的进化过程，<br>以及一些用来监控调试系统的工具。</p><h2 id="4-1-Maglev-的进化"><a href="#4-1-Maglev-的进化" class="headerlink" title="4.1 Maglev 的进化"></a>4.1 Maglev 的进化</h2><p>今天的 Maglev 和原始的系统已经有诸多的不同。<br>许多的变化，例如 IPv6 的支持，因为是可扩展的软件架构使变化非常平滑。<br>本节谈论了两个自诞生以来的实现和部署的最大变化。</p><h3 id="4-1-1-故障恢复"><a href="#4-1-1-故障恢复" class="headerlink" title="4.1.1 故障恢复"></a>4.1.1 故障恢复</h3><p>最早的 Maglev 机器成对地部署以应对故障恢复能力，<br>就如同被他们替代的硬件负载均衡器。<br>通常情况下只有活跃的机器才提供服务。<br>当活跃的机器变成不健康时，它的备机就会开始服务。<br>得益于 Maglev 哈希，这一过程通常不会造成连接中断，<br>但是这样部署有一些弊端。<br>首先浪费资源，它总是有一般的机器处于空闲状态。<br>同时单台机器的能力也阻碍我们扩展任何的 VIP。<br>最后，协调活跃和备份的机器也很复杂。<br>这种部署中，机器的宣告者会监控彼此的健康度和服务优先级，<br>在失去对方的时候提升自己BGP的优先级及其他多种机制。</p><p>在迁移到 ECMP 模型之后我们得到一大容量、效率以及操作便利上的益处。<br>同时 Maglev 哈希继续保护我们应对偶尔的 ECMP 抖动，<br>我们可以最大化路由的 ECMP 大小成倍地提升一个VIP的容量，<br>同时所有的机器都能被充分利用。</p><h3 id="4-1-2-包处理过程"><a href="#4-1-2-包处理过程" class="headerlink" title="4.1.2 包处理过程"></a>4.1.2 包处理过程</h3><p>原来 Maglev 使用的 Linux 内核协议栈处理包。<br>必须通过内核socket 与网卡交互，<br>这会因为硬件中断和软件中断、上下文切换、系统调用[26]等给处理过程带来很大的负担。<br>每个包必须从内核态拷贝到用户态，处理完再拷贝回去，也增加了很多负担。<br>Maglev 并不需要 TCP/IP 栈，只需要为每个包寻找一个合适的后端以及用 GRE 封包即可。<br>因此我们利用了 bypass kernel 的机制之后，在不削减功能的情况下<br>极大地改善了性能 —— 每台 Maglev 机器的吞吐量提高了 5 倍。</p><h3 id="4-2-VIP-匹配"><a href="#4-2-VIP-匹配" class="headerlink" title="4.2 VIP 匹配"></a>4.2 VIP 匹配</h3><p>Google 生产环境的网络，每个集群都给一个外网 IP 的前缀用来全球路由。<br>例如， 如图6， 对于集群C1 拥有 74.125.137.0/24 的前缀。<br>一个相同的服务在另外一个集群配置了另外的VIP，<br>用户通过 DNS 来访问他们。<br>例如，Service1 在 C1中配置为 74.125.137.1, C2中为 173.194.71.1。</p><p> <img src="/assets/img/maglev/cbe69316-d0fd-469a-9692-95948f0cfb51.jpg" alt="Alt pic"> </p><p>Google 拥有很多集群的级别，服务的不同的 VIP。<br>同一个级别的集群拥有相同的前缀长度，但是不同级别的集群长度可能不一样。<br>有时紧急情况下，我们需要利用 Maglev 封包将流量重定向到其他的集群中。<br>因此，我们需要目标 Maglev 能够正确识别从任意其他集群来的流量。<br>一种可行的方案是在所有可能收到重定向流量的集群中定义所有 VIP，<br>但是会有同步和可扩展性的问题。</p><p>取而代之，我们实现了一个特殊的编号规则和一个特别的 VIP 匹配机制来解决这个问题。<br>对于每个集群级别，我们赋予每个 VIP 相同的后缀(所有当前相同级别的集群都一致)。<br>然后我们使用一个前缀/后缀匹配机制来匹配 VIP。<br>首先，进来的包经过最长前缀匹配，以决定目标是哪个集群级别。<br>然后在特定集群级别中，经过最长后缀匹配决定那个后端池。<br>为了减少在严格时间尺度下需要全局同步的配置量，<br>拥有相同前缀的同级别新集群创建是，我们在 Maglev 预先配置了相应集群级别足够的前缀组.<br>这样 Maglev 可以正确的处理原始目的是陌生集群的重定向流量。</p><p>结果，每个 VIP 都会配置为 <prefix group,="" ip="" suffix,="" port,="" protocol=""> 的元组。<br>例如图6，假设集群 C2 和 C3 同属于一个级别，<br>如果一个被C2接收到的数据包目的是 173.194.71.1，<br>但是C2 的 Maglev 并无法确认可服务的后端时，<br>它会封包之后，透过隧道传给 C3 相同服务的 VIP(173.194.72.1)。<br>然后 C3 的 Maglev 解包之后用前缀/后缀匹配包内的 VIP 得到是传给 Service1 的,<br>然后数据包被 C3 的后端正确处理。</prefix></p><p>这个 VIP 匹配机制是为 Google 生产环境部署特定的，<br>但是它为软件负载均衡器提供了一种用于快速原型匹配和迭代的良好范例。</p><h2 id="4-3-分片处理"><a href="#4-3-分片处理" class="headerlink" title="4.3 分片处理"></a>4.3 分片处理</h2><p>截至目前，本文还未涉及到 IP 分片。<br>分片处理需要特别的技巧，因为 Maglev 为大部分 VIP 提供的是五元组哈希，<br>但是分片信息并不包含五元组所需的全部信息。<br>例如，一个大的报文被分成两个分片，<br>第一个分片包含 L3 和 L4 的头，但是第二个分片只包含 L3 的头。<br>因此当 Maglev 接收到非首个的分片时，它并没有办法单纯依据包头来正确决定如何转发。</p><p>为了正确处理分片，Maglev 必须符合两个要求。<br>首先，所有相同数据报文的分片必须被路由到同一台 Maglev 上。<br>其次，Maglev 必须能为非分片、首个分片和非首个分片选择同一个后端。</p><p>通常，我们并不能依赖 Maglev 前面的硬件设备来满足第一个条件。<br>例如，有些路由器为首个分片做五元组哈希但是为非首分片做三元组哈希。<br>我们因此需要在 Maglev 中实现一个通用的满足任何分片哈希行为的解决方案。<br>每个 Maglev 配置了一个特殊的后端池，包含所有的 Maglev 机器。<br>一旦接收到首个分片， Maglev 用 L3 的头计算三元组哈希，<br>然后根据哈希值选择特定的 Maglev 作为后端进行转发。<br>因为所有属于相同报文的分片总是有相同的三元组，<br>能够保证他们都被重定向给相同的 Maglev。<br>我们使用 GRE recusion control 字段，确保分片只能被重定向一次。</p><p>为了满足第二个条件， Maglev 为未分片数据包和第二跳的首分片(通常在不同的 Maglev 实例上) 使用相同的后端决策算法。<br>它维护了一个固定大小的分片表，记录了首分片的转发决策。<br>当同一台 Maglev 收到一个第二跳非首分片，<br>会从分片表中查找，若匹配则立即转发；<br>否则，会缓存到分片表中，直到首分片收到或者老化。</p><p>这种方法有两种限制：<br>首先导致分片被额外传输一次，有可能会导致数据包乱序。<br>另外需要额外的内存来缓存非首分片。<br>因为网络中任何地方都可能导致包乱序，<br>我们需要依赖后端来处理乱序包。<br>实际中一个极少数 VIP 允许分片报文，<br>我们很容易就能提供一个足够大的分片表来处理这些。</p><h2 id="4-4-监控和调试"><a href="#4-4-监控和调试" class="headerlink" title="4.4 监控和调试"></a>4.4 监控和调试</h2><p>和监控其他生产系统一样，我们监控每个 Maglev 机器的健康程度和行为。<br>例如，我们使用了黑盒监控和白盒监控。<br>我们的黑盒监控包含遍布全世界的 Agent，周期性地检查 VIP 的可访问性和<br>延迟。<br>对于白盒监控，每个 Maglev 都会利用 HTTP Server 导出一些指标，<br>然后监控系统周期性的拉取并计算服务状态信息。<br>当出现异常行为时监控系统会发报警。</p><p>由于 Maglev 的分布式特性，从路由器到 Maglev 到服务存在着多条路径。<br>但是，调试时，我们能够用特定的数据包来识别具体的路径。<br>因此我们开发了 packet-tracer，类似于 X-Trace[21]。<br>Packet-tracer 构造和发送特殊的 Maglev 能够识别的三层和四层的数据包。<br>数据包内容包含需要 Maglev 发送调试信息的接收者的 IP。<br>数据包的目的通常是一个特殊的 VIP，可能被正确地路由到我们的前端集群。<br>当 Maglev 接收到 Packet-tracer 的数据包时，它会照常转发，但是同时会把<br>包含当前机器名、选择的后端等调试信息发送给数据包指定的接收者。<br>Packet-tracer 数据包会被 Maglev 限速，因此他们处理比较耗时。<br>这个工具在调试生产环境的问题非常管用，<br>特别是发生分片时有多台 Maglev 在链路中。</p><h1 id="5-评估"><a href="#5-评估" class="headerlink" title="5. 评估"></a>5. 评估</h1><p>本章我们评估了 Maglev 的效率和性能。<br>我们展示了某个 Google 生产集群以及一些微基准测试的评估结果。</p><h2 id="5-1-负载均衡"><a href="#5-1-负载均衡" class="headerlink" title="5.1 负载均衡"></a>5.1 负载均衡</h2><p>作为一个网络负载均衡器， Maglev 的主要职责就是把流量均衡到多台后端服务上。<br>为了展示 maglev 的负载均衡的性能，<br>我们收集了一个位于欧洲集群的 458 个 endpoint 的 cps (Connections Per Second)。<br>这个数据是多个HTTP服务的聚合，包含搜索服务。<br>数据收集粒度为5分钟，负载用每天的平均 cps 标准化。图7 显示了某天所有 endpoint 的负载的平均值和标准差。<br>流量负载的显示了一天的趋势。相对于平均负载，标准差一直都很小，变异系数大多数时间在 6% ~ 7%之间。</p><p> <img src="/assets/img/maglev/84c97589-6f51-4e76-817b-b176a0411f89.jpg" alt="Alt pic"> </p><p>图7同时显示了每个时间点最高负载与平均负载的冗余系数。<br>冗余系数非常重要，我们总是要确保最繁忙的节点有足够的能力处理所有流量。<br>冗余系数在 60% 的时间段小于 1.2。<br>在非峰荷时段冗余系数比较高，这是合理的，<br>因为低流量时比较难以平衡负载。<br>另外，非峰荷时段高冗余系数也不需要额外的 Maglev 机器。</p><h2 id="5-2-单机吞吐量"><a href="#5-2-单机吞吐量" class="headerlink" title="5.2 单机吞吐量"></a>5.2 单机吞吐量</h2><p>因为每台 Maglev 机器通过 ECMP 收到差不多的流量，<br>总的吞吐量的估算可以通过机器数量乘以单机吞吐量简单计算得到。<br>单机承担的能力越高，所需要的机器就越少。<br>因此单机吞吐量是整个系统效率的关键。</p><p>Maglev 单机的吞吐量受很多因素的影响，包括处理线程的个数、<br>网卡速度、流量类型等。<br>本节我们在一系列条件下透过一小个试验台来评估单台 Maglev 处理数据包的能力。<br>除非特别说明，所有的实验机器均为以下配置：<br>两个当前服务端的8核CPU，1个万兆网卡和 128GB 内存。<br>我们只给 Maglev 使用1个CPU，其他的包含操作系统，在另外一个CPU上运行。<br>实验台包含位于同一个以太网域内的两个发送端、两个接收端和1台Maglev机器。<br>发送端缓慢地增加发送速率，<br>同时记录Maglev 处理的 pps，记录最大值和何时开始丢包。<br>我们使用两个发送端是为了确保 Maglev 能够过载。</p><h3 id="5-2-1-Kernel-Bypass"><a href="#5-2-1-Kernel-Bypass" class="headerlink" title="5.2.1 Kernel Bypass"></a>5.2.1 Kernel Bypass</h3><p>试验中，我们让 Maglev 跑在 Linux 主线版本内核(即 vanilla kernel)协议栈和跑在 Kernel bypass 模式下，<br>对比 Maglev 的吞吐量。<br>发送端从不同的源端口发送最小的UDP包，以确保 Maglev 的 Steering<br>模块中不会被转给一个处理线程处理。<br>由于测试环境的限制，最小的 UDP包大小为 52 字节，略大于理论上的以太网内最小包大小。<br>同时也更改线程的数量，每个线程绑到固定的核上（与生产环境一致）以保证性能。<br>我们用了1个核来处理 Steering 和 Muxing，因此最多有7个工作线程。<br>包含和不包含 Kernel bypass 的测试结果见图8.</p><p> <img src="/assets/img/maglev/cd73a348-3ac6-4581-9509-a87cf75376a0.jpg" alt="Alt pic"> </p><p>图中显示 Maglev 在 Kernel Bypass 下拥有明显的性能优势。在不超过4个线程时， Maglev 是瓶颈，吞吐量随线程数线性增长。<br>当超过4个线程时，网卡成为了瓶颈。<br>另一方面，在用协议栈时， Maglev 总是瓶颈，能达到的最大吞吐量只有 Kernel Bypass 的 30%不到。</p><h3 id="5-2-2-流量类型"><a href="#5-2-2-流量类型" class="headerlink" title="5.2.2 流量类型"></a>5.2.2 流量类型</h3><p>依据处理线程中的代码执行路径， Maglev 处理不同类型流量的速度有所差别。<br>比如，一个线程需要为 TCP 的SYN包 选择一个后端并记录到连接追踪表中，<br>对于非 SYN 包只需要查表即可。<br>本节测试中，我们测试 Maglev 处理不同 TCP 类型包能力。</p><p>有三种类型需要考虑： SYN、非SYN以及固定五元组。<br>对于SYN和非SYN 实验，只发送 SYN 和 非 SYN 包。<br>SYN 包实验显示 Maglev 在应对 SYN Flood 时的表现，<br>非 SYN 包显示 Maglev 在处理常规 TCP 流量的表现。<br>对于固定五元组的实验，所有数据包包含相同三层和四层的头，<br>这个特殊的用例是因为 Steering 模块通常尝试将相同的五元组指派给同一个线程处理，<br>只有当目标线程的处理队列满了之后才会指派给其他线程。<br>发送SYN和非SYN 发送端变换不同的源端口来产生不同的五元组，<br>但是对于固定五元组，则使用固定的端口。<br>这些实验总是发送最小的 TCP 包 —— 即 64 字节。</p><p> <img src="/assets/img/maglev/ecf106d0-185f-4e64-9f9b-d50d869a3ba6.jpg" alt="Alt pic"> </p><p>如图9， 这些试验中，在非 SYN 和固定五元组中， 5个处理线程就达到网卡的极限。<br>但是对于 SYN 包， Maglev 需要 6 个线程才能跑满网卡。<br>因为 Maglev 需要为每个 SYN 选择一个后端。<br>Maglev 在固定五元组也拥有很高的性能，表明 Steering 模块<br>可以高效地处理非离散的数据包。<br>因为所有的包拥有相同的五元组，那么他们连接追踪表的信息总是在 CPU Cache中，<br>保证了最高的吞吐量。<br>对于非 SYN 包，表查找过程由不时地Cache miss，因此在5线程以内，性能略低于固定五元组。</p><h3 id="5-2-3-网卡速度"><a href="#5-2-3-网卡速度" class="headerlink" title="5.2.3 网卡速度"></a>5.2.3 网卡速度</h3><p>在前面的试验中， 网卡在5个线程时就跑满了。<br>为了测出 Maglev 的所有能力，这个实验使用了更快的网卡来评估吞吐量。<br>为此我们使用了 40Gbps 网卡代替10Gbps，然后与 5.2.1 节一样的测试环境。<br>结果见图10。当不超过5线程时， 40Gbps网卡只能略高于10Gbps网卡，因为40 Gbps的芯片比 10Gbps好。<br>但是对于40Gbps，当先线程到7个时，吞吐量的增长率没有下降。<br>因为网卡不再是瓶颈，这张图显示了Maglev在当前硬件条件下的性能极限——略高于 15Mbps。<br>实际上，瓶颈是 Maglev 的Steering 模块，未来切换到40Gbps网卡时我们会继续优化。</p><p> <img src="/assets/img/maglev/4d4244e8-cd4d-4d82-98d5-a80180f885d4.jpg" alt="Alt pic"> </p><h2 id="5-3-一致性哈希"><a href="#5-3-一致性哈希" class="headerlink" title="5.3 一致性哈希"></a>5.3 一致性哈希</h2><p>这个实验中我们对比评估 <em>Karger</em>[28]、 <em>Rendezvous</em>[38] 哈希和 Maglev 哈希的性能。<br>我们关注两个指标： 负载均衡的效率和后端变更的恢复能力。</p><p>为了评估这些方法的效率，我们用每个方法构建查询表，然后统表计设置后端实例的条目数。<br>我们设定后端数目为1000个，查询表的大小为65537和655373。<br>对于 Karger 我们设定视图数目为1000。<br>图11展示了每种方法的表大小、每个后端的最小和最大条目比例。</p><p> <img src="/assets/img/maglev/5b99a425-e144-4baa-bd73-6287b409003f.jpg" alt="Alt pic"> </p><p>正如期望的，无论表达小如何，Maglev 哈希提供了几乎完美的负载均衡特性。<br>当表大小为65537时， Karger 和 Rendezvous 为了应对不平衡的流量，需要后端的冗余分别达到29.7%和49.5%。<br>当表大小为655373 是，数目降为 10.3% 和 12.3%。<br>因为每个VIP都需要查询表，因此需要控制表大小。<br>因此 Karger 和 Rendezvous 并不能满足 Maglev 负载均衡需求。</p><p>另一个重要的指标是一致性哈希应对后端变化的应对能力。<br>Karger 和 Rendezvous 保证当某些后端失效， 剩余的后端均不会有影响。<br>因此我们只需要评估 Maglev 哈希这个指标即可。<br>图12 展示了不同比例后端失效的情况，表中需要变化的条目个数。<br>我们同样设定后端数目为1000. 对于每个失败数 <code>k</code>， 我们随机从池中移除 <code>k</code> 个后端，<br>然后重新生成表并计算表变更的数目。<br>对于每个 k，我们重复了 200 次实验，然后计算平均值。</p><p> <img src="/assets/img/maglev/a338aa2f-df9b-4973-857f-305c70e6ed9f.jpg" alt="Alt pic"> </p><p>图12 展示随着同时失败数目的增加，需要变更条目数目的比例也逐步增加。<br>Maglev 哈希在表大小更大的情况应对恢复的能给力越好。<br>实际应用中我们使用了 65537 作为表的默认大小因为我们发现同时失败的后端数目非常少见。<br>同时我们还有连接追踪做保证。<br>另外，微基准测试表明，查询表生成时间在表大小从65537到655373时，从1.8ms增长到22.9ms，这也限制了我们无节制增加表大小。</p><h1 id="6-相关工作"><a href="#6-相关工作" class="headerlink" title="6. 相关工作"></a>6. 相关工作</h1><p>不像传统的硬件负载均衡器[1,2,3,5,9,12,13]， Maglev 是一个运行在通用服务器上的分布式软件系统。<br>硬件负载均衡器通常需要以主备的形式成对部署。<br>Maglev 以多主的形式更加高效和更富有弹性。<br>而且，升级硬件负载均衡器的能力需要额外的购买机器<br>以及物理部署，使得按需调整能力更加困难。<br>但是，Maglev 的能力可以简单地通过增加和减少 Maglev 节点<br>进行调节，而无须中断服务。<br>有些硬件服务商也提供了虚拟化环境的负载均衡软件，但Maglev 相比较拥有更高的吞吐量。</p><p>Ananta[34] 是一个分布式的软件负载均衡器，与 Maglev 类似，<br>它也是通过 ECMP 来扩容，以及使用一个流表来获得连接亲缘性。<br>然后，它并没有提供具体的机制来柔性处理负载均衡池的变更，<br>同时它也没有特别优化单机性能。<br>Maglev 没有提供类似 Ananta HostAgent 这种 NAT 服务，<br>但是有一个外部系统(本文并未涉及)来达到类似功能。<br>Ananta 允许最多内部VIP 流量绕过负载均衡器，<br>Maglev 没有提供此功能是因为本身已经拥有足够的能力处理内部流量。<br>Embrane[4] 是一个为虚拟环境开发的类似系统。<br>但是它吞吐量优化受限于虚拟环境的限制。<br>Duet[22] 是一个硬件和软件的混合负载均衡器，旨在解决纯软的低吞吐量问题。<br>Maglev 有可能达到较高的性能，因此混合模式变得没有必要。</p><p>还有许许多多通用负载均衡软件包，最流行的如 NGINX[14]、 HAProxy[7] 以及 LVS[11]。<br>他们通常运行在单机上，但是也可以通过 ECMP 组来多机部署，达到横向扩展的能力。<br>他们都提供一致性哈希的机制。<br>与 Maglev 相比，他们就如同 [28] 和 [38] 一样，最小打断优先于公平负载均衡。<br>因为他们的设计目标是可移植性，所以并没有花大力气优化性能。</p><p>一致性哈希[28] 和 Rendezvous 哈希 [28] 提出的原始目的是为了协调分布式缓存。<br>两种方法都能保证回弹能力，即当某些后端移除，只有这些后端相关的条目会被更新。<br>但是他们并没有很好的提供对LB来说非常重要的负载均衡性。<br>相对的， Maglev 一致性哈希方法能够达到完美的均衡以及很少的回弹代价，<br>实际中也很好的与连接追踪结合。<br>另一种实现一致性哈希的方法是分布式哈希，类似于 Chord[37]，<br>但是这会给系统带来额外的延迟和复杂度。</p><p>Maglev 中一些性能优化手段从上个世纪90年代已经出现。<br>Smith 等[36] 建议通过减少中断和内存拷贝来提供吞吐量。<br>Mogul 等[33] 开发了基于轮询机制来避免收到中断产生的活锁。<br>Edwards 等[19] 探寻了在用户态处理网络的方法，但是并没有完全绕过内核。<br>Marinos 等[31] 显示绕过内核的专门的用户态协议栈能够显著地提高应用的吞吐量。<br>Hanford 等[25] 提出跨多个CPU 核分发包处理，提高 CPU 缓存命中率。<br>CuckooSwitch [41] 是一个高性能2层软件交换机。<br>它的一个核心技术就是通过批量处理和预取的方式降低内存访问延迟。<br>RouteBricks[18] 解释了如何通过并行处理包来高效地利用多核CPU。</p><p>最近业界有一些内核旁路的技术，包括 DPDK[8]、 OpenOnload[15]、netmap[35] 以及<br>PF_RING[17] 等。<br>[10] 是对这些流量的内核旁路方案技术的良好总结。<br>这些技术可以非常有效地提高包处理速度，但是他们都有局限性。<br>例如 DPDK 和 OpenOnload 都与具体网卡型号/提供商绑定，<br>netmap 和 PF_RING 都需要修改 Linux 内核。<br>在 Maglev 中，我们实现了一个灵活的 I/O 层，让我们无须修改内核并能够方便地切换不同的网卡。<br>像其他技术， 一旦 Maglev 启动之后，它会接管网卡，然后使用 TAP 设备将数据包注回内核。</p><p>最近，GPU 在高速包处理中越来越流行[24, 39]。<br>但是， Kalia 等[27] 最近发现基于 CPU 的解决方案也能达到类似的性能，<br>而且在正确实现的情况下资源利用更高效。 </p><h1 id="7-结论"><a href="#7-结论" class="headerlink" title="7. 结论"></a>7. 结论</h1><p>本文展示了 Maglev, 一个高效、可靠、可扩展和灵活的软件网络负载均衡器。<br>我们通过 ECMP 来横向扩展 Maglev，同时每台机器都能在万兆网卡下达到线速，<br>在高速增长的业务需求下提供划算的性能。<br>我们结合连接追踪和 Maglev 哈希，将相同的连接映射到同一个后端。<br>多年来大规模地应用让我们高效地把控网站，<br>以及在需求增长或者未来新需求下快速反应。</p><h1 id="致谢"><a href="#致谢" class="headerlink" title="致谢"></a>致谢</h1><p>略</p><h1 id="引用"><a href="#引用" class="headerlink" title="引用"></a>引用</h1><ul><li>[1] A10. <a href="http://www.a10networks.com" target="_blank" rel="noopener">http://www.a10networks.com</a>.</li><li>[2] Array networks. <a href="http://www.arraynetworks.com" target="_blank" rel="noopener">http://www.arraynetworks.com</a>.</li><li>[3] Barracuda. <a href="http://www.barracuda.com" target="_blank" rel="noopener">http://www.barracuda.com</a>.</li><li>[4] Embrane. <a href="http://www.embrane.com" target="_blank" rel="noopener">http://www.embrane.com</a>.</li><li>[5] F5. <a href="http://www.f5.com" target="_blank" rel="noopener">http://www.f5.com</a>.</li><li>[6] Google cloud platform. <a href="http://cloud.google.com" target="_blank" rel="noopener">http://cloud.google.com</a>.</li><li>[7] Haproxy. <a href="http://www.haproxy.org" target="_blank" rel="noopener">http://www.haproxy.org</a>.</li><li>[8] Intel dpdk. <a href="http://www.dpdk.org" target="_blank" rel="noopener">http://www.dpdk.org</a>.</li><li>[9] Kemp. <a href="http://www.kemptechnologies.com" target="_blank" rel="noopener">http://www.kemptechnologies.com</a>.</li><li>[10] Kernel bypass. <a href="http://blog.cloudflare.com/kernel-bypass" target="_blank" rel="noopener">http://blog.cloudflare.com/kernel-bypass</a>.</li><li>[11] Linux virtual server. <a href="http://www.linuxvirtualserver.org" target="_blank" rel="noopener">http://www.linuxvirtualserver.org</a>.</li><li>[12] Load balancer .org. <a href="http://www.loadbalancer.org" target="_blank" rel="noopener">http://www.loadbalancer.org</a>.</li><li>[13] Netscaler. <a href="http://www.citrix.com" target="_blank" rel="noopener">http://www.citrix.com</a>.</li><li>[14] Nginx. <a href="http://www.nginx.org" target="_blank" rel="noopener">http://www.nginx.org</a>.</li><li>[15] Openonload. <a href="http://www.openonload.org" target="_blank" rel="noopener">http://www.openonload.org</a>.</li><li>[16] F. Chen, R. K. Sitaraman, and M. Torres. End-user mapping:<br>Next generation request routing for content delivery. In Proceedings<br>of SIGCOMM, 2015.</li><li>[17] L. Deri. Improving passive packet capture: Beyond device<br>polling. In Proceedings of SANE, 2004.</li><li>[18] M. Dobrescu, N. Egi, K. Argyraki, B.-G. Chun, K. Fall, G. Iannaccone,<br>A. Knies, M. Manesh, and S. Ratnasamy. Routebricks:<br>Exploiting parallelism to scale software routers. In Proceedings<br>of SOSP, 2009.</li><li>[19] A. Edwards and S. Muir. Experiences implementing a high performance<br>tcp in user-space. In Proceedings of SIGCOMM, 1995.</li><li>[20] R. A. Fisher and F. Yates. Statistical tables for biological, agricultural<br>and medical research. Edinburgh: Oliver and Boyd,1963.</li><li>[21] R. Fonseca, G. Porter, R. H. Katz, S. Shenker, and I. Stoica. Xtrace:<br>A pervasive network tracing framework. In Proceedings of<br>NSDI, 2007.</li><li>[22] R. Gandhi, H. H. Liu, Y. C. Hu, G. Lu, J. Padhye, L. Yuan, and<br>M. Zhang. Duet: Cloud scale load balancing with hardware and<br>software. In Proceedings of SIGCOMM, 2014.</li><li>[23] P. Gill, N. Jain, and N. Nagappan. Understanding network failures<br>in data centers: Measurement, analysis, and implications. In<br>Proceedings of SIGCOMM, 2011.</li><li>[24] S. Han, K. Jang, K. Park, and S. Moon. Packetshader: A gpuaccelerated<br>software router. In Proceedings of SIGCOMM, 2010.</li><li>[25] N. Hanford, V. Ahuja, M. Balman, M. K. Farrens, D. Ghosal,<br>E. Pouyoul, and B. Tierney. Characterizing the impact of endsystem<br>affinities on the end-to-end performance of high-speed<br>flows. In Proceedings of NDM, 2013.</li><li>[26] V. Jacobson and B. Felderman. Speeding up networking.<br><a href="http://www.lemis.com/grog/Documentation/vj/lca06vj.pdf" target="_blank" rel="noopener">http://www.lemis.com/grog/Documentation/vj/lca06vj.pdf</a>.</li><li>[27] A. Kalia, D. Zhou, M. Kaminsky, and D. G. Andersen. Raising<br>the bar for using gpus in software packet processing. In Proceedings<br>of NSDI, 2015.</li><li>[28] D. Karger, E. Lehman, T. Leighton, R. Panigrahy, M. Levine,<br>and D. Lewin. Consistent hashing and random trees: Distributed<br>caching protocols for relieving hot spots on the world wide web.<br>In Proceedings of ACM Symposium on Theory of Computing,1997.</li><li>[29] C. Labovitz. Google sets new internet record.<br><a href="http://www.deepfield.com/2013/07/google-sets-new-internetrecord/" target="_blank" rel="noopener">http://www.deepfield.com/2013/07/google-sets-new-internetrecord/</a>.</li><li>[30] C. Labovitz, S. Iekel-Johnson, D. McPherson, J. Oberheide, and<br>F. Jahanian. Internet inter-domain traffic. In Proceedings of SIGCOMM,2010.</li><li>[31] I. Marinos, R. N. Watson, and M. Handley. Network stack specialization<br>for performance. In Proceedings of SIGCOMM, 2014.</li><li>[32] J. C. McCullough, J. Dunagan, A. Wolman, and A. C. Snoeren.<br>Stout: An adaptive interface to scalable cloud storage. In Proceedings<br>of USENIX ATC, 2010.</li><li>[33] J. C. Mogul and K. K. Ramakrishnan. Eliminating receive livelock<br>in an interrupt-driven kernel. In Proceedings of USENIX<br>ATC, 1996.</li><li>[34] P. Patel, D. Bansal, L. Yuan, A. Murthy, A. Greenberg, D. A.<br>Maltz, R. Kern, H. Kumar, M. Zikos, H. Wu, C. Kim, and<br>N. Karri. Ananta: Cloud scale load balancing. In Proceedings<br>of SIGCOMM, 2013.</li><li>[35] L. Rizzo. netmap: A novel framework for fast packet i/o. In<br>Proceedings of USENIX Security, 2012.</li><li>[36] J. Smith and C. Traw. Giving applications access to gb/s networking.<br>Network, IEEE, 7(4):44–52, 1993.</li><li>[37] I. Stoica, R. Morris, D. Karger, M. F. Kaashoek, and H. Balakrishnan.<br>Chord: A scalable peer-to-peer lookup service for internet<br>applications. In Proceedings of SIGCOMM, 2001.</li><li>[38] D. G. Thaler and C. V. Ravishankar. Using name-based mappings<br>to increase hit rates. IEEE/ACM Transactions on Networking,<br>6(1):1–14, 1998.</li><li>[39] M. Varvello, R. Laufer, F. Zhang, and T. Lakshman. Multi-layer<br>packet classification with graphics processing units. In Proceedings<br>of CoNEXT, 2014.</li><li>[40] K. V. Vishwanath and N. Nagappan. Characterizing cloud computing<br>hardware reliability. In Proceedings of SoCC, 2010.</li><li>[41] D. Zhou, B. Fan, H. Lim, M. Kaminsky, and D. G. Andersen.<br>Scalable, high performance ethernet forwarding with cuckooswitch.<br>In Proceedings of CoNEXT, 2013.</li></ul>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;[缘由]： 本文是 google 在今年NSDI上一篇会议论文，介绍他们运行了8年的负责全球业务的负载均衡服务 Maglev。从文中可以看到 Maglev 中使用的技术，例如 ECMP、BGP、GRE、Kernel Bypass、一致性哈希等都是常见且成熟的技术方案，但他们
      
    
    </summary>
    
    
      <category term="tech" scheme="https://blog.gobyoung.com/tags/tech/"/>
    
  </entry>
  
  <entry>
    <title>可扩展交换性原则：多核多处理下可扩展性软件开发</title>
    <link href="https://blog.gobyoung.com/2015/commutativity-sosp13/"/>
    <id>https://blog.gobyoung.com/2015/commutativity-sosp13/</id>
    <published>2015-12-21T11:53:53.000Z</published>
    <updated>2018-03-18T07:49:33.203Z</updated>
    
    <content type="html"><![CDATA[<p>原文：<br><a href="http://web.mit.edu/amdragon/www/pubs/commutativity-sosp13.pdf" target="_blank" rel="noopener">http://web.mit.edu/amdragon/www/pubs/commutativity-sosp13.pdf</a></p><p>MorningPaper：<br><a href="http://blog.acolyer.org/2015/04/24/the-scalable-commutativity-rule-designing-scalable-software-for-multicore-processors/" target="_blank" rel="noopener">http://blog.acolyer.org/2015/04/24/the-scalable-commutativity-rule-designing-scalable-software-for-multicore-processors/</a></p><p>不管何种实现，API的设计方式都是对系统可扩展性影响最大的因素（深以为然，之前BOSS<br>让我一定要慎重考虑API的设计，我还不觉得什么，后来又说系统无状态化，才发觉API设计<br>的重要性）。<strong>Clements 等人</strong>定义的可扩展交换性原则：COMMUTER 就可以指导我们如<br>何设计API。一个例子就是根据他们的API设计规范来设计，18个文件系统的POSIX相关调用<br>都能显著地提高可扩展性。</p><p>Colyer认为需要的工作是：</p><p> a. 关注API设计在可扩展性的影响，相对应的是技术实现和后期优化<br> b. 并不是所有调用都是频繁的，因此关注于每个调用执行边界</p><p>首先作者贴了这么一段引文：</p><blockquote><p>At the core of our approach is this scalable commutativity rule:<br>In any situation where several operations commute—meaning there’s<br>no way to distinguish their execution order using the interface—they<br>have an implementation whose memory accesses are conflict-free<br>during those operations. Or, more concisely, whenever interface<br>operations commute, they can be implemented in a way that scales.</p></blockquote><p>也就是说，任何情况下多个操作Commute（不是很明白怎么直接翻译，交互？意思是使用接口<br>不会混淆他们的执行顺序），那么他们的内存操作必须是无冲突的。</p><p>他们提出了一个原则：SIM – State dependent, Interface-based, Monotonic，即<br>状态独立、基于接口且单调的（Not very clear）。</p><blockquote><p>When operations commute in the context of a specific system state,<br>specific operation arguments, and specific concurrent operations,<br>we show that an implementation exists that is conflict-free for<br>that state and those arguments and concurrent operations. This<br>exposes many more opportunities to apply the rule to real<br>interfaces—and thus discover scalable implementations—than a<br>more conventional notion of commutativity would.</p></blockquote><p>意思是，如果操作有一个特定系统状态、特定操作参数、特定并发指令的上下文，那么作者<br>也能够利用这些原则去实现一个状态/参数/并发无冲突的实现。</p><p>比如对于unix 系统调用，很少有无条件的调用：<code>getpid()</code>是一个这种例子。而其他大<br>部分则是与状态参数相关的，比如调用 <code>open(&quot;a&quot;, O_CREATE|O_EXCL)</code> 在不同工作<br>路径下调用则结果不同。</p><p>COMMUTER 工具能够用一个接口模型，能够限定一系列操作下的精确条件。“该工具能够集成<br>到开发过程中，用来驱动最初设计与实现、或者改进现有实现、或者帮助开发者更好地理解接<br>口的交换性”。可以说，不同线程内存访问的无冲突化是可扩展性的途径。</p><h2 id="COMMUTER"><a href="#COMMUTER" class="headerlink" title="COMMUTER"></a>COMMUTER</h2><p>用户可以利用COMMUTER的组件 ANALYZER，依据接口的参数和状态生成一系列表达式，这些<br>表达式可以直接通过 TESTGEN 转化成实际的测试用例。</p><p>为了形象的表达他们的工作，他们介绍了一种新的标记– 冲突覆盖率。冲突覆盖率描述的是<br>在共有数据接口下的所有可能的模式调用。例如对于 18 个POSIX系统调用， TESTGEN<br>生成 13664 个测试用例，用来查找 Linux ramfs 文件系统的虚拟内存系统的可扩展性问题。</p><p>MTRACE 用一个修改过的 qemu 和 Linux内核的虚拟机运行这些测试用例，检查无冲突下各个<br>实现的冲突覆盖率。</p><p>![fig-5:test result][sosp]<br>[sosp]: [[!!images/sosp/sosp1.png]] “Test result of the paper by COMMUTER”</p><p>作者的实现： <a href="http://pdos.csail.mit.edu/commuter" target="_blank" rel="noopener">http://pdos.csail.mit.edu/commuter</a></p><p>最后总结出的4条设计可交换接口的Guideline（<strong>完完全全不理解</strong>）：</p><ol><li>组件拆分，每个操作制作一件事情。比如 <code>fork</code> 有创建进程和当前进程的状态与属性快照的功能。这个说明它没办法与其他<br>方法commute，而<code>posix_spawn</code>则是OK的（不了解这个系统调用）</li><li>允许自由实现。比如允许 <code>open</code> 返回任何未使用的文件描述符，而不是最小的那个</li><li>允许弱序（Weak ordering）。比如通过local unix domain socket、甚至UDP来发送有序消息。在多读多写的场景允许<br>发送接收commute</li><li>异步释放资源。许多POSIX操作许多全局的影响必须在操作返回前可见</li></ol><p>4个设计实现的：</p><ol><li>Layer scability.</li><li>Defer work. </li><li>Precede perssimism with optimism</li><li><p>Don’t read unless necessary.</p><p>最后这几点不是很了解，接下来挑个时间解读一下原文，比如第二点，在原文指的是资源释放使用<br>垃圾回收方式。</p></li></ol>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;原文：&lt;br&gt;&lt;a href=&quot;http://web.mit.edu/amdragon/www/pubs/commutativity-sosp13.pdf&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;http://web.mit.edu/amdragon
      
    
    </summary>
    
    
      <category term="tech" scheme="https://blog.gobyoung.com/tags/tech/"/>
    
  </entry>
  
  <entry>
    <title>Nginx 模块开发</title>
    <link href="https://blog.gobyoung.com/2015/nginx-module-learn-note/"/>
    <id>https://blog.gobyoung.com/2015/nginx-module-learn-note/</id>
    <published>2015-12-17T11:33:54.000Z</published>
    <updated>2018-03-18T07:49:33.203Z</updated>
    
    <content type="html"><![CDATA[<ol><li>使用 OpenResty – 使用lua语言</li><li>使用原生 – 直接开发第三方模块</li></ol><p>Emiller’s Guide To Nginx Module Development<br><a href="http://www.evanmiller.org/nginx-modules-guide.html" target="_blank" rel="noopener">http://www.evanmiller.org/nginx-modules-guide.html</a></p><p>Emiller’s Advanced Topics In Nginx Module Development<br><a href="http://www.evanmiller.org/nginx-modules-guide-advanced.html" target="_blank" rel="noopener">http://www.evanmiller.org/nginx-modules-guide-advanced.html</a></p><p>Handlers – 处理器，处理请求和产生结果<br>Filters – 过滤器，过滤Handler 产生的结果<br>Load-Balancers – 负载均衡器，反向代理的时候用到</p><p>一个模块是如何工作的？<br>通常，在nginx启动时，所有的模块都有机会根据配置加载到程序中，<br>如果有多个 Handler 同时附加到某个位置，则只有一个可以成功载入。</p><p>Handler可能返回三种值：</p><ol><li>所有均正确载入</li><li>有错误但还能工作</li><li>无法工作</li></ol><p>如果Handler没有错误，那么Filter就会接着处理Handler的输出。<br>多个过滤器可以一起协同工作，比如响应结果就能压缩和分块。<br>Filter以经典的”Chain of Responsibility” 模式工作。和 webpy 的 middleware 一样。</p><p>Filter不会等到上一个处理均结束才开始，而是类似于Unix的管道一样，<br>以 buffer形式（流水线），可以理解成流式的。</p><p>一个处理周期如下：</p><ol><li>客户端发送HTTP请求</li><li>Nginx选择合理的Handler处理（根据配置中的location来）</li><li>[可选]选用某个后端</li><li>Handler 处理完把每个Buffer传给第一个Filter</li><li>第一个Filter传给第二个Filter</li><li>… 直到最后一个并把所有响应给Client</li></ol><h1 id="Nginx-模块的组成部分"><a href="#Nginx-模块的组成部分" class="headerlink" title="Nginx 模块的组成部分"></a>Nginx 模块的组成部分</h1><h2 id="1-配置部分"><a href="#1-配置部分" class="headerlink" title="1. 配置部分"></a>1. 配置部分</h2><p>命名： ngx_http_&lt;module_name>_(main|srv|loc)_conf_t，例如 dav 模块：</p><pre><code>::ctypedef struct {    ngx_uint_t methods;    ngx_flag_t create_full_put_path;    ngx_uint_t access;} ngx_http_dav_loc_conf_t;</code></pre><p>例如 ngx-redis模块：</p><pre><code>::ctypedef struct {    nginx_http_upstream_conf_t  upstream;      // set upsteam    nginx_int_t                 index;         //     nginx_int_t                 db;    nginx_uint_t                gzip_flag;    ngx_http_complex_value_t   *complex_target;} ngx_http_redis_loc_conf_t;</code></pre><h2 id="2-指令部分"><a href="#2-指令部分" class="headerlink" title="2. 指令部分"></a>2. 指令部分</h2><p>一般是 ngx_command_t 的数组：</p><pre><code>::cstatic ngx_command_t  ngx_http_redis_commands[] = {    { ngx_string(&quot;redis_pass&quot;),      NGX_HTTP_LOC_CONF|NGX_HTTP_LIF_CONF|NGX_CONF_TAKE1,      ngx_http_redis_pass,      NGX_HTTP_LOC_CONF_OFFSET,      0,         NULL },    #if defined nginx_version &amp;&amp; nginx_version &gt;= 8022    { ngx_string(&quot;redis_bind&quot;),      NGX_HTTP_MAIN_CONF|NGX_HTTP_SRV_CONF|NGX_HTTP_LOC_CONF|NGX_CONF_TAKE1,      ngx_http_upstream_bind_set_slot,      NGX_HTTP_LOC_CONF_OFFSET,      offsetof(ngx_http_redis_loc_conf_t, upstream.local),      NULL },    #endif    { ngx_string(&quot;redis_connect_timeout&quot;),      NGX_HTTP_MAIN_CONF|NGX_HTTP_SRV_CONF|NGX_HTTP_LOC_CONF|NGX_CONF_TAKE1,      ngx_conf_set_msec_slot,      NGX_HTTP_LOC_CONF_OFFSET,      offsetof(ngx_http_redis_loc_conf_t, upstream.connect_timeout),      NULL },    { ngx_string(&quot;redis_send_timeout&quot;),      NGX_HTTP_MAIN_CONF|NGX_HTTP_SRV_CONF|NGX_HTTP_LOC_CONF|NGX_CONF_TAKE1,      ngx_conf_set_msec_slot,      NGX_HTTP_LOC_CONF_OFFSET,      offsetof(ngx_http_redis_loc_conf_t, upstream.send_timeout),      NULL },    ...}</code></pre><p>一个ngx_command_t 的结构如下：</p><pre><code>::cstruct ngx_command_t {    ngx_str_t         name; // 指令名称    ngx_uint_t        type; // 指令作用的类型    char  *(*set)(ngx_conf_t *cf, ngx_command_t *cmd, void *conf); // 设置的回调    ngx_uint_t        conf;  // 标识变量在的位置，是在Main、Server还是Location    ngx_uint_t        offset; // 确定变量在结构体中的位置    void             *post; // 后处理的指针，一般是个NULL};</code></pre><p>具体参见：<a href="http://www.nginxguts.com/2011/09/configuration-directives/" target="_blank" rel="noopener">http://www.nginxguts.com/2011/09/configuration-directives/</a></p><h2 id="3-模块上下文"><a href="#3-模块上下文" class="headerlink" title="3. 模块上下文"></a>3. 模块上下文</h2><p>静态 <code>ngx_http_module_t</code> 结构体，命名<code>ngx_http_&lt;module_name&gt;_module_ctx</code>，功能包括：</p><ul><li>preconfiguration(conf)</li><li>postconfiguration</li><li>create_main_conf – 分配内存以及设定初始值</li><li>init_main_conf – 根据nginx.conf 重写初始值</li><li>create_srv_conf – 创建server</li><li>merge_srv_conf </li><li>create_loc_conf</li><li>merge_loc_conf</li></ul><p>redis的模块例子如下：</p><pre><code>::cstatic ngx_http_module_t  ngx_http_redis_module_ctx = {    ngx_http_redis_add_variables,          /* preconfiguration */    NULL,                                  /* postconfiguration */    NULL,                                  /* create main configuration */    NULL,                                  /* init main configuration */    NULL,                                  /* create server configuration */    NULL,                                  /* merge server configuration */    ngx_http_redis_create_loc_conf,        /* create location configration */    ngx_http_redis_merge_loc_conf          /* merge location configration */};</code></pre><p>就如上面的例子，一般来说模块只有两个需要实现的， <code>ngxin_http_&lt;module&gt;_create_loc_conf</code><br> 用来分配内存， <code>nginx_http_&lt;module&gt;_merge_loc_conf</code> 用来合并配置。<br>合并配置会检查配置合法性，如果出错了，就会终止nginx的启动。</p><p>preconfiguration 用来做一些配置读取前的准备，<br>例如redis模块用来初始化内置的变量 <code>ngx_http_redis_add_variables</code>：</p><pre><code>::cstatic ngx_int_tngx_http_redis_add_variables(ngx_conf_t *cf){    ngx_int_t             n;    ngx_http_variable_t  *var;    var = ngx_http_add_variable(cf, &amp;ngx_http_redis_db,                                NGX_HTTP_VAR_CHANGEABLE);    if (var == NULL) {        return NGX_ERROR;    }    var-&gt;get_handler = ngx_http_redis_reset_variable;    n = ngx_http_get_variable_index(cf, &amp;ngx_http_redis_db);    if (n == NGX_ERROR) {        return NGX_ERROR;    }    ngx_http_redis_db_index = n;    return NGX_OK;}</code></pre><p>创建location位置的配置，例如redis的方法<code>nginx_http_redis_create_loc_conf</code>:</p><pre><code>::cstatic void *ngx_http_redis_create_loc_conf(ngx_conf_t *cf){    ngx_http_redis_loc_conf_t  *conf;    conf = ngx_pcalloc(cf-&gt;pool, sizeof(ngx_http_redis_loc_conf_t));    if (conf == NULL) {#if defined nginx_version &amp;&amp; nginx_version &gt;= 8011        return NULL;#else        return NGX_CONF_ERROR;#endif    }    /*     * set by ngx_pcalloc():     *     *     conf-&gt;upstream.bufs.num = 0;     *     conf-&gt;upstream.next_upstream = 0;     *     conf-&gt;upstream.temp_path = NULL;     *     conf-&gt;upstream.uri = { 0, NULL };     *     conf-&gt;upstream.location = NULL;     */    conf-&gt;upstream.connect_timeout = NGX_CONF_UNSET_MSEC;    /* more code */    return conf;}</code></pre><p>上面的<code>NGX_CONF_UNSET_MSEC</code>说明这些变量应该被合并。</p><p>合并变量，<code>ngx_http_redis_merge_loc_conf</code>:</p><pre><code>::cstatic char *ngx_http_redis_merge_loc_conf(ngx_conf_t *cf, void *parent, void *child){    ngx_hash_init_t            hash;    ngx_http_redis_loc_conf_t *prev = parent;    ngx_http_redis_loc_conf_t *conf = child;    ngx_conf_merge_msec_value(conf-&gt;upstream.connect_timeout,                              prev-&gt;upstream.connect_timeout, 60000);    if (0/*something bad happend*/) {        ngx_conf_log_error(NGX_LOG_EMERG, cf, 0, &quot;maybe you forget set upstream?&quot;);        return NGX_CONF_ERROR;    }    /* more code */    return NGX_CONF_OK;}</code></pre><h2 id="4-模块定义"><a href="#4-模块定义" class="headerlink" title="4. 模块定义"></a>4. 模块定义</h2><p>一般称为<code>ngx_http_&lt;module&gt;_module</code>，一般需要的是上下文、命令，还有类型，<br>其他都是一堆钩子函数，正常用不到，用到了再说。</p><pre><code>::cngx_module_t  ngx_http_redis_module = {    NGX_MODULE_V1,    &amp;ngx_http_redis_module_ctx,            /* module context */    ngx_http_redis_commands,               /* module directives */    NGX_HTTP_MODULE,                       /* module type */    NULL,                                  /* init master */    NULL,                                  /* init module */    NULL,                                  /* init process */    NULL,                                  /* init thread */    NULL,                                  /* exit thread */    NULL,                                  /* exit process */    NULL,                                  /* exit master */    NGX_MODULE_V1_PADDING};</code></pre><h2 id="5-模块安装"><a href="#5-模块安装" class="headerlink" title="5. 模块安装"></a>5. 模块安装</h2><p>安装的方式根据模块类型而不同，以下一一介绍。</p><h1 id="Handlers"><a href="#Handlers" class="headerlink" title="Handlers"></a>Handlers</h1><h2 id="1-Handler-解析"><a href="#1-Handler-解析" class="headerlink" title="1. Handler 解析"></a>1. Handler 解析</h2><p>Handler一般做四件事：</p><ol><li>获取配置</li><li>生成对应的响应，如果是upstream，交给upstream处理</li><li>发送 Headers</li><li>发送 Body</li></ol><p>Handler 方法原型是包含一个 ngx_http_request_t 的参数，然后返回处理正确与否。<br>redis 模块的 Handler方法如下：</p><pre><code>::cstatic ngx_int_tngx_http_redis_handler(ngx_http_request_t *r) {    ngx_int_t                       rc;     ngx_http_upstream_t            *u;         ngx_http_redis_ctx_t           *ctx;           ngx_http_redis_loc_conf_t      *rlcf;    if (!(r-&gt;method &amp; (NGX_HTTP_GET|NGX_HTTP_HEAD))) {        return NGX_HTTP_NOT_ALLOWED;    }                                       rc = ngx_http_discard_request_body(r);    if (rc != NGX_OK) {                 return rc;                              }                                               if (ngx_http_set_content_type(r) != NGX_OK) {        return NGX_HTTP_INTERNAL_SERVER_ERROR;      }                                                   rlcf = ngx_http_get_module_loc_conf(r, ngx_http_redis_module);    if (rlcf-&gt;complex_target) {                     ngx_str_t           target;                             ngx_url_t           url;                                        /* Some code here */    }    /* Another code there */    return NGX_DONE;}</code></pre><h3 id="获取配置"><a href="#获取配置" class="headerlink" title="获取配置"></a>获取配置</h3><p>从上面代码，可以看到应用了宏 <code>ngx_http_get_module_loc_conf</code>，相应的，有srv/main的宏。</p><pre><code>::c#define ngx_http_get_module_main_conf(r, module)                             \    (r)-&gt;main_conf[module.ctx_index]#define ngx_http_get_module_srv_conf(r, module)  (r)-&gt;srv_conf[module.ctx_index]#define ngx_http_get_module_loc_conf(r, module)  (r)-&gt;loc_conf[module.ctx_index]</code></pre><p>返回的<code>ngx_http_redis_loc_conf_t</code>就是需要配置了。</p><h3 id="产生响应"><a href="#产生响应" class="headerlink" title="产生响应"></a>产生响应</h3><p>由于handler的参数只有一个 <code>ngx_http_request_t</code>，而这个结构体包罗万象，比如：</p><pre><code>::ctypedef struct {.../* the memory pool, used in the ngx_palloc functions */    ngx_pool_t                       *pool;     ngx_str_t                         uri;    ngx_str_t                         args;    ngx_http_headers_in_t             headers_in;...} ngx_http_request_t;</code></pre><ul><li><code>pool</code> 内存池，用ngx_palloc时需要的</li><li><code>uri</code> 请求的uri</li><li><code>args</code> 请求的queryString部分，比如 <code>name=jhon</code></li><li><code>headers_in</code> Request的Headers部分，详见<a href="http://lxr.evanmiller.org/http/source/http/ngx_http_request.h#L158" target="_blank" rel="noopener">http/ngx_http_request.h</a></li></ul><h3 id="发送Headers"><a href="#发送Headers" class="headerlink" title="发送Headers"></a>发送Headers</h3><p>Response的Headers在<code>ngx_http_request_t.headers_out</code> 中，<br>要发送headers，直接 <code>rc = ngx_http_send_header(r)</code> 就行了，<br>其中这个结构体中比较有趣的一部分是：</p><pre><code>::ctypedef stuct {...    ngx_uint_t                        status;    size_t                            content_type_len;    ngx_str_t                         content_type;    ngx_table_elt_t                  *content_encoding;    off_t                             content_length_n;    time_t                            date_time;    time_t                            last_modified_time;..} ngx_http_headers_out_t;</code></pre><p>比如我们可以根据redis的设定返回Header（事实上这个模块并没有这种配置，<br>echo模块有status设置，以下是我自己的脑补）：</p><pre><code>::cr-&gt;headers_out.status = rlcf.status;r-&gt;headers_out.content_length_n = 100;r-&gt;headers_out.content_type.len = sizeof(rlcf.content_type) - 1;r-&gt;headers_out.content_type.data = (u_char *) rlcf.content_type;ngx_http_send_header(r);</code></pre><p>但有些HTTP头并不能直接配置，例如<code>r-&gt;headers_out.content_encoding</code><br>是个 <code>nginx_table_elt_t*</code>，所以需要先分配内存。<code>ngx_list_push</code>这个方法<br>可以帮我们做这个事情，它传入一个<code>ngx_list_t</code>并返回最新的</p><h3 id="TEST-MathJax"><a href="#TEST-MathJax" class="headerlink" title="TEST MathJax"></a>TEST MathJax</h3><p>$$\frac{\partial u}{\partial t}<br>= h^2 \left( \frac{\partial^2 u}{\partial x^2} +<br>\frac{\partial^2 u}{\partial y^2} +<br>\frac{\partial^2 u}{\partial z^2}\right)$$</p><p>$$\begin{align}<br>    p(v_i=1|\mathbf{h}) &amp;= \sigma\left(\sum_j w_{ij}h_j + b_i\right) \<br>    p(h_j=1|\mathbf{v}) &amp;= \sigma\left(\sum_i w_{ij}v_i + c_j\right)<br> \end{align}$$</p><p>$$E(\mathbf{v}, \mathbf{h}) = -\sum_{i,j}w_{ij}v_i h_j - \sum_i b_i v_i - \sum_j c_j h_j$$</p><ul><li>Inline equations: $p(x|y) = \frac{p(y|x)p(x)}{p(y)}$.</li><li>Simple inline $a = b + c$.</li></ul>]]></content>
    
    <summary type="html">
    
      
      
        &lt;ol&gt;
&lt;li&gt;使用 OpenResty – 使用lua语言&lt;/li&gt;
&lt;li&gt;使用原生 – 直接开发第三方模块&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;Emiller’s Guide To Nginx Module Development&lt;br&gt;&lt;a href=&quot;http://www.e
      
    
    </summary>
    
    
      <category term="tech" scheme="https://blog.gobyoung.com/tags/tech/"/>
    
  </entry>
  
  <entry>
    <title>SynProxy 工作原理</title>
    <link href="https://blog.gobyoung.com/2015/how-synproxy-works/"/>
    <id>https://blog.gobyoung.com/2015/how-synproxy-works/</id>
    <published>2015-12-16T17:37:44.000Z</published>
    <updated>2018-03-18T07:49:33.203Z</updated>
    
    <content type="html"><![CDATA[<p>[TOC]</p><h2 id="SynFlood-简述"><a href="#SynFlood-简述" class="headerlink" title="SynFlood 简述"></a>SynFlood 简述</h2><p>Syn Flood 从1994年就被发现到现在，一直以来都是较为简单、有效的DDoS攻击手段。虽然如今很多在实现TCP/IP协议栈的时候采用了很多方法来减缓Syn Flood的攻击（比如<a href="http://cr.yp.to/syncookies.html" title="Syn Cookie" target="_blank" rel="noopener">Syn Cookie</a>、 <a href="https://tools.ietf.org/html/rfc6013" title="TCP Cookie Transaction" target="_blank" rel="noopener">TCP Cookie Transaction</a>），但是今天的DDoS攻击中Syn Flood的占比依旧<a href="http://www.thegitc.com/phone/pptDown/2015/ppt/%E5%88%86%E4%BC%9A%E5%9C%BA/306%E5%AE%89%E5%85%A8/11%E6%9C%8819%E6%97%A5/1%E5%88%98%E7%B4%AB%E5%8D%83%E2%80%94%E7%94%B5%E4%BF%A1/%E5%88%98%E7%B4%AB%E5%8D%83%E2%80%94DDoS%E7%9A%84%E7%8E%B0%E7%8A%B6%E3%80%81%E8%B6%8B%E5%8A%BF%E5%92%8C%E5%BA%94%E5%AF%B9.pdf" title="云堤报告" target="_blank" rel="noopener">高达58%</a>。最近两三年随着各种公有云的兴起，DDoS攻击流量也从原来的几十Gps上升到400Gps，所以威胁并没有随着网络性能提升而得到减缓。比较系统的介绍SynFlood攻击和防御可参见(<a href="https://tools.ietf.org/html/rfc4987" title="TCP SYN Flooding Attacks and Common Mitigations" target="_blank" rel="noopener">TCP SYN Flooding Attacks and Common Mitigations</a>)。当前防护Syn Flood的手段主要有三种：</p><ol><li>丢包模式，利用TCP重传机制，丢弃首个 Syn 包。<br>当系统收到Syn包时，进行计数，如果该SYN包的来源IP是首次到达，那么就丢弃处理。<br>这种防御方法也是最简单、比较有效的方式，能够防御所有的伪造源IP的Syn Flood攻击。<br>但是根据RFC793以及各种实现来看，Syn包的首次重传至少有1秒的间隔，<br>非常影响正常用户的体验，以及也没有办法防御来自固定源IP的攻击；</li><li>反向探测，即向Client发送探测包。<br>就是当收到Syn包时，系统先向Client发送可用来验证合法请求的数据包，<br>比如常见的是返回响应码不正确SynAck包，然后再根据Client返回的Reset包来判断该Client的合法性。<br>这种方法不仅能够防御伪造源IP，也能防御固定IP的攻击。<br>但是有个缺点是当Client有比较高级的防火墙会丢弃非法的SynAck包时，会造成误杀；</li><li>代理模式，即Syn Proxy，把DDoS设备当成代理。<br>这种模式类似于目前负载均衡设备的功能，防御设备先伪造Server与Client建立连接，<br>然后再与Server建立连接，双向连接建立好之后再进行数据转发。<br>显然这种方式能够拦截所有想要发起Syn Flood 的 Client，<br>甚至如果做得复杂些也能防御应用层的大部分攻击（比如CC、 <a href="https://en.wikipedia.org/wiki/Slowloris_(software)" target="_blank" rel="noopener">Slowloris</a>）。<br>但是这种模式也比较复杂，如果实现不好反而容易被攻击。<br>而且这种模式对于网络架构上也有比较高的要求，Client-Server双向均需要经过<br>（前两种模式只需要部署在Client–&gt; Server单向中，如果你比较熟悉LVS的话，<br>丢包模式和反向探测都可以工作在DR或者TUN模式下，而代理模式只能工作在NAT/FullNAT模式下）。<br>这种防御手段一般是实现成另外一种比较容易的方式：<br>如果与Client建立连接之后就立即断开连接，并认为Client可信，<br>但这种方式的缺点是会影响用户体验，需要Client再次发起连接。</li></ol><p>下文将简要介绍下Syn Proxy的设计和实现（下文简称为 Proxy）。<br>Syn Proxy 早在6、7年前已经有人在内核的netfilter框架中<a href="https://github.com/xiaosuo/xiaosuo/tree/master/synproxy" target="_blank" rel="noopener">实现</a>了，<br>后来百度、<a href="https://github.com/alibaba/LVS" target="_blank" rel="noopener">阿里</a>、360等的LVS也有实现，本文也参考了他们的设计。</p><h2 id="SynProxy一般流程"><a href="#SynProxy一般流程" class="headerlink" title="SynProxy一般流程"></a>SynProxy一般流程</h2><p>Syn Proxy的主要流程是与Client三路握手、与Server三路握手、转发数据。<br>因此大致的数据流如下图：</p><figure class="image-bubble">                <div class="img-lightbox">                    <div class="overlay"></div>                    <img src="/assets/img/synproxy/flow.png" alt="three way hands shake" title="">                </div>                <div class="image-caption">three way hands shake</div>            </figure><p>上述流程分为四个阶段：</p><ul><li>T1: Client 与 Proxy 三路握手</li><li>T2: Proxy 与 Server 三路握手</li><li>T3：Client与Server之间传输数据</li><li>T4: Proxy 清理资源</li></ul><p>四个阶段的状态变迁如下图：</p><figure class="image-bubble">                <div class="img-lightbox">                    <div class="overlay"></div>                    <img src="/assets/img/synproxy/stat.png" alt="stat transfer" title="">                </div>                <div class="image-caption">stat transfer</div>            </figure><p>###优点：</p><ul><li>只有在 Client 与 Proxy 三路握手之后才会与 Server 连接，实现了对Syn Flood的防御</li><li>利用 Syn Cookie 原理，实现对非 Syn 包有 Cookie 检测，不符合Cookie算法数据包直接丢弃，可以实现对TCP标志位攻击的防御</li></ul><p>###挑战：</p><ul><li>T1阶段 WinSize 处理</li><li>T1阶段其他扩展，比如TFO(TCP Fast Open)、带payload</li><li>T1阶段 TCP Options 的处理，包括MSS、WinScale、Timestamp等，发起前并未知 Server 配置</li><li>T1之后，T2还没完成之前，Client push数据会被丢弃</li><li>T2阶段的处理，目标是否可达、目标的端口是否开启</li><li>T2阶段记录Proxy生成的SeqNumber与Server生成的SeqNumber之间的差别，用于T3转发的矫正</li><li>T3阶段对 SeqNumber 的矫正</li><li>T4阶段的资源回收</li></ul><p>接下来先介绍下 Syn Cookie 的算法。</p><h2 id="Syn-Cookie-生成和验证"><a href="#Syn-Cookie-生成和验证" class="headerlink" title="Syn Cookie 生成和验证"></a>Syn Cookie 生成和验证</h2><p>Syn Cookie生成不同操作系统的实现，最原始算法见[SYN cookies]，一般都由若干密钥、时间、MSS以及四元组决定。在linux kernel 2.6.32 中是下面这个公式：</p><pre><code>syn_cookie = hash1 + syn_seq + current_time * 2^24 + hash2 + MSS % 2^24</code></pre><p>其中：</p><pre><code>hash1 := hash(sec1, saddr, daddr, sport, dport)hash2 := hash(sec2, saddr, daddr, sport, dport, current_time)syn_seq : client发起的sequence numbercurrent_time: 收到SYN包的时间，以分钟位单位sec1, sec2 := 加密种子</code></pre><p>当进行校验时，首先校对时间，从上式发现，时间与为syn_cookie的高8位决定，高八位由时间、hash1和syn_seq决定：</p><pre><code>time = (syn_cookie - hash1 - syn_seq)/(2^24)</code></pre><p>如果time合法（内核以分钟为单位），则可以确定hash2，因此MSS也可以确定，再对MSS进行判定。</p><h2 id="T1阶段处理"><a href="#T1阶段处理" class="headerlink" title="T1阶段处理"></a>T1阶段处理</h2><p>T1阶段Proxy并不知道后端的情况，包括WinSize大小、MSS大小、WinScale及Tcpstamp开启情况、扩展支持情况(比如TCP Fast Open)</p><h3 id="WinSize处理"><a href="#WinSize处理" class="headerlink" title="WinSize处理"></a>WinSize处理</h3><p>WinSize的处理比较简单，有两种解决方案，一种取 Linux 默认大小4096，另外一种取0。当WinSize取0时，根据TCP协议，Client是不应该PUSH数据过来的，这时我们可以等T2阶段Server响应Proxy的SynAck，从中取得WinSize再通过Ack包发送给Client，同时这样也可以避免在T2握手完成之前Client Push数据过来。</p><h3 id="TCP-Options处理-MSS、SACK、Tcpstamp、WinScale"><a href="#TCP-Options处理-MSS、SACK、Tcpstamp、WinScale" class="headerlink" title="TCP Options处理(MSS、SACK、Tcpstamp、WinScale)"></a>TCP Options处理(MSS、SACK、Tcpstamp、WinScale)</h3><p>这几个参数的处理比较难办，MSS、SACK、WinScale只能在SYN包中出现，因此在选择时就需要进行评估，好在 Server 是我们自己管理的，因此这三个选项可放在配置中。但是Timestamp的处理就比较麻烦。Timstamp使得接收方能够在收到Ack之后计算RTT，在这个解决方案中我们并不能保证T1阶段Proxy给Client的timestamp 不比 T2阶段Server给Proxy的Timestamp大。因此如果需要启用Timestamp的话需要保存与T2阶段获取的Server段的Timestamp的差值 DeltaTimestamp。</p><h3 id="SYN-Cookie-算法的改进"><a href="#SYN-Cookie-算法的改进" class="headerlink" title="SYN Cookie 算法的改进"></a>SYN Cookie 算法的改进</h3><p>从上一节我们发现Syn Cookie中，高8位可以还原Time和MSS，那么还有低24位是不是可以用来放置 SACK、Timestamp和WinScale呢？阿里开源的LVS中就用下面的<a href="https://github.com/alibaba/LVS/blob/master/kernel/net/ipv4/syncookies.c#L381" target="_blank" rel="noopener">算法</a> 来改进Syn Cookie:</p><figure class="image-bubble">                <div class="img-lightbox">                    <div class="overlay"></div>                    <img src="/assets/img/synproxy/code.png" alt="code of syn cookie" title="">                </div>                <div class="image-caption">code of syn cookie</div>            </figure><h3 id="T1阶段防御"><a href="#T1阶段防御" class="headerlink" title="T1阶段防御"></a>T1阶段防御</h3><p>收到Client的Syn包，计算Syn Cookie，配置WinSize=0以及TCP Options，响应SynAck。对 Client 发过来的Ack包进行解析，判定是否合法。这个阶段可以丢弃同一链路上所有的push包。需要注意的是这个阶段需要Client发过来的Sequence Number、MSS、WinScale，其中Sequence Number可以通过最后的握手包直接获取而无须额外保存，但Client的MSS可能小于我们Server之间协定的MSS。</p><h2 id="T2阶段"><a href="#T2阶段" class="headerlink" title="T2阶段"></a>T2阶段</h2><p>T2阶段发生在Client全连接建立之后，当收到Client的Ack包时，我们认定该Client是合法Client（非Syn Flood 攻击源），那么我们就可以向后端发起三次握手，握手信息从T1阶段最后的Ack包中复原Client的Sequence Number， 从Ack包的 AckNumber 复原 SACK、WinScale、MSS等信息拼接 TCP Options，向Server发送Syn包。</p><p>当接收到Server的SynAck包时，除了给后端发送Ack完成三次握手，还需要获取其中的WinSize和Sequence Number，将WinSize值以Ack包发给Client告诉Client可以发送数据了（Ack包的信息，Sequence Number来源T1阶段的保存，Ack Number可以从SynAck包复原，WinSize值从SynAck包复原）。</p><p>这个阶段需要记录Proxy 生成的Sequence Number和 Sever生成的 Sequence Number 之间的差值 DeltaSeq。</p><p>这个时候后端Server有三种可能的状态，一个是主机不在线，第二个是主机在线但繁忙，第三是主机可达但是端口没开。前两种情况的表现比较一致，需要Proxy有重传机制。如果主机不在线，这个时候，Client可能会发送Window Probe过来，这时proxy也需要回复ZeroWindow（亦可丢弃，因为client会重传）。第三种情况主机返回RST，此时Proxy需要给Client发送RST并进入T4阶段。如果这个阶段刚好收到Client的 RST 或者 FIN 包时，则给后端发送RST并进入T4阶段。</p><h3 id="T2阶段防御"><a href="#T2阶段防御" class="headerlink" title="T2阶段防御"></a>T2阶段防御</h3><p>T2阶段能够防御所有Client的TCP标志位攻击，因为这个时间段所有的Client过来的数据包（除了FIN和RST）均会被人不过T2阶段一般时间很短。</p><h2 id="T3-amp-T4阶段"><a href="#T3-amp-T4阶段" class="headerlink" title="T3&amp;T4阶段"></a>T3&amp;T4阶段</h2><p>T3阶段是数据转发阶段，需要利用T2阶段获取的DeltaSeq对双向数据包进行 Sequence Number 和 Acknowledge Number进行修正。如果收到任何一方的Reset或者FinAck包时，需要进行转发并进入T4阶段。在断开连接有四次挥手的状态变化，但这里简化处理并没有加以判断。</p><p>T4阶段一般来说比较短暂，主要是重置标志位、移除Hash key等。</p><h3 id="T3-amp-T4阶段防御"><a href="#T3-amp-T4阶段防御" class="headerlink" title="T3&amp;T4阶段防御"></a>T3&amp;T4阶段防御</h3><p>这个阶段需要注意防止慢攻击、小包攻击，因此需要加入超时机制（测速）以及小包检测。在计时器溢出或者检测频繁小包的时候给Server和Client发送 RST 并进入T4阶段。</p><h2 id="LVS中的实现"><a href="#LVS中的实现" class="headerlink" title="LVS中的实现"></a>LVS中的实现</h2><p>目前 SynProxy 模式被广泛应用于LVS中，如前文提到的阿里、小米、UC等的开源版本。其思路主要是：</p><ul><li>在NF_INET_PRE_ROUTING处 ip_vs_pre_routing hook函数中获取Client的Syn包，获取syn包、并回复SynAck</li><li>同在NF_INET_PRE_ROUTING处的 ip_vs_in –&gt; tcp_conn_schedule 中处理与Client三路握手的Ack包，校验cookie成功后创建ipvs的session信息，完成T1阶段，并构建Syn包发送给RealServer，同时注册timer用来处理重传，进入T2阶段</li><li>在NF_INET_FORWARD的ip_vs_out中处理RealServer返回的SynAck，记录 DeltaSeq、DeltaTimestamp，向Client发送包含RealServer WinSize 的Ack包、向RealServer发送三路握手的Ack包，进入T3阶段</li><li>在tcp_dnat_handler/tcp_fnat_in_handler中修正AckSeq以及SACK中的AckSeq、Timestamp</li><li>同样，也在tcp_snat_handler/tcp_fnat_out_handler中修正</li></ul>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;[TOC]&lt;/p&gt;
&lt;h2 id=&quot;SynFlood-简述&quot;&gt;&lt;a href=&quot;#SynFlood-简述&quot; class=&quot;headerlink&quot; title=&quot;SynFlood 简述&quot;&gt;&lt;/a&gt;SynFlood 简述&lt;/h2&gt;&lt;p&gt;Syn Flood 从1994年就被发现到
      
    
    </summary>
    
    
      <category term="tech" scheme="https://blog.gobyoung.com/tags/tech/"/>
    
  </entry>
  
  <entry>
    <title>JavaScript Intellisense</title>
    <link href="https://blog.gobyoung.com/2015/javascript-intellisense/"/>
    <id>https://blog.gobyoung.com/2015/javascript-intellisense/</id>
    <published>2015-05-14T15:11:00.000Z</published>
    <updated>2018-03-18T07:49:33.203Z</updated>
    
    <content type="html"><![CDATA[<p>现在的cocos2d-js官方API文档存在比较多的缺失，特别对我这种新手来说，对cocos2d-x 的 API 完全不熟悉，这三天写js都有点头大，经常一个类要先打开官方jsdoc看，没有的话再放狗搜，狗搜到了之后经常是写一行运行一遍，效率齐低。今天下午喝完咖啡突然想起来以前写 ASP.Net 不是可以用 Visual Studio 来做 js 的自动补全吗？</p><p>根据Mads Kristensen（VS web code editor成员）的说法是当时考虑了三种方式[^Mads]：</p><ol><li>为所有的js的文件做索引，显然这种缺点非常明显，就是性能会成为瓶颈的，而且会有很多干扰选项</li><li>只索引 HTML 中 <code>&lt;script&gt;</code> 中的内容，这种能够减少非常多的负担而且能够符合一部分Web开发需求，但是假如说只写js怎么办？难道弄到一个HTML 中去？</li><li>显然，准确的方式应该是寻求一种和 using 或者 #include 的方式</li></ol><p>最后，他们决定使用如下注释的方式（天啊撸不知道vc会不会像喷golang那样喷VS）：</p><pre><code>/// &lt;reference path=&quot;../app/respond.js&quot; /&gt;</code></pre><p>就可以像using 那样根据引入的模块提示了（可以说VS的 Intellisense 真是甩其他IDE几条街），甚至可以直接从 Solution Explorer 中把 .js 拖到打开的 .js 自动完成reference，如我手残者的福音啊。</p><p>但是这个时候欲求不满的用户又叕提出需求了，假如我有几个公共的 js 需要引用怎么办？难道要我蛋疼到每个文件写之前都 reference 一次吗？于是他们在开发 VS2012 的时候就新加入了个 _references.js 的文件，只要被添加到这个文件的 .js 都默认被所有的 .js 引用。那么问题来了， _references.js 该放在哪里？ 放在根目录下肯定不合适啊，于是规定放在 ~/Scripts/ 下。 但是用户又会说，我喜欢放在 js/ 下呢？放在 res/js/ 下呢？</p><p>于是又有了选择，咱们可以在工具–&gt;选项里配置，这里有个快捷键：Ctrl+Q，就可以搜索选项了！真棒！</p><p>终于我们绕了一个大弯，如何让 VS 的 javascript editor 支持 cocos2d-js 的智能提示呢？<br>简单啊，我们新建个Web 工程，把文件以 link 方式添加进来，然后用 everything 把所有的js都扔进来就行了。于是就可以像下面这样：</p><p>![JavaScript Intellisense][ji]<br>[ji]: [[!!images/js/js-intellisense.png]] “Look”</p><p>太棒了！！</p><p>等等，前段时间巨硬不是推出了前端的福音、Mac 软狗欢呼雀跃、即将一统江湖的神兵利器吗？没错就是 Visual Studio Code 怎么用？</p><p>其实和上面的方式就是一样的:-) 只要把 _references.js 放在 当前folder 的ROOT 下就行了。<br><em>不过在我的8M js 面前 Code崩溃了哇哈哈哈哈哈哈哈</em></p><p>![lol][]<br>[lol]: [[!!images/js/lol.png]] “哈哈哈哈哈哈哈”</p><p>[^Mads]: <a href="http://madskristensen.net/post/the-story-behind-_referencesjs" target="_blank" rel="noopener">The Story Behind _References.js</a></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;现在的cocos2d-js官方API文档存在比较多的缺失，特别对我这种新手来说，对cocos2d-x 的 API 完全不熟悉，这三天写js都有点头大，经常一个类要先打开官方jsdoc看，没有的话再放狗搜，狗搜到了之后经常是写一行运行一遍，效率齐低。今天下午喝完咖啡突然想起来
      
    
    </summary>
    
    
      <category term="tech" scheme="https://blog.gobyoung.com/tags/tech/"/>
    
  </entry>
  
  <entry>
    <title>JavaScript bind 探究</title>
    <link href="https://blog.gobyoung.com/2015/javascript-bind-call-and-apply/"/>
    <id>https://blog.gobyoung.com/2015/javascript-bind-call-and-apply/</id>
    <published>2015-05-14T15:11:00.000Z</published>
    <updated>2018-03-18T07:49:33.203Z</updated>
    
    <content type="html"><![CDATA[<p>最近搞 OpenDove 需要注册一个回调，但是当方法体调用的时候却不能在回调里直接用 <code>this</code>，对我这门外汉来说简直不能忍（其实也不难理解诶，直观理解就是 .Net 平台下的UI Component 里的Invoke，当前线程扔一个回调给 UI 线程——到了UI线程中控制权显然发生交换了。但是 .Net 中回调的上下文环境没有因控制权转换而发生变化）。后来在 Chrome Console 下试了试 Function.prototype.bind 和 apply 等方法，在注册回调之后再用bind回本身就能用this了。 于是学学 JavaScript bind 到底是什么东西。当然首先要解答下 this 在 JavaScript 下到底是什么幺蛾子。</p><h1 id="关于-this"><a href="#关于-this" class="headerlink" title="关于 this"></a>关于 this</h1><p>–<br>在常规的 OOL 中， <code>this</code> 与其原意是一样的，引进来是为了保存一个对象的引用（其实我很反感 python 的 self 设计——别人说 python 是完全面向对象语言，但它内部却又很多随意性和不统一性，比如那些全局方法——每个实例方法都要明确地给个self，这个不是多此一举嘛还不如 golang 的写法）。</p><p>首先正常理解的<code>this</code>用法如下：</p><pre><code>::javascriptvar MyLayer = cc.Layer.extend({    sprite: null,    doSomething: function() {        this.sprite &amp;&amp; this.sprite.do();    }});</code></pre><p>这里的<code>this</code>就是 MyLayer 对象了。</p><p>方法外或者匿名方法下对<code>this</code>的引用在 ‘use strict’ 时是 undefined，不然就是其定义的方法的直接调用者了。例如：<br>    ::javascript<br>    var obj = {test: function(){return this;}};<br>    obj.test() === obj; // true</p><pre><code>var A = function(){}A.prototype.test = function(){return this;}A.prototype.testObj = function(){return obj.test();} // 谁调用的？是的，是obj，但是有没有办法直接绕过obj直接调用test呢？var a = new A();a.test() === a; // truea.testObj() === obj; // true</code></pre><p>对于 this 的理解，有这么一句话：</p><p><code>this</code> is not assigned a value until an object invokes the function where this is defined. </p><p>也就是说 this 只有在定义 this 的 Function 被调用的时候才会被赋值。有点绕，其实就是和 C/C++ 里头的 this 一个意思了。<br>（其实这里有关关键就是，调用方是什么概念？ Instance or Function ？然后Function 究竟是何物？为什么 1 instanceof Number 是个false？ 为什么 {} instanceof Object 是个 true？ 十万个为什么，走进科学让我们走近 Brendan Eich —— 一个让这个世界出现全栈工程师的大师）</p><p>好了，接下来就是 this 的一些坑了。</p><h2 id="回调的时候"><a href="#回调的时候" class="headerlink" title="回调的时候"></a>回调的时候</h2><p>既然this和调用者关联，那么就说要根据上下文来判断了，比如出现一个：</p><pre><code>::javscriptvar a = {callback: function(){return this;}}var b = {}b.invoke = a.callback;b.invoke() === a; // falseb.invoke() === b; // true!!!</code></pre><p>我们就需要在 a.callback 中处理“未知”的 this。 也就是我最前面碰到的问题。怎么办呢？ bind 大法好:</p><pre><code>::javscriptvar a = {callback: function(){return this;}}var b = {}b.invoke = a.callback.bind(a);b.invoke() === a; // trueb.invoke() === b; // false</code></pre><h2 id="闭包中"><a href="#闭包中" class="headerlink" title="闭包中"></a>闭包中</h2><p>OpenDove 中，其实我刚开始用的是闭包来解决回调出现的问题，只要通过中间变量处理就行了。就像下面这个：</p><pre><code>::javascriptvar b = {}var a = {    init: function(){         //这里做一些事        b.invoke = function(){            return this;        }    }}a.init();b.invoke() === b; // true</code></pre><p>这个时间就只能用变量名大法了，比如在闭包前面加一个:</p><pre><code>::javascriptvar self = this;</code></pre><h2 id="借方法（Borrowing-Methods）"><a href="#借方法（Borrowing-Methods）" class="headerlink" title="借方法（Borrowing Methods）"></a>借方法（Borrowing Methods）</h2><p>这种我 jQuery 上用过几次，通常是这种方式：</p><pre><code>::javascriptFunction.apply(instance, [args...]);Function.call(instance, args...); // More efficient for saving an array</code></pre><p>这种模式的是一种代码重用的机制，比如以前经常需要用到一些jQeury的 util 方法等，或者有时候我有些对象没办法用原型链去控制时（比如会有Array-like的东西可以直接借用 Array 的方法），这种确实是好方法。</p><p>到这里，Function 的三大方法： bind/apply/call 已经集齐了，可以召唤神龙拯救世界开始说主题了</p><h1 id="这三个方法是什么鬼？"><a href="#这三个方法是什么鬼？" class="headerlink" title="这三个方法是什么鬼？"></a>这三个方法是什么鬼？</h1><p>首先 Function 是 JavaScript 中的一种对象，那对象肯定有方法啊，没错，就是酱紫的。其实上面差不多把这三个方法的用途讲完了，基本上都是为了传递 this、以及Borrowing Methods。</p><h2 id="Function-prototype-bind"><a href="#Function-prototype-bind" class="headerlink" title="Function.prototype.bind"></a>Function.prototype.bind</h2><p>bind 是 EC5 引入的，EC5 之前都要自己实现，如何实现呢？参考 [JavaScriptIsSexy][<a href="http://javascriptissexy.com/javascript-apply-call-and-bind-methods-are-essential-for-javascript-professionals/]，刚好可以理解下是如何实现的：" target="_blank" rel="noopener">http://javascriptissexy.com/javascript-apply-call-and-bind-methods-are-essential-for-javascript-professionals/]，刚好可以理解下是如何实现的：</a></p><pre><code>::javascript// https://developer.mozilla.org/zh-CN/docs/Web/JavaScript/Reference/Global_Objects/Function/bindif (!Function.prototype.bind) {    Function.prototype.bind = function(oThis) {        if(typeof this !== &apos;function&apos;){ // 0            // 保证 XXX.bind 中的 XXX 是 Function，是callable            // 有一种情况可以用 Something.prototype = new Function() 制造原型            // 虽然 new Something 有 bind 方法却非callable            throw new TypeError(&quot;Function.prototype.bind - what is trying to be bound is not callable&quot;);        }        var args = Array.prototype.slice.call(arguments, 1), // 1            toBindFunction = this,            EmptyFunction  = function() {},                  // 2            BoundFunction  = function() {                return toBindFunction.apply(                    this instanceof EmptyFunction &amp;&amp; oThis   // 3                    ? this                     : oThis || window,                       // 4                    args.concat(Array.prototype.slice.call(arguments))); // 5            };        EmptyFunction.prototype = this.prototype;        BoundFunction.prototype = new EmptyFunction();       // 6        return BoundFunction;    };}</code></pre><p>上面这个方法有点难理解（谁当我是彩笔。。。），我对其中的简单理解如下：</p><pre><code>0. 此处的 this 指 我们要调用的方法本身，而要被绑定的是 this.this，这里需要进行判断是因为我们要调用的方法必须是可调用的，当出现 Something.prototype = new Function() 会继承这个方法，但是确实么有意义1. 获取除了 oThis 之外的参数2. 作用是啥？3. 这里的 this 指的是 BoundFunction 的实例，而前文的 this 在此处为 toBindFunction。这里判断是否为 EmptyFunction（至于为什么我现在还不懂，其实没有后面几步正常也是可行的）4. 保证没有指定的时候默认为 window（浏览器环境的 global 对象）5. 拼接两个方法的参数6. 通过 EmptyFunction（这个名字我自己取的）间接让 BoundFunction 继承 this（就是原来的方法）的方法</code></pre><h2 id="apply-amp-call"><a href="#apply-amp-call" class="headerlink" title="apply &amp; call"></a>apply &amp; call</h2><p>这两个上面也用了好多了，我太清楚具体的区别， 不过明显区别就是， apply 第二个是参数列表（是不是和其他语言的很想，比如 python 的方法参数是 tuple、.Net 里头回调方法基本上都是用数组），而call则是直接是一个个以逗号区分的参数，就像普通方法调用那样。</p><h1 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h1><p>总之我还不懂 javascript 的各类高级用法，继续学习中。。。</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;最近搞 OpenDove 需要注册一个回调，但是当方法体调用的时候却不能在回调里直接用 &lt;code&gt;this&lt;/code&gt;，对我这门外汉来说简直不能忍（其实也不难理解诶，直观理解就是 .Net 平台下的UI Component 里的Invoke，当前线程扔一个回调给 UI 
      
    
    </summary>
    
    
      <category term="tech" scheme="https://blog.gobyoung.com/tags/tech/"/>
    
  </entry>
  
  <entry>
    <title>《代码大全》初读</title>
    <link href="https://blog.gobyoung.com/2015/read-cc2e/"/>
    <id>https://blog.gobyoung.com/2015/read-cc2e/</id>
    <published>2015-01-01T07:21:00.000Z</published>
    <updated>2018-03-18T07:49:33.203Z</updated>
    
    <content type="html"><![CDATA[<p> 很惭愧到现在才开始阅读代码大全，这个还是在微博上看到有人说起码代码大全应该读一遍才适合做同事的。于是下定决心读一下。</p><p> 本科就见过《代码大全》真本书了，厚厚的一本书，然后望文生义地觉得这本估计就是算法小抄了，以至于后来在实验室之后也没有再去看了。知道上个礼拜，才开始觉得应该读一下。一翻书才发现我操这是一本软件工程的书啊，这中文书名真是害死人！！！</p><p> 最近才看完第2部分：创建高质量的代码部分。</p><h1 id="Lay-the-Foundation"><a href="#Lay-the-Foundation" class="headerlink" title="Lay the Foundation"></a>Lay the Foundation</h1><p> 第一部分主要讲的是软件构建的基础，分为4个章节，从软件构建的基础知识、到软件构建中的专业术语、<br>编写代码之前应该做什么事情、到准备开始动手开干。软件构建的基础知识我记得在本科毕业的时候想要进实验室曾经给自己下的一个任务，可是这么多年过去了，直到最近读这本书才想起来。比较系统的了解还是在进入公司之后，在看公司的一些文档才有了一个大致的了解。</p><p>在实验室的时候，需求基本上都是小boss来谈，而且就实验室的项目来言，感觉都是课程大作业类型的。项目都是属于快速交付类型，就是一边编码一边调试一边上线，需求也总是变化，一个项目经常做上好几年，可能都博士毕业了项目还没结束。如果遇到那种 科研类型 的项目还好，反正也没人用，只要按照合同来一步步做，最后糊弄过熟悉的专家就行了（突然想起来，上次实验室的“双态云”还被专家认可为国际领先！！！）。另一种就是有实际用户的项目，这种项目非常吃力，只要一进实验室分配到这种项目，未来三年五年就是做这种了。我11年的时候就一个人驻地开发了3个月，经常直接在用户旁边根据用户的需求来改。这有个好处就是能贴近用户的需求，但是也模糊了个别用户与通用的界限，同时纵容用户也导致一些伪需求的出现。</p><p>后来进了公司之后，发现公司里有点过了，可能为了明确责任吧，经常一个需求讨论挺久的。由于我所在的部门不是产品部门，这些其实也接触较少，唉，这涉及到另外一个话题了。现在有时候在后悔当初来这个岗位的决定，其实不太适合我，虽然我有信心做好，但会浪费很多时间。希望这段时间不是被我浪费，而是作为成为认真成长的一个阶段吧。</p><p>最近在开发 <a href="http://grinder.sourceforge.net" target="_blank" rel="noopener">Grinder</a> 的一个插件，用来控制并发的，蛮简单的一个，过程设计之类的就放在另外一个地方吧，反正这个挺简单的。</p><h1 id="TODO"><a href="#TODO" class="headerlink" title="TODO"></a>TODO</h1><p>*[科研类型]: 合作骗钱</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt; 很惭愧到现在才开始阅读代码大全，这个还是在微博上看到有人说起码代码大全应该读一遍才适合做同事的。于是下定决心读一下。&lt;/p&gt;
&lt;p&gt; 本科就见过《代码大全》真本书了，厚厚的一本书，然后望文生义地觉得这本估计就是算法小抄了，以至于后来在实验室之后也没有再去看了。知道上个礼拜
      
    
    </summary>
    
    
      <category term="tech" scheme="https://blog.gobyoung.com/tags/tech/"/>
    
  </entry>
  
  <entry>
    <title>一步一步写GIS库 0. 写在所有之前</title>
    <link href="https://blog.gobyoung.com/2013/write-gis-lib-0/"/>
    <id>https://blog.gobyoung.com/2013/write-gis-lib-0/</id>
    <published>2013-11-29T16:00:00.000Z</published>
    <updated>2018-03-18T07:49:33.203Z</updated>
    
    <content type="html"><![CDATA[<p>暑假康博师兄回来说要做一个用 OpenGL 和 SQLite 一起的跨平台的GIS相关lib。 刚好可以利用这个机会学习学习。学了这么多年GIS，对于GIS算法和渲染这方便基本没了解，希望趁此机会能有所建树。</p><p>但一人之力尚不足完成这件事情，恰好也在找工作期间，所以一下子耽搁到11月份了。最近事情渐少，便参考 <a href="https://github.com/mousebird/WhirlyGlobe" target="_blank" rel="noopener">WhirlyGlobe</a> 自己造个轮子，一是因为这个项目是APL2 的， 不好直接拿来用，二来边参考边码代码有助于提高编码能力和对Geometry的理解。</p><p>按照我这种常常把创作冲动当创作才能的人，真的很难有个好结尾的，所以看能不能写个日志监督一下。</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;暑假康博师兄回来说要做一个用 OpenGL 和 SQLite 一起的跨平台的GIS相关lib。 刚好可以利用这个机会学习学习。学了这么多年GIS，对于GIS算法和渲染这方便基本没了解，希望趁此机会能有所建树。&lt;/p&gt;
&lt;p&gt;但一人之力尚不足完成这件事情，恰好也在找工作期间，
      
    
    </summary>
    
    
      <category term="tutorial" scheme="https://blog.gobyoung.com/tags/tutorial/"/>
    
  </entry>
  
  <entry>
    <title>一步一步写GIS库 1. 基本结构</title>
    <link href="https://blog.gobyoung.com/2013/write-gis-lib-1/"/>
    <id>https://blog.gobyoung.com/2013/write-gis-lib-1/</id>
    <published>2013-11-29T16:00:00.000Z</published>
    <updated>2018-03-18T07:49:33.203Z</updated>
    
    <content type="html"><![CDATA[<p>一般的GIS的程序库和其他应用没什么区别，整个结构大致可以分成三部分：</p><ol><li>数据结构</li><li>数据组织</li><li>数据渲染</li></ol><h1 id="数据结构"><a href="#数据结构" class="headerlink" title="数据结构"></a>数据结构</h1><p>数据结构从根本分为<strong>矢量</strong>和<strong>栅格</strong>两种类型。</p><h2 id="栅格"><a href="#栅格" class="headerlink" title="栅格"></a>栅格</h2><p>对于栅格，因为移动设备关系，不太可能加载遥感数据，因此可能就是普通的格网+纹理贴图方式解决 ( Texture )，又因我们地图要缩放，所以需要组织不同缩放级别下的数据，因此需要 LOD( Level of Detail ) 和四叉树 ( QuadTree )。</p><h2 id="矢量"><a href="#矢量" class="headerlink" title="矢量"></a>矢量</h2><p>数据结构从最基本的几何体开始（点、线、面、体），以及集合体加上属性之后形成的要素类型。( Geometry + Feature )</p><p>现在将一个物体在一个空间中表现出来，那么就需要给这个空间建立坐标系（方便起见一般都是直角坐标系或者地心坐标）来表示空间相对关系和大小，平面几何仅仅是小范围可用，对于地理空间来说，地球表面的球面变换尤为重要，因此不仅需要坐标系统（Coordination System），还需要坐标变换系统 ( Project )。</p><h1 id="数据组织"><a href="#数据组织" class="headerlink" title="数据组织"></a>数据组织</h1><p>为了方便管理，一般会对数据进行分层，比如我们常见的地图应用中，从上往下有：兴趣点 ( POI: Point of Interesting )、地标标注（Annotation）、查询数据（路线、交通流量等）、线状地物（道路网、行政边界等）、面状地物（行政区域、建筑物）、栅格底图。分层管理有个好处就是可以进行层过滤，简化数据的组织难度，方便渲染。</p><p>以上几种的图层可以大致分为三类： </p><ol><li>标注层（Annotation Layer）：矢量文字的渲染</li><li>矢量层（Vector Layer）：矢量数据</li><li>栅格层（Tiled Layer）：切割成规则瓦片的栅格图所在的层</li></ol><p>对于矢量层， 矢量数据类型很多，因此可以对矢量数据进行归类管理，即从数据个体 –&gt; 数据类(Class) –&gt; 数据集(Set)。</p><h1 id="数据渲染"><a href="#数据渲染" class="headerlink" title="数据渲染"></a>数据渲染</h1><p>数据渲染可能根据不同数据类型渲染，基础的就是颜色（Color）、纹理（Texture）、光线（Lighting）、着色器（Shader），基本可以看成是OpenGL  ES的问题了。</p><h1 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h1><p>数据类型有：</p><ol><li>Vertor (2-3位，用来表示Vertex)</li><li>Geometry ( Point、Polyline、Polygon )</li><li>Feature (Geometry +Fields)</li><li>FeatureClass ( Multi-Feature )</li><li>FeatureSet (Multi-FeatureClass)</li><li>CoordSystem</li><li>QuadTree</li><li>Texture</li></ol><p>数据组织有：</p><ol><li>Layer</li><li>AnnotationLayer</li><li>VectorLayer</li><li>TiledLayer</li></ol><p>数据渲染差不多就是对OpenGL ES的封装了。</p><p>为了简化整个过程，将使用一些开源库（空间操作、分析），下一篇说说即将用到的一些开源库。</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;一般的GIS的程序库和其他应用没什么区别，整个结构大致可以分成三部分：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;数据结构&lt;/li&gt;
&lt;li&gt;数据组织&lt;/li&gt;
&lt;li&gt;数据渲染&lt;/li&gt;
&lt;/ol&gt;
&lt;h1 id=&quot;数据结构&quot;&gt;&lt;a href=&quot;#数据结构&quot; class=&quot;headerl
      
    
    </summary>
    
    
      <category term="tutorial" scheme="https://blog.gobyoung.com/tags/tutorial/"/>
    
  </entry>
  
</feed>
